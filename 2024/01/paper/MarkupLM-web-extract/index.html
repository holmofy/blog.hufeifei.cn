<!doctype html><html lang="en"><head><meta charset="utf-8"><script async src="https://www.googletagmanager.com/gtag/js?id=G-H58NSPXYPF"></script><script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-H58NSPXYPF")</script><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script"),t=(e.src="https://hm.baidu.com/hm.js?b3392fb5f6d65fb10354f590338d1ee4",document.getElementsByTagName("script")[0]);t.parentNode.insertBefore(e,t)}()</script><script type="text/javascript">!function(t,e,n,c,a,i){t[n]=t[n]||function(){(t[n].q=t[n].q||[]).push(arguments)},(a=e.createElement(c)).async=1,a.src="https://www.clarity.ms/tag/95vxjpui4h",(i=e.getElementsByTagName(c)[0]).parentNode.insertBefore(a,i)}(window,document,"clarity","script")</script><title>【译】基于MarkupLM的web数据抽取 | holmofy</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="baidu_union_verify" content="b7d27ec946758934fcdf3c5c26386237"><meta description="摘要网站在当今数字时代已成为许多组织获取信息的关键来源。然而，从多个网站的网页中提取和组织半结构化数据存在挑战，尤其是在希望保持广泛适用性的同时实现高度自动化时。在追求自动化的过程中，自然而然的发展是将网页数据提取的方法从仅能处理单个网站扩展到通常在同一领域内处理多个网站。尽管这些网站共享相同的域，但数据的结构可能差异巨大。一个关键问题是在保持足够准确性的同时，这样的系统能够通用地涵盖大量网站。该"><meta property="og:type" content="article"><meta property="og:title" content="【译】基于MarkupLM的web数据抽取"><meta property="og:url" content="https://blog.hufeifei.cn/2024/01/paper/MarkupLM-web-extract/index.html"><meta property="og:site_name" content="holmofy"><link rel="canonical" href="https://blog.hufeifei.cn/2024/01/paper/MarkupLM-web-extract/index.html"><meta property="description" content="摘要网站在当今数字时代已成为许多组织获取信息的关键来源。然而，从多个网站的网页中提取和组织半结构化数据存在挑战，尤其是在希望保持广泛适用性的同时实现高度自动化时。在追求自动化的过程中，自然而然的发展是将网页数据提取的方法从仅能处理单个网站扩展到通常在同一领域内处理多个网站。尽管这些网站共享相同的域，但数据的结构可能差异巨大。一个关键问题是在保持足够准确性的同时，这样的系统能够通用地涵盖大量网站。该"><meta name="description" content="摘要网站在当今数字时代已成为许多组织获取信息的关键来源。然而，从多个网站的网页中提取和组织半结构化数据存在挑战，尤其是在希望保持广泛适用性的同时实现高度自动化时。在追求自动化的过程中，自然而然的发展是将网页数据提取的方法从仅能处理单个网站扩展到通常在同一领域内处理多个网站。尽管这些网站共享相同的域，但数据的结构可能差异巨大。一个关键问题是在保持足够准确性的同时，这样的系统能够通用地涵盖大量网站。该"><meta property="og:description" content="摘要网站在当今数字时代已成为许多组织获取信息的关键来源。然而，从多个网站的网页中提取和组织半结构化数据存在挑战，尤其是在希望保持广泛适用性的同时实现高度自动化时。在追求自动化的过程中，自然而然的发展是将网页数据提取的方法从仅能处理单个网站扩展到通常在同一领域内处理多个网站。尽管这些网站共享相同的域，但数据的结构可能差异巨大。一个关键问题是在保持足够准确性的同时，这样的系统能够通用地涵盖大量网站。该"><meta property="article:published_time" content="2024-01-10T16:00:00.000Z"><meta property="article:modified_time" content="2024-05-03T05:17:06.707Z"><meta property="article:author" content="胡飞飞"><meta property="article:tag" content="算法"><meta property="article:tag" content="Web挖掘"><meta property="twitter:card" content="summary"><script data-ad-client="ca-pub-7111912103882824" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7111912103882824" crossorigin="anonymous"></script><script async custom-element="amp-auto-ads" src="https://cdn.ampproject.org/v0/amp-auto-ads-0.1.js"></script><script type="text/javascript" src="//cpro.baidustatic.com/cpro/ui/cm.js" async defer></script><link rel="alternate" href="/atom.xml" title="holmofy" type="application/atom+xml"><link rel="icon" href="//www.hufeifei.cn/favicon.jpg"><link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css"><link href="//unpkg.com/@waline/client@v3/dist/waline.css" rel="stylesheet" type="text/css"><link href="//at.alicdn.com/t/font_841402_efkj8jo1xld.css" rel="stylesheet" type="text/css"><link rel="stylesheet" href="//cdnjs.loli.net/ajax/libs/font-awesome/5.15.3/css/all.min.css" type="text/css"><link rel="stylesheet" href="/css/style.css"><link rel="dns-prefetch" href="//static.zhimg.com"><link rel="dns-prefetch" href="//at.alicdn.com"><link rel="dns-prefetch" href="//cdn.jsdelivr.net"><link rel="dns-prefetch" href="//img-blog.csdn.net"><link rel="dns-prefetch" href="//img-blog.csdnimg.cn"><meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><style>
    figure.codeblock {
       margin: 0;
    }
    figure figcaption .tabs {
      display: flex;
      margin: 0;
    }
    figure figcaption .tabs .tab {
      cursor: pointer;
      list-style: none;
      padding: 5px 15px;
    }
    figure figcaption .tabs .tab.active {
      background: #2d2d2d;
      color: white;
    }
  </style></head><body><amp-auto-ads type="adsense" data-ad-client="ca-pub-7111912103882824"></amp-auto-ads><div id="container"><div id="wrap"><header id="header"><div class="outer" id="header-outer"><div class="inner" id="header-inner"><nav id="main-nav"><a class="nav-icon" id="main-nav-toggle"><i class="fas fa-bars"></i></a><a class="main-nav-link" href="//www.hufeifei.cn">主页</a><a class="main-nav-link" href="/">博客</a><a class="main-nav-link" href="/archives">归档</a><a class="main-nav-link" target="_blank" rel="noopener" href="//algo.hufeifei.cn">算法</a><a class="main-nav-link" href="/book">书籍</a><a class="main-nav-link" href="/github">Github</a></nav><nav id="sub-nav"><a class="nav-icon" id="nav-rss-link" href="/atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a><a class="nav-icon" id="nav-search-btn" title="Search"><i class="fas fa-search"></i></a></nav><div id="search-form-wrap"><form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit"><i class="fas fa-search"></i></button><input type="hidden" name="sitesearch" value="https://blog.hufeifei.cn"></form></div></div></div></header><div class="outer"><section id="main"><article class="article article-type-post" id="post-paper/MarkupLM-web-extract" itemscope itemprop="blogPost"><div class="article-meta"><a class="article-date" href="/2024/01/paper/MarkupLM-web-extract/"><time datetime="2024-01-10T16:00:00.000Z" itemprop="datePublished">2024-01-11</time></a><div class="article-category"><a class="article-category-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></div><div class="article-views leancloud_visitors" id="/2024/01/paper/MarkupLM-web-extract/" data-flag-title="【译】基于MarkupLM的web数据抽取" title="Views"><i class="fas fa-eye"></i><span class="waline-pageview-count" data-path="/2024/01/paper/MarkupLM-web-extract/"></span></div></div><div class="article-inner"><header class="article-header" style="text-align:center"><h1 class="article-title" itemprop="name">【译】基于MarkupLM的web数据抽取</h1></header><div class="article-entry" itemprop="articleBody"><link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2>摘要</h2><p>网站在当今数字时代已成为许多组织获取信息的关键来源。然而，从多个网站的网页中提取和组织半结构化数据存在挑战，尤其是在希望保持广泛适用性的同时实现高度自动化时。在追求自动化的过程中，自然而然的发展是将网页数据提取的方法从仅能处理单个网站扩展到通常在同一领域内处理多个网站。尽管这些网站共享相同的域，但数据的结构可能差异巨大。一个关键问题是在保持足够准确性的同时，这样的系统能够通用地涵盖大量网站。该论文检查了在多个瑞典保险公司网站上进行的自动化网络数据提取的效率。先前的工作表明，使用包含多个领域网页的已知英语数据集可以取得良好的结果。选择了最先进的模型MarkupLM，并使用监督学习使用两个预训练模型（一个瑞典模型和一个英语模型）在标记的汽车保险客户网络数据的训练集上进行零样本学习。结果显示，这样的模型可以通过利用预训练模型，在源语言为瑞典的情况下，以相对较小的数据集在领域范围内取得良好的准确性。</p><h2>1、介绍</h2><p>数字时代使互联网成为主要信息来源。互联网上的数据丰富且复杂度增加，同时对更复杂服务的需求也在不断增加。尽管有大量数据可供探索，一个关键挑战是在满足数据质量和有效性要求的前提下，尽可能高效而准确地提取和结构化信息。数据的结构范围从非结构化数据（如文本）到半结构化数据（如超文本标记语言（HTML））再到结构化数据，后者可以采用表格或数据库生成的HTML形式 [1, 2]。<br>尽管人类可以手动提取这些数据，但自动化这一过程是非常可取的，即最小化人工劳动、错误和干预。存在一些可自动提取信息的网络数据提取方法，但它们的使用高度依赖于泛化和鲁棒性要求。<br>另一种选择是网站提供 Web 应用程序编程接口（API），使用诸如 RESTful API 或 GraphQL API 等技术。然而，在本论文中不会探讨这种替代方案。<br>另一种选择是网页的行业标准格式。通过模板对网站进行一些标准化，如[3]所述，但本论文不会关注这种替代方案。</p><h3>1.1、背景</h3><p>自动化网络数据提取的一个主要问题是系统的灵活性和通用性。根据Sergio Flesca等人的说法，许多系统依赖于包装器，“一组适用于从网站提取信息的提取规则” [4]，这些规则与其训练时紧密耦合的网站的底层文档对象模型（DOM）[5]树结构相关。这使得系统对结构的变化非常敏感，除非进行包装器维护 [6]，同时在未在训练集中的网站上提取正确数据方面效果不佳。任何这类系统的一个极具吸引力的特征是从先前未见过的网站提取数据（即，它应具有泛化能力），并且在满足使用提取数据的应用程序的具体要求的同时保持足够的准确性。尝试在生成和维护这样的系统期间最小化涉及的手动人工劳动会进一步增加问题的复杂性。<br>问题的一个有趣的限定是将自动化网络数据提取系统的泛化能力缩小到一组具有一些相似之处的网站。其中一种方法是创建一个特定领域的系统，旨在从同一垂直（即领域）内的多个网站中提取相同类型的对象（例如，图书）。这使系统能够充分利用这些网站在信息和结构上潜在共享的相似之处。</p><h3>1.2、问题</h3><p>这个问题在很大程度上依赖于所需数据的复杂性（例如，结构水平和目标属性数量），以及目标领域网站表示（即，HTML布局）的相似性。另一个方面是网站的语言，这是一个依赖自然语言处理（NLP）从文本中提取语义意义的系统（即，模型）中的因素。在训练数据有限时，预训练表示通常对提高性能至关重要。虽然英语有大量高质量的预训练模型，但瑞典语的数量并不如此之多。问题的一个有趣方面是预训练表示对网页数据提取模型性能的影响。<br>一个带有监督学习的网络数据提取模型能够从未见过的瑞典保险网站中提取信息的效果如何？</p><h3>1.3、宗旨</h3><p>该论文旨在探索自动化从同一垂直内的多个网站中提取网络数据的可能性。具体而言，将使用瑞典保险网站的用户网页，其中包含其保险计划的摘要。这将有望为使用当前先进技术（SOTA）模型从瑞典保险网站提取数据的可能性和效率提供一些见解。</p><h3>1.4、目标</h3><p>该论文旨在确定一个适用的网络数据提取模型，然后在瑞典汽车保险网站上对其进行修改和评估。子目标包括：</p><ul><li>获取数据集，</li><li>确定适用的模型，</li><li>修改模型，以及</li><li>评估模型。</li></ul><h3>1.5、研究方法</h3><p>项目中采用的研究方法将是设计科学 [7]，并使用实验方法进行评估。设计科学是一种范式，其中通过设计的工件产生知识和解决方案。<br>该论文将采用 MarkupLM 模型（参见第2.4.5节），并进行必要的修改以使其与瑞典语兼容。该模型（即，工件）将通过实验评估，以确定它在测试数据集中从未见过的保险网站中提取数据的效果如何。准确性将使用三个指标进行测量：精确度、召回率和 F-分数（这些指标在第2.3节中描述）。</p><h3>1.6、限制</h3><p>该论文探讨并评估单一模型的变种，而非多个不同模型。所使用的数据将仅为瑞典语且为HTML格式。对于数据集的基准真实性，将不进行手动标注。相反，将使用公司（即，Insurely）开发的手工提取机制生成基准真实性。</p><h3>1.7、结构</h3><p>第二章介绍了有关自动化网络数据提取的相关背景信息。第三章介绍了解决问题所使用的方法和方法论。第四章描述了对先进技术（SOTA）模型的修改。第五章呈现了对模型进行评估的结果。第六章讨论了所获得的结果，最后第七章提出了论文的结论并提出未来的工作。</p><h2>2、背景</h2><p>这一章概述了与网页数据提取领域（第2.1节）和深度学习（第2.2节）相关的技术，这些技术可能在网页数据提取系统中使用。第2.3节描述了用于评估网页数据提取系统的一些性能指标。不同的网页数据提取方法和三个先进技术（SOTA）模型作为相关工作被介绍（第2.4节）。</p><h3>2.1 网页数据提取</h3><p>网页数据提取是指从网页中提取信息的过程。软件系统通过在内容更改时自动和重复地从网页中提取数据来执行网页数据提取 [8]。每个网页将如第2.1.1节所述表示，页面的特定部分将如第2.1.2节所述被处理。</p><h4>2.1.1 文档对象模型</h4><p>文档对象模型（DOM）是一个API，使得文档（如HTML和可扩展标记语言（XML）文档）能够被表示为逻辑树（如图2.1所示），由节点组成，每个节点包含对象。通过将文档表示为DOM，然后操作DOM，可以以编程方式更改网页（例如，结构、样式或内容）[5]。</p><img width="438" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/b88c232a-1c66-406b-8305-5e46531e3601"><h4>2.1.2 XML路径语言</h4><p>XML路径语言（XPath）以路径符号提供了一种灵活的方法来寻址XML或HTML对象的部分。XML路径语言（XPath）表达式可用于在HTML文件的DOM树中导航，而无需依赖DOM核心特性，例如Document和Node接口，这些接口提供了getElementById()和ChildNodes等方法和属性 [9]。图2.2显示了应用于同一HTML对象的两个XPath表达式的示例。</p><img width="498" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/83f5f693-eadc-45e1-947e-620aeedae10e"><h4>2.1.3 JavaScript对象表示法</h4><p>JavaScript对象表示法（JSON）是一种轻量级的与语言无关的数据格式 [10]。JSON具有易于阅读和编写的文本格式，如图2.3所示。它基于两种结构：一组键/值对和一个有序列表。键/值对的集合称为对象，其中键/值对在左括号和右括号之间列出，键/值之间用冒号分隔。有序列表可以包含多个对象。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">{</span></span><br><span class="line">    ”name”<span class="punctuation">:</span> ”Alice”<span class="punctuation">,</span></span><br><span class="line">    ”age” <span class="punctuation">:</span> <span class="number">25</span></span><br><span class="line">  <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">{</span></span><br><span class="line">    ”name”<span class="punctuation">:</span> ”Bob”<span class="punctuation">,</span></span><br><span class="line">    ”age” <span class="punctuation">:</span> <span class="number">26</span><span class="punctuation">,</span></span><br><span class="line">    ”height”<span class="punctuation">:</span> <span class="number">174.5</span></span><br><span class="line">  <span class="punctuation">}</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure><h3>2.2 深度学习</h3><p>深度学习是机器学习的一个子集，其中建模并训练神经网络，试图模拟人脑在学习过程中的行为 [11]。在深度学习中，需要较少的数据预处理，可以使用非结构化数据，如文本和图像。使用深度学习的一个显著优势是自动特征提取，机器决定哪些特征是相关的，而无需依赖人类专家。使深度学习网络“深”的主要因素包括层中神经元的数量、这些层之间连接的复杂方式以及训练网络所需的大量计算能力 [12]。<br>以下小节介绍了几个深度学习概念，这些概念对理解模型架构很重要，具体包括卷积神经网络（CNNs）（第2.2.1节）、循环神经网络（RNNs）（第2.2.2节）和变压器（第2.2.3节），以及迁移学习的概念（第2.2.4节）。</p><h4>2.2.1 卷积神经网络</h4><p>卷积神经网络（CNNs）是深度网络的主要架构之一，其目标是通过利用卷积进行特征检测，学习数据中的高阶特征。这通过对两组信息应用数学运算来实现 [12]。CNNs主要用于机器视觉（例如，图像分类），但也适用于文本分析。在建模数据（如图像）时，CNNs具有较高的计算效率，否则在全连接网络中可能导致连接数量激增。<br>主要的三个层组包括：输入层、特征提取层和分类层，如图2.4所示。架构各层之间的主要区别在于特征提取层，它包含两种类型的层：卷积层和池化层。</p><img width="455" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/ff250a43-04cc-480e-9c33-fb3817ac2fa3"><p>卷积层在数据中寻找特征，通过对输入应用滤波器将这些特征组合成高阶特征。图2.5中显示了一个这样的滤波器，其核（即，滤波器）向量的权重为[1/3, 1/3, 1/3]。在一层中可以应用多个不同的滤波器。在应用滤波器后，激活函数用于决定哪些神经元应该被激活并传播其值。两种这样的激活函数是修正线性单元（ReLU）和高斯误差线性单元（GELU）。线性函数ReLU对于所有非负输入都输出相应的输入，否则输出零，即max(0, x)。而GELU [13] 是一个更复杂的非线性函数，可以看作是ReLU的一个更平滑的版本。</p><img width="429" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/ec51720d-1956-41cb-80f1-3a7827281ed2"><p>池化层在卷积层之后使用，以减小（即，下采样）数据表示的空间大小。这有助于减少网络记忆训练数据的自由度（即，过拟合），而是迫使其进行学习泛化；因此，在未见过的数据上表现更好。最大池化是其中的一种常见变体，它选择滤波器区域中的最大值。</p><h4>2.2.2 循环神经网络</h4><p>RNN与其他类型的神经网络有所不同，因为它们具有对数据的时间维度（即，时间依赖性）进行建模的能力。RNN在每个输入（即，时间步）之间保留状态，它使用这些状态对数据进行建模，然后将状态传递到下一个时间步。这种时间反馈使模型能够捕捉上下文，特别是对于需要基于当前和先前输入生成/推断序列的敏感数据，如语言、音频和文本 [12]。<br>长短时记忆（LSTM）[14]是最常见的RNN架构之一。其主要优势在于它能够在时间步之间保持内存不变。这种特性使其能够克服梯度消失问题，即模型由于模型（即，权重）的更新变得非常小，导致模型停止学习，无法进一步捕获任何输入。</p><h4>2.2.3 变压器</h4><p>变压器是由Ashish Vaswani等人在他们的论文《Attention is all you need》[15]中提出的最新架构之一。它是一种完全基于注意机制而非循环或卷积的架构。与具有顺序性质的循环相比，这种结构在训练期间具有更大的并行性，其中新的隐藏状态是作为过去状态的函数而生成的。<br>变压器架构基于一个编码器-解码器结构，包括编码器和解码器堆栈，每个堆栈由六个相同的层组成。编码器堆栈负责将输入的符号序列映射为连续表示。解码器堆栈生成一个符号序列，其中每次生成一个符号，并在下一生成步骤中用作额外的输入。</p><h4>2.2.4 迁移学习</h4><p>迁移学习是通过从相关领域传递信息来改进某一领域中的学习者的一种方式。在神经网络中，由于需要更大的数据集来训练网络以避免过拟合 [16]，迁移学习可以发挥重要作用，特别是在训练集有限的情况下。与从头开始训练一个模型不同，可以利用已经使用与目标域相关的更大数据集进行训练的模型，用于任务如文本情感分析和图像分类 [17]。迁移学习可以在包含两个阶段的学习框架中形式化：预训练和微调 [18]。<br>预训练阶段包括捕捉一个或多个任务的知识。这可以通过大规模未标记的语料库来学习良好的表示，然后在其他任务中使用这个表示。预训练的一些优势包括学习通用语言表示、更好的模型初始化以及在小数据集上防止过拟合的正则化效果 [16]。微调阶段使用预训练模型，并进一步使用代表特定问题的较小数据集进行所谓的下游（即，目标）任务的训练。</p><h3>2.3 评估指标</h3><p>该模型的三个评估指标将是：精确度、召回率和F分数。在关注分类性能的机器学习应用中，这些是关键指标。<br>精确度衡量正类别的预测值，同时避免将负类别错误地分类为正类别 [19]。具体而言，正确定义的预测中实际正确的比例：</p> <mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align:-2.059ex" xmlns="http://www.w3.org/2000/svg" width="32.144ex" height="5.285ex" role="img" focusable="false" viewBox="0 -1426 14207.6 2336"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">精</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">确</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">度</text></g><g data-mml-node="mo" transform="translate(2977.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4033.6,0)"><g data-mml-node="mtext" transform="translate(2209,676)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">真</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">例</text></g><g data-mml-node="mtext" transform="translate(220,-710)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">真</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">例</text><path data-c="20" d="" transform="translate(2700,0)"></path><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" transform="translate(2950,0)"></path><path data-c="20" d="" transform="translate(3728,0)"></path><text data-variant="normal" transform="translate(3978,0) scale(1,-1)" font-size="884px" font-family="serif">假</text><text data-variant="normal" transform="translate(4878,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(5778,0) scale(1,-1)" font-size="884px" font-family="serif">例</text></g><rect width="6878" height="60" x="120" y="220"></rect></g><g data-mml-node="mstyle" transform="translate(11151.6,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(12151.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(12540.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(13818.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container> <p>召回率衡量正类别的预测值，同时避免将正类别错误地分类为负类别 [19]。具体而言，正确定义的预测与所有实际正类别的比例：</p> <mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align:-2.059ex" xmlns="http://www.w3.org/2000/svg" width="32.144ex" height="5.285ex" role="img" focusable="false" viewBox="0 -1426 14207.6 2336"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">召</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">回</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">率</text></g><g data-mml-node="mo" transform="translate(2977.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4033.6,0)"><g data-mml-node="mtext" transform="translate(2209,676)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">真</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">例</text></g><g data-mml-node="mtext" transform="translate(220,-710)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">真</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">例</text><path data-c="20" d="" transform="translate(2700,0)"></path><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" transform="translate(2950,0)"></path><path data-c="20" d="" transform="translate(3728,0)"></path><text data-variant="normal" transform="translate(3978,0) scale(1,-1)" font-size="884px" font-family="serif">假</text><text data-variant="normal" transform="translate(4878,0) scale(1,-1)" font-size="884px" font-family="serif">负</text><text data-variant="normal" transform="translate(5778,0) scale(1,-1)" font-size="884px" font-family="serif">例</text></g><rect width="6878" height="60" x="120" y="220"></rect></g><g data-mml-node="mstyle" transform="translate(11151.6,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(12151.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(12540.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(13818.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container> <p>F分数，即F1分数，是精确度和召回率之间的调和平均值。基于F-beta分数，其中精确度和召回率根据beta值具有不同的权重 [19]。当beta为1时，精确度和召回率具有相等的权重（即，相等的重要性）。</p> <mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align:-2.081ex" xmlns="http://www.w3.org/2000/svg" width="43.105ex" height="5.574ex" role="img" focusable="false" viewBox="0 -1543.9 19052.4 2463.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="46" d="M128 619Q121 626 117 628T101 631T58 634H25V680H582V676Q584 670 596 560T610 444V440H570V444Q563 493 561 501Q555 538 543 563T516 601T477 622T431 631T374 633H334H286Q252 633 244 631T233 621Q232 619 232 490V363H284Q287 363 303 363T327 364T349 367T372 373T389 385Q407 403 410 459V480H450V200H410V221Q407 276 389 296Q381 303 371 307T348 313T327 316T303 317T284 317H232V189L233 61Q240 54 245 52T270 48T333 46H360V0H348Q324 3 182 3Q51 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path><path data-c="2D" d="M11 179V252H277V179H11Z" transform="translate(653,0)"></path><path data-c="62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z" transform="translate(986,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1542,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1986,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2375,0)"></path></g><g data-mml-node="mo" transform="translate(3152.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4208.6,0)"><g data-mml-node="mrow" transform="translate(220,710)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msup" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mn" transform="translate(599,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1613.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(2614,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(3114,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3725.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mtext" transform="translate(4725.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">精</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">确</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">度</text></g><g data-mml-node="mo" transform="translate(7647.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mtext" transform="translate(8647.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">召</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">回</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">率</text></g></g><g data-mml-node="mrow" transform="translate(1470.2,-719.9)"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mn" transform="translate(599,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1224.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mtext" transform="translate(2225,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">精</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">确</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">度</text></g><g data-mml-node="mo" transform="translate(5147.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mtext" transform="translate(6147.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">召</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">回</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">率</text></g></g><rect width="11547.9" height="60" x="120" y="220"></rect></g><g data-mml-node="mstyle" transform="translate(15996.4,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(16996.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(17385.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(18663.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container><p><br></p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align:-2.059ex" xmlns="http://www.w3.org/2000/svg" width="32.541ex" height="5.285ex" role="img" focusable="false" viewBox="0 -1426 14383 2336"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="46" d="M128 619Q121 626 117 628T101 631T58 634H25V680H582V676Q584 670 596 560T610 444V440H570V444Q563 493 561 501Q555 538 543 563T516 601T477 622T431 631T374 633H334H286Q252 633 244 631T233 621Q232 619 232 490V363H284Q287 363 303 363T327 364T349 367T372 373T389 385Q407 403 410 459V480H450V200H410V221Q407 276 389 296Q381 303 371 307T348 313T327 316T303 317T284 317H232V189L233 61Q240 54 245 52T270 48T333 46H360V0H348Q324 3 182 3Q51 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(653,0)"></path></g><g data-mml-node="mo" transform="translate(1430.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(2486.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(3208.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mfrac" transform="translate(4209,0)"><g data-mml-node="mrow" transform="translate(247.8,676)"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">精</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">确</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">度</text></g><g data-mml-node="mo" transform="translate(2922.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mtext" transform="translate(3922.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">召</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">回</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">率</text></g></g><g data-mml-node="mtext" transform="translate(220,-710)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">精</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">确</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">度</text><path data-c="20" d="" transform="translate(2700,0)"></path><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" transform="translate(2950,0)"></path><path data-c="20" d="" transform="translate(3728,0)"></path><text data-variant="normal" transform="translate(3978,0) scale(1,-1)" font-size="884px" font-family="serif">召</text><text data-variant="normal" transform="translate(4878,0) scale(1,-1)" font-size="884px" font-family="serif">回</text><text data-variant="normal" transform="translate(5778,0) scale(1,-1)" font-size="884px" font-family="serif">率</text></g><rect width="6878" height="60" x="120" y="220"></rect></g><g data-mml-node="mstyle" transform="translate(11327,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(12327,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(12716,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(13994,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container> <p>在优先考虑精确度或召回率的情况下，高度依赖于具体情境。由于它们通常对彼此产生相反的影响 [20]，最大化其中一个可能会降低另一个。在医学诊断中，假负例可能比假正例更昂贵（即，致命），因此在这种情况下可能更重要，应相应地加以权重。</p><h3>2.4 相关工作</h3><p>存在一些可以构建在其基础上的相关工作。具体而言，有关网络数据提取文献的调查（第2.4.1节），语言模型Bidirectional Encoder Representations from Transformers（BERT）（第2.4.3节）以及SOTA模型MarkupLM（第2.4.5节），本论文使用它们作为基础。</p><h4>2.4.1 网络数据提取调查</h4><p>Emilio Ferrara等人进行了一项调查，全面概述了网络数据提取领域的文献，并为网络数据提取应用提供了分类框架 [21]。他们确定了两种主要的算法方法：树匹配和机器学习算法。</p><h5>2.4.1.1 树匹配算法</h5><p>树匹配算法利用Web页面的半结构化特性，以HTML的形式表示为带有标签的有序根树，即DOM树。</p><p>这些类型的算法使用XPath语法处理DOM树中的特定元素。它们依赖于XPath表达式，以找到两个文档之间相似树的所谓树编辑距离匹配。类似于字符串编辑距离问题，两个有序树可以通过尽可能少的操作（即，节点删除、插入或替换）来相互转换以匹配。简单的树匹配算法 [22]是树编辑距离匹配问题的高效且易于实现的解决方案 [23]。</p><h5>2.4.1.2 机器学习算法</h5><p>机器学习算法是一种适用于具有不同结构的多个网站的领域特定提取的良好方法。这些算法依赖于手动标记的网站，以获取领域专业知识，一些最早使用机器学习的系统包括WIEN [24]、Rapier [25]和WHISK [26]。</p><p>WIEN专注于归纳学习技术，以自动生成包装器。生成的规则可能类似于“忽略所有字符，直到找到第一个’.’并提取餐厅名称，该字符串以第一个’:’结束。然后，再次忽略所有字符，直到找到’(‘并提取以’)’结束的字符串。” [27]。类似这样的规则会在存在多个对象的情况下重复，直到无法与其他对象匹配。</p><p>Rapier使用有限的句法和语义信息学习规则，而无需在文档之前进行解析或后处理。规则分为三种模式：前填充器、填充器和后填充器。其中前填充器和后填充器充当左右分隔符，而填充器模式描述目标信息结构。</p><p>WHISK生成可以处理各种结构的文档（从自由文本到HTML）的规则。这些规则是一种特殊类型的正则表达式（即，尝试与输入文本匹配的模式），由两个组件组成。第一个组件负责确定短语必须处于其中以使其相关的正确上下文，而另一个指定要提取的短语的哪些部分。</p><h4>2.4.2 网页表提取调查</h4><p>Shuo Zhang等人进行了一项调查 [28]，研究了有关网页表提取的文献。其目的是确定和描述几个网页表提取任务及其相互依赖关系。他们确定了六个主要类别，用于对文献进行分类。这些类别包括：表提取、表解释、表搜索、问题回答、知识库增强和表增强。</p><p>他们定义了一个表由以下元素组成：页面标题、标题、列、单元格、行、列和实体。提出了一种表分类方案，通过两个维度内容和布局来区分表。</p><h5>2.4.2.1 表提取</h5><p>表提取是在网页上检测和提取表格，然后以一致的格式存储的过程。在网上提取表格的第一步是过滤掉“不好的”表格（例如，用于布局或格式目的的表格）。这通常通过关系表分类来完成，以识别包含关系数据的表格。在这里，可以使用具有布局或内容类型特征的机器学习分类器。布局特征可以是行数、列数或平均单元格字符串长度。而内容类型特征可以是表体中非字符串数据的百分比、带</p><p>有数字字符的单元格的比例，或包含 <code>&lt;span&gt;</code> 标签的单元格的比例。类似的方法也可以用于表头检测和表类型分类，前者检测表是否包含标题行或列，而后者根据预定义的分类法对表进行分类。</p><h5>2.4.2.2 表解释</h5><p>表解释旨在发现网页上表格的语义，以便对表格中的数据进行智能处理。使用分类法来了解表列的含义以及它们是否与其他列相关。主要的任务有列类型识别、实体链接和关系提取。</p><p>列类型识别涉及确定列类型并定位核心列（即，主体列），通常是最左边的列。实体链接是指检测实体（例如，人物、组织和地点），这对于揭示语义至关重要。关系提取旨在将一对列与其内容之间的关系关联起来。</p><h5>2.4.2.3 表搜索</h5><p>表搜索通过关键字查询返回带有排名列表的表，其中查询可以是一个表或多个关键字。主要有基于关键字和基于表的两种搜索类型。基于关键字的搜索返回给定关键字查询的表的排名列表。</p><h5>2.4.2.4 问题回答</h5><p>问题回答试图使用表格中的结构化数据回答自然语言处理问题。使用表格回答问题的主要挑战是将非结构化查询与表格中的结构化信息匹配。将查询解析为形式化表示的任务称为语义解析，其中生成逻辑表达式，可在知识库上执行。</p><h5>2.4.2.5 知识库增强</h5><p>知识库增强使用表格数据来探索、扩展或构建知识库。知识探索可以在具有属性搜索查询或实体关系查询的表格上进行。通过使用知识库进行注释，然后从表格中提取信息，可以扩展现有的知识库。如果表格包含丰富的信息，它可以转化为新的知识库。</p><h5>2.4.2.6 表增强</h5><p>表增强通过添加附加数据扩展现有表格。它可以分为三个任务：行扩展、列扩展和数据完成。行扩展通常应用于水平关系表。相反，列扩展通常通过查找相似的表格，然后评估这些表格中的列标题和值来添加额外的列。数据完成可以应用于整个列，通过匹配来自其他表格的类似列，或在单个单元格上使用机器学习算法，例如k最近邻或线性回归。</p><h5>2.4.3 双向编码器表示转换器</h5><p>Jacob Devlin等人提出了一种名为BERT的新语言表示模型 [29]。预训练语言模型已被证明可以在句子和标记级别的任务上提高几种自然语言处理问题。然而，以前的技术限制了预训练模型的体系结构选择，使其能够联合条件化左侧和右侧（即双向）上下文，这对于标记级别的任务如问答至关重要。BERT通过利用Transformer体系结构（第2.2.3节）和两个预训练目标实现了双向预训练。</p><p>该体系结构是一个多层双向Transformer编码器，并具有需要最小更改用于最终下游体系结构的属性。输入表示可以处理单个和多个句子作为输入序列，并以三种方式嵌入：令牌、段和位置嵌入。这三种嵌入求和以表示输入嵌入，如图2.6所示。一个令牌可以是三种情况之一：特殊的序列开始令牌（[CLS]），一个单词或一个分隔令牌（[SEP]）以区分句子。特定于序列中的令牌所属的段嵌入（例如，句子A或B）。位置嵌入编码了序列中令牌的位置。</p><img width="499" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/a80b8b0a-5db7-48fc-a524-5d582cf98928"><p>两个目标，遮蔽语言建模（MLM）和下一句预测（NSP），在预训练期间被使用。MLM通过随机遮蔽输入标记的一部分，然后训练模型预测被遮蔽标记，使模型学习双向表示。NSP使模型学习两个句子之间的关系。选择两个句子A和B，其中句子B一半的时间被随机替换，要求模型预测句子B是否跟随句子A。</p><p>BERT使用两个数据集进行预训练：BooksCorpus [30]（800M字）和English Wikipedia（2500M字）。BERT是第一个基于微调的表示模型，在多个标记和句子级任务上取得了SOTA结果，如通用语言理解评估（GLUE）[31]、斯坦福问答数据集（SQuAD）[32]和带有对抗生成的情境（SWAG）[33]。</p><h4>2.4.4 SimpDOM</h4><p>Yichao Zhou等人探索了在相同垂直领域内从多个网站提取数据的可能性 [34]。他们提出的模型∗，称为SimpDOM，在使用Few-Shot Learning（FSL）准确提取未见网站的数据时取得了SOTA结果。</p><p>SimpDOM模型的主要思想是专注于HTML页面的DOM树表示，并为每个变量节点构建丰富的表示。该方法避免了昂贵的网页呈现过程，利用DOM树中节点属性值的语义。</p><p>该架构由DOM树简化模块、离散特征模块和文本编码器组成。DOM树简化模块提取具有不同值的所有节点的上下文（因为在数据点之间具有相同值的节点不感兴趣）。上下文是其友好节点（即附近节点）的特征。离散特征模块通过添加额外的离散特征（例如XPath、叶节点类型和相对节点位置）来增强节点表示。文本编码器是CNN-LSTM的组合，对字符和单词级特征进行编码。</p><p>使用Structured Web Data Extraction（SWDE）数据集对SimpDOM进行评估。该数据集最初由郝强等人创建 [35]，包含来自80个不同网站的124,000个标记页面，分为八个垂直领域（例如汽车、图书和电影），每个领域包含3到5个感兴趣的属性（例如标题和作者）。在每个垂直领域中，使用10个网站中的5个作为种子站点（即训练集中的站点），SimpDOM实现了93.75的平均F1分数。</p><p>SimpDOM的作者选择使用一个基于Global Vectors for Word Representation（GloVe）[36]架构训练的，包含60亿标记的著名预训练词嵌入来初始化他们的模型。</p><h4>2.4.5 MarkupLM</h4><p>Junlong Li等人研究了创建一个模型∗，能够解决多个文档理解任务，适用于视觉丰富的标记文档，如HTML和XML文件 [37]。任务包括文档理解、类型分类和视觉问答。通过利用DOM树，可以对文档的不同元素之间建模位置关系，而不是使用显式的2D表示，这对文档渲染的设备高度依赖。通过使用DOM树建模位置关系而不使用渲染的2D可视化，简化了预训练，同时仍然利用了文档布局。</p><p>BERT [29]体系结构被用作编码器，其中嵌入层扩展了额外的输入XPath嵌入。然后，该模型通过三个主要目标进行预训练：遮蔽标记语言建模（MMLM），节点关系预测（NRP）和标题页匹配（TPM）。MMLM是MLM的扩展，通过使用文本和标记作为输入，遮</p><img width="496" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/03eed6a4-bfc1-40bc-a231-8ed78c21932d"><h4>2.4.6 DOM-LM</h4><p>邓翔等人提出了一种能够解决类似文档理解任务的模型，与MarkupLM一样，利用了DOM树表示法，就像以前的工作所做的一样 [39]。该模型基于BERT（与MarkupLM相同），其参数是从预训练的BERT模型（对非结构化文本进行预训练）中初始化的，然后进一步训练以捕获HTML文档的结构和布局信息。该模型以两个目标进行预训练：遮蔽节点预测（MNP）和遮蔽标记预测（MTP）。MTP类似于BERT中执行的MLM目标（以及MarkupLM中的修改变体MMLM）。MNP通过不仅遮蔽输入标记而且遮蔽整个节点来进一步概括模型，以迫使模型学习树级上下文化，并对布局具有整体视图。</p><p>该模型的主要方法是将文档编码为一组子树，其中嵌入了位置信息，并采用了自监督预训练。首先通过去除与网页结构和语义无关的所有DOM节点（例如，<code>&lt;script&gt;</code> 和 <code>&lt;style&gt;</code> 元素），然后将树分割成子树来构建一组子树。分割是通过在整个DOM树上应用具有固定步长（即单位）的滑动窗口来完成的。滑动是这样进行的，以便在同一直接周围的节点被捕获在同一子树中。</p><p>在培训过程中使用的数据量与SimpDOM和MarkupLM中使用的数量有所不同。DOM-LM仅使用了10％的种子站点（2和5）的数据，而不是所有的数据，这与SimpDOM和MarkupLM不同。结果可见于表2.2。</p><img width="494" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/6c4a8b89-49a5-4e4b-ae9d-533391a8c3b4"><h3>2.5 总结</h3><p>本章在第2.1节介绍了相关的关键网络技术DOM和XPath，第2.2节介绍了深度学习架构，如RNN和Transformer，第2.3节介绍了度量标准，第2.4节介绍了相关工作，如BERT和MarkupLM。</p><h2>3、方法</h2><p>在本章中，介绍了研究方法。研究过程在第3.1节中描述，数据收集过程在第3.2节中描述，最后，在第3.3节中描述了实验设计和评估框架。</p><h3>3.1 研究过程</h3><p>该论文遵循设计科学研究过程，该过程可以分为六个活动，如Ken Peffers等人在[40]中提出的。这些活动包括：问题识别和动机、解决方案目标、设计和开发、演示、评估和沟通。根据这个过程，研究人员并不被期望按顺序进行这些活动，而是取决于所选择的方法（例如，问题中心或目标中心）。<br>问题识别和动机的活动涉及具体说明研究问题并证明解决方案的价值。这可以通过获取有关问题状态和解决方案重要性的知识来实现。<br>解决方案目标指的是解决方案的定量或定性目标。这些目标通常涉及所期望的解决方案，该解决方案应更好或解决未解决的问题。在这个阶段，需要了解当前解决方案。</p><p>设计和开发涉及创建一种工件解决方案（例如，构造、模型、方法）。在创建解决方案之前，需要理解理论，决定工件的功能和架构。</p><p>演示工件在解决问题时的有效性。这可以通过实验、模拟、证明或案例研究来完成。</p><p>评估是衡量工件支持问题解决的效果。通过使用相关的度量和分析技术，可以确定工件的有效性，并作为迭代回活动3（设计和开发）的基础，以尝试在可行的情况下改进工件。</p><p>沟通是最后的活动，在其中整个过程都被记录在研究论文中。这包括问题及其重要性、工件及其效用、研究的设计以及与社区的相关性。</p><p>问题是在主机公司识别的，解决方案得到了证明。随后进行文献研究以更好地了解问题的状态和当前的解决方案。然后确定了建立在当前解决方案基础上以在新环境中解决问题的目标。工件的评估类似于相关工作中的模型。最后，在这篇论文中记录了整个过程。</p><h3>3.2 数据收集</h3><p>汽车保险数据来自几家瑞典保险公司，其中主机公司目前使用和维护手工制作的包装器。数据将采用HTML的形式，并附有JSON文件，表示由包装器提取的值的基本事实。敏感用户信息在用于模型之前被混淆。仅使用具有不为空的JSON对应文件的HTML文件。如果JSON中没有提取的值，则假定包装器失败或用户在给定网站上没有保险。</p><h3>3.3 实验设计</h3><p>实验设计遵循相关工作中使用的设计[34, 35, 37]，在k个种子站点上对模型进行微调，然后在其余的n−k个站点上进行评估（即零-shot学习）。评估指标是页面级F1分数，最终F1分数是每个k的所有排列的平均值。模型使用一个瑞典和一个英文预训练模型初始化，然后进行实验性评估和比较。</p><p>模型在深度学习的Amazon Machine Image（AMI）[41]上进行训练，实例类型为G4dn [42]，具有以下规格：1个Nvidia Tesla T4图形处理单元（GPU），8个Intel Cascade Lake虚拟中央处理单元（CPU），32GB内存。</p><h2>4、实现</h2><p>本章描述了获取数据集和修改针对性网站的开源模型的步骤。数据预处理步骤在第4.1节中介绍，MarkupLM模型的实施和修改细节在第4.2节中给出。</p><h3>4.1 数据预处理</h3><p>在使用模型训练数据之前，数据需要进行处理。从公司收到的数据包括三种类型的文件：HTML、JSON和文本（日志）文件。HTML文件包含用户的保险数据，并且仅限于包含单一保险的页面（省略包含多个保险的HTML文件）。JSON文件包含目标属性的提取数据，公司手动开发的包装器执行提取。最初的计划是使用JSON数据作为数据集的基本事实，但由于某些值是使用正则表达式进行转换的，因此与HTML中的文本不是精确匹配，这是不可能的。日志文件包含包装器整个执行流程的日志消息。幸运的是，提取的值在转换之前被转储到日志中，因此可以使用日志中的数据作为基本事实。<br>模型要提取的属性数量被限制为三家选定公司的较大部分数据中出现的五个属性：Trygg-Hansa、If和Moderna。数据集中仅使用包含所有属性的数据点。这五个属性是：保险覆盖类型、保险单号、年度保费金额、续保日期和车辆注册号。每家公司的数据点数量如表4.1所示，每个属性的统计信息如表4.2所示。</p><img width="427" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/d24d2b15-9220-40ac-ad36-81a77e4b61a5"> <img width="527" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/d4d515e7-8d6e-4d9b-81b2-474df1cea7ba"><h3>4.1.1 基本事实</h3><p>通过解析包含以JSON格式提取和未经处理的值的日志，生成了包含HTML和基本事实文件的数据集。基本事实JSON中的对象通过保险类型（即汽车保险）进行过滤。如果网页上有其他类型的保险或超过一种汽车保险，则会省略数据点。之所以这样做，是因为三家公司中有两家公司在单个网页上显示客户的所有保险，而在DOM树中没有区分。这意味着所有保险都以相同的HTML列表对象的方式列出，而且在其中没有任何特定顺序，这样模型就很难学习上下文如何区分一个保险对象和另一个保险对象。</p><h3>4.1.2 数据模糊化</h3><p>在数据集可以传输到AMI并在模型中使用之前，必须模糊化可以与特定个人关联的所有敏感数据。属性保单持有人、地址、保险单号和车辆注册号都被替换为随机生成的值。使用网站www. fejk.se生成虚假姓名、个人身份号码和地址，而使用Python脚本生成保险和车辆注册号。</p><h2>4.2 实施</h2><p>所使用的模型基于开源模型MarkupLM [37]，该模型在第2.4.5节中有描述。此模型使用Python编写，使用Pytorch机器学习框架 [43] 和提供API以轻松下载和训练SOTA预训练模型的Transformers库 [44]。模型的执行步骤如图4.1所示。<br>第一步将HTML文件打包成适当的Python数据对象，然后将它们序列化为单个文件，这是使用pickle库 [45] 完成的。第二步创建了每个HTML文件与相应基本事实之间的映射，并将其作为pickle文件分别存储在每个网站上。最后一步使用所有种子站点的排列训练和评估模型，其中在训练之前使用预训练的模型初始化。模型在多个周期（即在训练集中循环）中进行训练，最后在未被种子化的每个网站上进行评估。</p><img width="261" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/a30c1520-1efe-46c8-a94b-aefa952e42a1"><p>大部分的修改发生在数据准备和评估步骤。数据准备步骤，即HTML与基本事实之间的映射，需要修改以处理瑞典字符，并处理网站的边缘情况，其中基本事实的值并未单独位于正确的节点中，而必须使用正则表达式进行匹配。评估步骤通过更详细的记录和在每个周期后进行模型评估，引入了早停机制，以在训练损失不再降低时终止训练。<br>在对保险数据集进行微调之前，MarkupLM模型是使用预训练模型初始化的。论文中使用的两个预训练模型是MarkupLMLARGE和来自瑞典国家图书馆的瑞典BERT模型。</p><h3>4.2.1 MarkupLM-LARGE</h3><p>MarkupLM论文的作者们 [37] 也开源了两个预训练模型，MarkupLMBASE和MarkupLMLARGE。他们首先在Common Crawl（CC）数据集∗的 2400 万个英语网页上对MarkupLM模型进行了预训练，该数据集使用了原始论文作者发布的Robustly Optimized BERT pretraining Approach (RoBERTa)模型进行初始化 [46]。然后在SWDE数据集上对该模型进行了微调。MarkupLMLARGE在SWDE上的性能见表2.1。</p><h3>4.2.2 瑞典BERT</h3><p>瑞典国家图书馆（瑞典文：Kungliga biblioteket）于2020年发布了三个基于BERT和A Lite BERT (ALBERT) [47] 的预训练瑞典语言模型。这些模型是在一个18,341 MB的瑞典文语料库上进行训练的，该语料库由报纸、政府报告、法定电子存档、社交媒体评论和维基百科的文本组成。他们的预训练BERT模型名为KB-BERT，用于在微调之前初始化模型。初始化是通过使用Transformers库实现的，加载托管在AI社区站点Hugging Face [48] 上的预训练模型，该站点还负责Transformers库。表4.3显示了两个预训练模型的一些关键模型配置参数，这些参数遵循原始BERT论文的设置（除了词汇表大小）。</p><img width="434" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/05e280a7-f189-49d5-82ac-9bb5631dedfb"><h2>5、结果</h2><p>这一章介绍了模型评估的结果。以精确度、召回率和F1分数为指标，展示了两个模型的页面级结果，并详细分析了属性级结果。</p><p>两个模型的总体结果显示在表5.1中。使用KB-BERT初始化的模型在训练过程中使用一个种子站点时，最佳F1分数为41.4，当使用两个种子站点时为47.3。使用MarkupLMLARGE初始化的模型在使用一个种子站点进行训练时，最佳F1分数为80.2，使用两个种子站点时为88.9。在评估过程中变化的最佳设置分别在表5.2和表5.3中显示，对应着一个和两个种子站点。</p><img width="517" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/01b15133-6bd0-4cdc-ab57-c92db267599e"> <img width="499" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/da7cffd5-148d-4ef0-8d24-6d1e4258e5ea"><p>使用KB-BERT初始化的模型每个属性的F1分数显示在表5.4中。该模型无法学习保单号的表示，同时在处理年度保费属性时也存在一些问题。</p><img width="496" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/029d6b49-02a7-471d-8d09-a28180880c8d"><p>使用MarkupLMLARGE初始化的模型每个属性的F1分数显示在表5.5中。该模型对大多数属性学到了一个表示，但在处理保险类型属性时并不那么成功。</p><img width="497" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/13558459-3124-4480-998b-3cb114459e0d"><h2>6、讨论</h2><p>这一章将讨论第5章中提出的结果，同时也将包括对实现目标（第1.4节）和研究问题（第1.2节）的探讨。</p><h3>6.1 结果</h3><p>结果表明，尽管MarkupLMLARGE模型并不“理解”瑞典语，而是学会了HTML的一般结构，但它在预训练模型的强大性上表现出色。这一事实事后看来并不令人惊讶，因为选择的五个属性中有四个不特定于瑞典语。</p><p>使用MarkupLMLARGE初始化的模型在三个属性上表现非常好：保险单号、续保日期和车辆注册号，在使用一个和两个种子站点时，F1分数均超过94%。保险单号具有特定格式（例如123 456 789、AB00123456.2.3和123456-78），每家公司有时甚至有几种格式。续保日期始终以YYYY-MM-DD的格式呈现，而车辆注册号有两种格式之一，即ABC123或ABC12D。年度保费这个属性的得分相对较低，这很可能是因为它在不同公司之间的格式不同，有时包含瑞典语词汇（例如“年”这个瑞典词）。然而，即使对于只包含瑞典语词汇的保险类型属性，该模型在某种程度上也成功地学到了，特别是在将种子站点数量从一个增加到两个时。</p><p>与MarkupLMLARGE初始化的模型相比，使用KB-BERT初始化的模型表现相对较差。使用一个和两个种子站点时，得分最高的属性是覆盖类型和续保日期，F1分数均超过71%。覆盖类型通常是“halvförsäkring”、“helförsäkring”、“trafikförsäkring”或其变体中的一个词，这是模型在这方面优于MarkupLMLARGE初始化的模型的唯一属性。令人惊讶的是，该模型无法学习保险单号的表示，对于使用一个和两个种子站点时的F1分数均低于4%。这可能是由于不同公司之间的格式不一致，再加上一些格式包含标点符号，这可能使学习变得更加困难，因为BERT将标点符号视为输入序列中“句子”的分隔符。</p><p>另一个方面是，瑞典BERT使用了较小的BERTBASE的参数，而MarkupLMLARGE使用了较大的BERTLARGE，它们在隐藏层的数量、隐藏层的大小以及每个隐藏层的注意头的数量上存在差异（如表4.3所示）。然而，在原始的BERT论文[29]中，BERTLARGE在GLUE基准上的得分约高出BERTBASE约3%，而在使用5个种子站点时，MarkupLMLARGE在SWDE数据集上的得分比MarkupLMBASE高出约1.5%。这应该表明，性能的这种大差异不能仅通过网络大小的差异来解释。</p><p>在表5.2和表5.3中显示的设置是为了寻找最佳精度而进行的调整的设置。在表现最佳的运行之间，最常见的批量大小为2。这似乎是合理的，因为数据集很小，数据集中最大的公司有100个数据点，而最小的公司只有23个。用于上下文的前面节点的最佳数量是4。训练时间的巨大差异可以通过两个预训练模型之间的参数差异（主要是层数和层大小）来解释。作为参考，BERT论文的作者使用4个云张量处理单元（TPU）[49]对BERTBASE进行了训练，分别对BERTLARGE进行了16个云TPU的训练，分别进行了4天的训练。</p><h3>6.2 指标选择</h3><p>在网络数据提取领域存在多种度量标准，然而，本论文专注于三个准确性指标：召回率、精确度和F分数。尽管这些指标并非完美[50]，但它们在机器学习评估中被广泛使用。由于大多数相关工作都在使用这些指标，尽管它们在处理负面例子时表现不佳，但它们被选择了。F分数的beta值被选择为1（即F1分数），因为没有（通过主机公司）明确要求将精确度优先于召回率，反之亦然。</p><h3>6.3 达到目标</h3><p>在第1.4节中提到的四个子目标是：数据集获取、模型识别、模型修改和模型评估。根据结果，可以说这四个子目标都已经实现。</p><p>收集到的数据比预期的要小，无论是从公司和网站的数量上还是从每家公司和网站的数据点数量上。然而，尽管数据集相对较小，MarkupLMLARGE模型取得了相对较好的分数，展示了预训练模型的强大性能。</p><p>模型的识别是成功的，并导致了SOTA模型MarkupLM的产生，尽管最初选择的是SimpDOM（第2.4.4节），这在第7章中作为一个局限性进一步讨论。模型修改按照最初的计划使用了一个预训练的瑞典BERT</p><p>模型，尽管其性能不及MarkupLM作者发布的预训练模型。最后，该模型使用了两个不同的预训练模型，在使用一个和两个种子站点时进行了评估。</p><h3>6.4 回答研究问题</h3><p>最初提出的研究问题是：</p><p>一个带有监督学习的网络数据提取模型在从未见过的瑞典保险网站中提取信息的能力如何？</p><p>最初的假设是这样的系统必须对瑞典语有一个良好的表示才能有效，因此需要使用在瑞典语上进行预训练的语言模型进行探索。然而，结果表明，这种对语言的依赖性表示不一定是必要的，至少当大多数属性不是语言特定的或者在其上下文中不被语言特定的文本包围时。此外，即使对于语言特定的属性，例如保险类型，也是在既预训练于英语语言又预训练于网页的模型表现得更好，而后者仅在瑞典语上进行了预训练。</p><p>对研究问题的回答是这样的模型实际上在瑞典保险网站上表现良好，达到了与在SWDE数据集上的SOTA模型相似的结果（如表2.1所示）。</p><h2>7、结论与未来工作</h2><h3>7.1 结论</h3><p>最初的假设认为在瑞典网站上，以英语数据为基础的模型性能较差。然而，结果表明，如果属性不包含特殊的瑞典字符，这样的模型表现良好。这种模型的学习强调HTML文档结构，特别是当值嵌入在结构化格式（如表格）中时。虽然没有达到100%的准确性，但在手动创建的包装器因站点故障或HTML更改而失败的情景下，该模型可能会很有价值。</p><h3>7.2 限制</h3><p>显著的限制包括有限的可用数据量，导致较少的候选公司可供论文使用。数据的倾斜和耗时的预处理影响了模型的探索。尝试复制 SimpDOM 的努力没有成功，妨碍了与 MarkupLM 的潜在比较。</p><h3>7.3 未来工作</h3><p><strong>尚未完成的工作</strong></p><ul><li>探索提取不可靠出现在大多数客户数据中的属性。</li><li>调查在网页上显示多个保险政策的情况。</li><li>为潜在的准确性提升调整学习率和丢失概率等超参数。</li></ul><p><strong>下一个明显需要做的事</strong></p><ul><li>评估在其他行业培训模型的好处。</li><li>探索少样本学习，对目标网站进行更多的手动标记。</li><li>考虑混合方法，利用开源模型提取特定属性。</li></ul><h3>7.4 反思</h3><p>从经济角度来看，所探讨的模型减少了在相同行业内设置数据提取的手动工作，并减少了对覆盖的网站进行的维护。与模型培训相关的计算成本可以通过使用开源预训练模型来缓解。伦理考虑涉及根据政府政策和法规处理客户数据。敏感数据的混淆是一种方法，但自动确定哪些数据是敏感并需要混淆是本工作范围之外的问题。</p><p>引用：</p><ul><li>[1] R. Kosala and H. Blockeel, “Web mining research: a survey,” ACM SIGKDD Explorations Newsletter, vol. 2, no. 1, pp. 1–15, Jun. 2000. doi: 10.1145/360402.360406. [Online]. Available: <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/360402.360406">https://dl.acm.org/doi/10.1145/360402.360406</a> [Page 1.]</li><li>[2] J. Wang and F. H. Lochovsky, “Data extraction and label assignment for web databases,” in Proceedings of the twelfth international conference on World Wide Web - WWW ’03. Budapest, Hungary: ACM Press, 2003. doi: 10.1145/775152.775179. ISBN 978-1-58113-680-7 p. 187. [Online]. Available: <a target="_blank" rel="noopener" href="http://portal.acm.org/citation.cfm?doid=775152.775179">http://portal.acm.org/citation.cfm?doid=775152.775179</a> [Page 1.]</li><li>[3] A. Troestler and H. P. Lee, “The adaptation and standardization on websites of international companies : Analysis and comparison from websites of United States, Germany and Taiwan,” Ph.D. dissertation, Linköping University, 2007. [Online]. Available: <a target="_blank" rel="noopener" href="http://urn.kb.se/resolve?urn=urn:nbn:se:liu:diva-9801">http://urn.kb.se/resolve?urn=urn:nbn:se:liu:diva-9801</a> [Page 1.]</li><li>[4] S. Flesca, G. Manco, E. Masciari, E. Rende, and A. Tagarelli, “Web wrapper induction: a brief survey,” AI Communications, vol. 17, no. 2, pp. 57–61, Apr. 2004. [Online]. Available: <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.5555/1218702.1218707">https://dl.acm.org/doi/10.5555/1218702.1218707</a> [Page 2.]</li><li>[5] “Document Object Model (DOM),” Dec. 2021. [Online]. Available: <a target="_blank" rel="noopener" href="https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model">https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model</a> [Pages 2 and 5.]</li><li>[6] K. Lerman, S. N. Minton, and C. A. Knoblock, “Wrapper Maintenance:A Machine Learning Approach,” Journal of Artificial Intelligence Research, vol. 18, pp. 149–181, Feb. 2003. doi: 10.1613/jair.1145. [Online]. Available: <a target="_blank" rel="noopener" href="https://jair.org/index.php/jair/article/view/10325">https://jair.org/index.php/jair/article/view/10325</a> [Page 2.]</li><li>[7] Hevner, March, Park, and Ram, “Design Science in Information Systems Research,” MIS Quarterly, vol. 28, no. 1, p. 75, 2004. doi: 10.2307/25148625. [Online]. Available: <a target="_blank" rel="noopener" href="https://www.jstor.org/stable/10.2307/25148625">https://www.jstor.org/stable/10.2307/25148625</a> [Page 3.]</li><li>[8] R. Baumgartner, W. Gatterbauer, and G. Gottlob, “Web Data Extraction System,” in Encyclopedia of Database Systems, L. Liu and M. T.Özsu, Eds. Boston, MA: Springer US, 2009, pp. 3465–3471. ISBN978-0-387-39940-9. [Online]. Available: <a target="_blank" rel="noopener" href="http://link.springer.com/10.1007/978-0-387-39940-9_1154">http://link.springer.com/10.1007/978-0-387-39940-9_1154</a> [Page 5.]</li><li>[9] “XPath,” Jan. 2022. [Online]. Available: <a target="_blank" rel="noopener" href="https://developer.mozilla.org/en-US/docs/Web/XPath">https://developer.mozilla.org/en-US/docs/Web/XPath</a> [Page 6.]</li><li>[10] “Introducing JSON.” [Online]. Available: <a target="_blank" rel="noopener" href="https://json.org/json-en.html">https://json.org/json-en.html</a> [Page 6.]</li><li>[11] “What is Deep Learning?” May 2020. [Online]. Available: <a target="_blank" rel="noopener" href="https://www.ibm.com/cloud/learn/deep-learning">https://www.ibm.com/cloud/learn/deep-learning</a> [Page 7.]</li><li>[12] J. Patterson and A. Gibson, Deep learning: a practitioner’s approach, 1st ed. Sebastopol, CA: O’Reilly, 2017. ISBN 978-1-4919-1425-0 [Pages 7, 8, and 9.]</li><li>[13] D. Hendrycks and K. Gimpel, “Gaussian Error Linear Units (GELUs),” arXiv:1606.08415 [cs], Jul. 2020. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1606.08415">http://arxiv.org/abs/1606.08415</a> [Page 9.]</li><li>[14] S. Hochreiter and J. Schmidhuber, “Long Short-Term Memory,” Neural Computation, vol. 9, no. 8, pp. 1735–1780, Nov. 1997. doi:10.1162/neco.1997.9.8.1735. [Online]. Available: <a target="_blank" rel="noopener" href="https://direct.mit.edu/neco/article/9/8/1735-1780/6109">https://direct.mit.edu/neco/article/9/8/1735-1780/6109</a> [Page 9.]</li><li>[15] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, ff. Kaiser, and I. Polosukhin, “Attention is All you Need,” in Advances in Neural Information Processing Systems, I. Guyon, U. V.Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, Eds., vol. 30. Curran Associates, Inc., 2017. [Online]. Available: <a target="_blank" rel="noopener" href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a> [Page 10.]</li><li>[16] X. Qiu, T. Sun, Y. Xu, Y. Shao, N. Dai, and X. Huang, “Pretrained models for natural language processing: A survey,” ScienceChina Technological Sciences, vol. 63, no. 10, pp. 1872–1897, Oct. 2020. doi: 10.1007/s11431-020-1647-3. [Online]. Available: <a target="_blank" rel="noopener" href="https://link.springer.com/10.1007/s11431-020-1647-3">https://link.springer.com/10.1007/s11431-020-1647-3</a> [Page 10.]</li><li>[17] K. Weiss, T. M. Khoshgoftaar, and D. Wang, “A survey of transfer learning,” Journal of Big Data, vol. 3, no. 1, p. 9, Dec. 2016. doi: 10.1186/s40537-016-0043-6. [Online]. Available: <a target="_blank" rel="noopener" href="http://journalofbigdata.springeropen.com/articles/10.1186/s40537-016-0043-6">http://journalofbigdata.springeropen.com/articles/10.1186/s40537-016-0043-6</a> [Page 10.]</li><li>[18] X. Han, Z. Zhang, N. Ding, Y. Gu, X. Liu, Y. Huo, J. Qiu, Y. Yao, A. Zhang, L. Zhang, W. Han, M. Huang, Q. Jin, Y. Lan, Y. Liu, Z. Liu,Z. Lu, X. Qiu, R. Song, J. Tang, J.-R. Wen, J. Yuan, W. X. Zhao, and J. Zhu, “Pre-trained models: Past, present and future,” AI Open, vol. 2, pp. 225–250, 2021. doi: 10.1016/j.aiopen.2021.08.002. [Online]. Available: <a target="_blank" rel="noopener" href="https://linkinghub.elsevier.com/retrieve/pii/S2666651021000231">https://linkinghub.elsevier.com/retrieve/pii/S2666651021000231</a> [Page 10.]</li><li>[19] G. Bonaccorso, Machine Learning Algorithms, 2nd ed. Packt, 2018. ISBN 978-1-78934-799-9 [Page 11.]</li><li>[20] M. Buckland and F. Gey, “The relationship between Recall and Precision,” Journal of the American Society for Information Science, vol. 45, no. 1, pp. 12–19, 1994. [Page 11.]</li><li>[21] E. Ferrara, P. De Meo, G. Fiumara, and R. Baumgartner, “Web data extraction, applications and techniques: A survey,” Knowledge-Based Systems, vol. 70, pp. 301–323, Nov. 2014. doi: 10.1016/j.knosys.2014.07.007. [Online]. Available: <a target="_blank" rel="noopener" href="https://linkinghub.elsevier.com/retrieve/pii/S0950705114002640">https://linkinghub.elsevier.com/retrieve/pii/S0950705114002640</a> [Page 12.]</li><li>[22] S. M. Selkow, “The tree-to-tree editing problem,” Information Processing Letters, vol. 6, no. 6, pp. 184–186, Dec. 1977. doi: 10.1016/0020-0190(77)90064-3. [Online]. Available: <a target="_blank" rel="noopener" href="https://linkinghub.elsevier.com/retrieve/pii/0020019077900643">https://linkinghub.elsevier.com/retrieve/pii/0020019077900643</a> [Page 12.]</li><li>[23] P. Kilpeläinen, “Tree matching problems with applications to structured text databases,” Ph.D dissertation, University of Helsinki, Department of Computer Science, Helsinki, Finland, Nov. 1992. [Page 12.]</li><li>[24] N. Kushmerick, D. S. Weld, and R. B. Doorenbos, “Wrapper Induction for Information Extraction,” in IJCAI, 1997. [Page 12.]</li><li>[25] R. Mooney, “Relational learning of pattern-match rules for information extraction,” in Proceedings of the sixteenth national conference on artificial intelligence, vol. 328, 1999, p. 334. [Page 12.]</li><li>[26] S. Soderland, “Learning information extraction rules for semi-structured and free text,” Machine learning, vol. 34, no. 1, pp. 233–272, 1999, publisher: Springer. [Page 12.]</li><li>[27] I. Muslea and others, “Extraction patterns for information extraction tasks: A survey,” in The AAAI-99 workshop on machine learning for information extraction, vol. 2. Orlando Florida, 1999, issue: 2. [Page 13.]</li><li>[28] S. Zhang and K. Balog, “Web Table Extraction, Retrieval, and Augmentation: A Survey,” ACM Transactions on Intelligent Systems and Technology, vol. 11, no. 2, pp. 1–35, Apr. 2020. doi: 10.1145/3372117. [Online]. Available: <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3372117">https://dl.acm.org/doi/10.1145/3372117</a> [Page 13.]</li><li>[29] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,” arXiv:1810.04805 [cs], May 2019. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1810.04805">http://arxiv.org/abs/1810.04805</a> [Pages 15, 17, and 36.]</li><li>[30] Y. Zhu, R. Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba, and S. Fidler, “Aligning books and movies: Towards story-like visual explanations by watching movies and reading books,” in Proceedings of the IEEE international conference on computer vision, 2015, pp. 19–27.[Page 16.]</li><li>[31] A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman, “GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding,” arXiv:1804.07461 [cs], Feb. 2019. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1804.07461">http://arxiv.org/abs/1804.07461</a> [Page 16.]</li><li>[32] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang, “SQuAD: 100,000+Questions for Machine Comprehension of Text,” arXiv:1606.05250 [cs], Oct. 2016. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1606.05250[Page">http://arxiv.org/abs/1606.05250[Page</a> 16.]</li><li>[33] R. Zellers, Y. Bisk, R. Schwartz, and Y. Choi, “SWAG: A LargeScale Adversarial Dataset for Grounded Commonsense Inference,” arXiv:1808.05326 [cs], Aug. 2018. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1808.05326">http://arxiv.org/abs/1808.05326</a> [Page 16.]</li><li>[34] Y. Zhou, Y. Sheng, N. Vo, N. Edmonds, and S. Tata, “Simplified DOM Trees for Transferable Attribute Extraction from the Web,”arXiv:2101.02415 [cs], Jan. 2021. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2101.02415">http://arxiv.org/abs/2101.02415</a> [Pages 16, 18, 19, 22, and 41.]</li><li>[35] Q. Hao, R. Cai, Y. Pang, and L. Zhang, “From one tree to a forest: a unified solution for structured web data extraction,” in Proceedings of the34th international ACM SIGIR conference on Research and development in Information - SIGIR ’11. Beijing, China: ACM Press, 2011. doi:10.1145/2009916.2010020. ISBN 978-1-4503-0757-4 p. 775. [Online]. Available: <a target="_blank" rel="noopener" href="http://portal.acm.org/citation.cfm?doid=2009916.2010020">http://portal.acm.org/citation.cfm?doid=2009916.2010020</a> [Pages 17, 18, 22, and 40.]</li><li>[36] J. Pennington, R. Socher, and C. Manning, “Glove: Global Vectors for Word Representation,” in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Doha, Qatar: Association for Computational Linguistics, 2014. doi: 10.3115/v1/D14-1162 pp. 1532–1543. [Online]. Available: <a target="_blank" rel="noopener" href="http://aclweb.org/anthology/D14-1162">http://aclweb.org/anthology/D14-1162</a> [Page 17.]</li><li>[37] J. Li, Y. Xu, L. Cui, and F. Wei, “MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding,”arXiv:2110.08518 [cs], Oct. 2021. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2110.08518">http://arxiv.org/abs/2110.08518</a> [Pages 17, 22, 27, and 29.]</li><li>[38] B. Y. Lin, Y. Sheng, N. Vo, and S. Tata, “FreeDOM: A Transferable Neural Architecture for Structured Information Extraction on Web Documents,” in Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. Virtual Event CA USA: ACM, Aug. 2020. doi: 10.1145/3394486.3403153. ISBN 978-1-4503-7998-4 pp. 1092–1102. [Online]. Available: <a target="_blank" rel="noopener" href="https://dl.acm.org/doi/10.1145/3394486.3403153">https://dl.acm.org/doi/10.1145/3394486.3403153</a> [Page 18.]</li><li>[39] X. Deng, P. Shiralkar, C. Lockard, B. Huang, and H. Sun, “DOMLM: Learning Generalizable Representations for HTML Documents,” arXiv:2201.10608 [cs], Jan. 2022. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2201.10608">http://arxiv.org/abs/2201.10608</a> [Page 18.]</li><li>[40] K. Peffers, T. Tuunanen, C. E. Gengler, M. Rossi, W. Hui, V. Virtanen, and J. Bragge, “Design Science Research Process: A Model for Producing and Presenting Information Systems Research,” arXiv:2006.02763 [cs], Jun. 2020. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2006.02763">http://arxiv.org/abs/2006.02763</a> [Page 21.]</li><li>[41] “AWS Deep Learning AMIs.” [Online]. Available: <a target="_blank" rel="noopener" href="https://aws.amazon.com/machine-learning/amis/">https://aws.amazon.com/machine-learning/amis/</a> [Page 23.]</li><li>[42] “Amazon EC2 G4 Instances.” [Online]. Available: <a target="_blank" rel="noopener" href="https://aws.amazon.com/ec2/instance-types/g4/">https://aws.amazon.com/ec2/instance-types/g4/</a> [Page 23.]</li><li>[43] “Pytorch.” [Online]. Available: <a target="_blank" rel="noopener" href="https://pytorch.org/">https://pytorch.org/</a> [Page 27.]</li><li>[44] “Transformers.” [Online]. Available: <a target="_blank" rel="noopener" href="https://huggingface.co/transformers">https://huggingface.co/transformers</a> [Page 27.]</li><li>[45] “pickle — Python object serialization,” Apr. 2022. [Online]. Available: <a target="_blank" rel="noopener" href="https://docs.python.org/3/library/pickle.html">https://docs.python.org/3/library/pickle.html</a> [Page 27.]</li><li>[46] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, “RoBERTa: A Robustly Optimized BERT Pretraining Approach,” arXiv:1907.11692 [cs], Jul. 2019. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/1907.11692">http://arxiv.org/abs/1907.11692</a> [Page 29.]</li><li>[47] M. Malmsten, L. Börjeson, and C. Haffenden, “Playing with Words at the National Library of Sweden – Making a Swedish BERT,” arXiv:2007.01658 [cs], Jul. 2020. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2007.01658">http://arxiv.org/abs/2007.01658</a> [Page 29.]</li><li>[48] “The AI community building the future.” [Online]. Available: <a target="_blank" rel="noopener" href="https://huggingface.co/">https://huggingface.co/</a> [Page 29.]</li><li>[49] “Cloud TPU.” [Online]. Available: <a target="_blank" rel="noopener" href="https://cloud.google.com/tpu/">https://cloud.google.com/tpu/</a> [Page 36.]</li><li>[50] D. M. W. Powers, “Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation,” arXiv:2010.16061 [cs, stat], Oct. 2020. [Online]. Available: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2010.16061">http://arxiv.org/abs/2010.16061</a> [Page 36.]</li></ul></div><div class="article-copyright"><p>本作品采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by/4.0/">知识共享署名 4.0 国际许可协议</a> 进行许可。</p><p>转载时请注明<a href="https://blog.hufeifei.cn/2024/01/paper/MarkupLM-web-extract/">原文链接</a>：https://blog.hufeifei.cn/2024/01/paper/MarkupLM-web-extract/</p></div><footer class="article-footer"><div class="article-tag"><ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Web%E6%8C%96%E6%8E%98/" rel="tag">Web挖掘</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E7%AE%97%E6%B3%95/" rel="tag">算法</a></li></ul></div></footer></div><div id="article-reward"><i class="iconfont ic-money"></i><div>鼓励一下</div><table><thead><tr><th style="text-align:center">支付宝</th><th style="text-align:center">微信</th></tr></thead><tbody><tr><td style="text-align:center"><img width="150" src="https://www.hufeifei.cn/reward-img/alipay.jpg"></td><td style="text-align:center"><img width="135" src="https://www.hufeifei.cn/reward-img/wechat.jpg"></td></tr></tbody></table></div><nav id="article-nav"><a class="article-nav-link-wrap" href="/2024/01/Net/x-forward-for/" id="article-nav-newer"><strong class="article-nav-caption">Newer</strong><div class="article-nav-title">“真”的IP真的是真的吗？</div></a><a class="article-nav-link-wrap" href="/2023/09/economic/tax-reform/" id="article-nav-older"><strong class="article-nav-caption">Older</strong><div class="article-nav-title">直接税改革——王朝周期律的胜负手</div></a></nav></article><div id="waline-comments"></div><script type="module">import { init } from 'https://unpkg.com/@waline/client@v3/dist/waline.js';init({"el":"#waline-comments","pageview":true,"enable":true,"serverURL":"https://api.waline.blog.hufeifei.cn","avatar":"mp","pageSize":10,"lang":"zh-cn","placeholder":"Just go go","visitor":true,"recordIP":true,"requiredFields":["nick"]});</script></section><aside id="sidebar"><div class="widget-wrap"><h3 class="widget-title">关注微信公众号</h3><div class="widget wechat"><img src="//www.hufeifei.cn/wechat-public-account.jpg"></div></div><div class="widget-wrap"><h3 class="widget-title">Categories</h3><div class="widget"><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Android/">Android</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/C-C/">C&C++</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/J2EE/">J2EE</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/JAVA/">JAVA</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Linux%E8%BF%90%E7%BB%B4/">Linux运维</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Ruby/">Ruby</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Rust/">Rust</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/Windows/">Windows</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E4%BB%A3%E7%A0%81%E6%97%A5%E5%B8%B8/">代码日常</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%88%86%E5%B8%83%E5%BC%8F/">分布式</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%89%8D%E7%AB%AF/">前端</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%95%86%E4%B8%9A/">商业</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/">数据库</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/">数据结构与算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%94%9F%E6%B4%BB/">生活</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%AE%97%E6%B3%95/">算法</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BB%8F%E6%B5%8E%E4%B8%8E%E9%87%91%E8%9E%8D/">经济与金融</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%BD%91%E7%BB%9C/">网络</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/">计算机组成</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E9%9D%A2%E8%AF%95/">面试</a></li></ul></div></div><div class="widget-wrap"><h3 class="widget-title">Tag Cloud</h3><div class="widget tagcloud"><a href="/tags/AVL/" style="font-size:11.11px">AVL</a> <a href="/tags/Alibaba/" style="font-size:14.44px">Alibaba</a> <a href="/tags/Android/" style="font-size:18.89px">Android</a> <a href="/tags/B-Tree/" style="font-size:12.22px">B-Tree</a> <a href="/tags/BKD-Tree/" style="font-size:10px">BKD-Tree</a> <a href="/tags/BST/" style="font-size:10px">BST</a> <a href="/tags/BigData/" style="font-size:11.11px">BigData</a> <a href="/tags/C/" style="font-size:14.44px">C</a> <a href="/tags/CGlib/" style="font-size:10px">CGlib</a> <a href="/tags/CS/" style="font-size:11.11px">CS</a> <a href="/tags/Canal/" style="font-size:10px">Canal</a> <a href="/tags/ClassLoader/" style="font-size:10px">ClassLoader</a> <a href="/tags/ClickHouse/" style="font-size:10px">ClickHouse</a> <a href="/tags/Config/" style="font-size:10px">Config</a> <a href="/tags/Cryptography/" style="font-size:10px">Cryptography</a> <a href="/tags/DB/" style="font-size:20px">DB</a> <a href="/tags/Dapper/" style="font-size:10px">Dapper</a> <a href="/tags/DataStructure/" style="font-size:14.44px">DataStructure</a> <a href="/tags/Debezium/" style="font-size:10px">Debezium</a> <a href="/tags/Diamond/" style="font-size:10px">Diamond</a> <a href="/tags/Distributed/" style="font-size:13.33px">Distributed</a> <a href="/tags/ElasticSearch/" style="font-size:10px">ElasticSearch</a> <a href="/tags/Encoding/" style="font-size:10px">Encoding</a> <a href="/tags/FastJson/" style="font-size:10px">FastJson</a> <a href="/tags/File/" style="font-size:10px">File</a> <a href="/tags/FlowMarketing/" style="font-size:10px">FlowMarketing</a> <a href="/tags/Grade/" style="font-size:10px">Grade</a> <a href="/tags/Gson/" style="font-size:10px">Gson</a> <a href="/tags/HTTP/" style="font-size:10px">HTTP</a> <a href="/tags/Handler/" style="font-size:10px">Handler</a> <a href="/tags/Hanlder/" style="font-size:10px">Hanlder</a> <a href="/tags/Hessian/" style="font-size:10px">Hessian</a> <a href="/tags/IO-Multiplex/" style="font-size:10px">IO-Multiplex</a> <a href="/tags/JAVA/" style="font-size:18.89px">JAVA</a> <a href="/tags/JVM/" style="font-size:10px">JVM</a> <a href="/tags/KD-Tree/" style="font-size:10px">KD-Tree</a> <a href="/tags/KDB-Tree/" style="font-size:10px">KDB-Tree</a> <a href="/tags/Kafka/" style="font-size:10px">Kafka</a> <a href="/tags/Kubernetes/" style="font-size:10px">Kubernetes</a> <a href="/tags/LSM-Tree/" style="font-size:11.11px">LSM-Tree</a> <a href="/tags/Linux/" style="font-size:17.78px">Linux</a> <a href="/tags/Lock/" style="font-size:11.11px">Lock</a> <a href="/tags/Lucene/" style="font-size:10px">Lucene</a> <a href="/tags/MQ/" style="font-size:10px">MQ</a> <a href="/tags/Macro/" style="font-size:10px">Macro</a> <a href="/tags/Magisk/" style="font-size:10px">Magisk</a> <a href="/tags/MultiDex/" style="font-size:10px">MultiDex</a> <a href="/tags/MySQL/" style="font-size:17.78px">MySQL</a> <a href="/tags/NIO/" style="font-size:10px">NIO</a> <a href="/tags/Nginx/" style="font-size:11.11px">Nginx</a> <a href="/tags/OGNL/" style="font-size:10px">OGNL</a> <a href="/tags/OpenResty/" style="font-size:10px">OpenResty</a> <a href="/tags/OpenTelemetry/" style="font-size:10px">OpenTelemetry</a> <a href="/tags/Oracle/" style="font-size:10px">Oracle</a> <a href="/tags/PostgreSQL/" style="font-size:10px">PostgreSQL</a> <a href="/tags/RB-Tree/" style="font-size:10px">RB-Tree</a> <a href="/tags/Redis/" style="font-size:10px">Redis</a> <a href="/tags/Rust/" style="font-size:10px">Rust</a> <a href="/tags/Sharding/" style="font-size:10px">Sharding</a> <a href="/tags/SpringBoot/" style="font-size:10px">SpringBoot</a> <a href="/tags/SpringCloud/" style="font-size:10px">SpringCloud</a> <a href="/tags/SpringCloudConfig/" style="font-size:10px">SpringCloudConfig</a> <a href="/tags/Sqlite/" style="font-size:10px">Sqlite</a> <a href="/tags/SurfaceView/" style="font-size:10px">SurfaceView</a> <a href="/tags/VSCode/" style="font-size:11.11px">VSCode</a> <a href="/tags/WebFlux/" style="font-size:10px">WebFlux</a> <a href="/tags/WebPush/" style="font-size:10px">WebPush</a> <a href="/tags/Web%E6%8C%96%E6%8E%98/" style="font-size:11.11px">Web挖掘</a> <a href="/tags/awk/" style="font-size:10px">awk</a> <a href="/tags/bit-hack/" style="font-size:10px">bit-hack</a> <a href="/tags/cheat-sheet/" style="font-size:10px">cheat sheet</a> <a href="/tags/curl/" style="font-size:10px">curl</a> <a href="/tags/epoll/" style="font-size:10px">epoll</a> <a href="/tags/gRPC/" style="font-size:10px">gRPC</a> <a href="/tags/grep/" style="font-size:10px">grep</a> <a href="/tags/kqueue/" style="font-size:10px">kqueue</a> <a href="/tags/libev/" style="font-size:10px">libev</a> <a href="/tags/libevent/" style="font-size:10px">libevent</a> <a href="/tags/libuv/" style="font-size:10px">libuv</a> <a href="/tags/metaq/" style="font-size:10px">metaq</a> <a href="/tags/poll/" style="font-size:10px">poll</a> <a href="/tags/sed/" style="font-size:10px">sed</a> <a href="/tags/select/" style="font-size:10px">select</a> <a href="/tags/ssh/" style="font-size:10px">ssh</a> <a href="/tags/%E5%8E%86%E5%8F%B2/" style="font-size:10px">历史</a> <a href="/tags/%E5%95%86%E4%B8%9A/" style="font-size:10px">商业</a> <a href="/tags/%E5%BF%83%E7%90%86%E5%AD%A6/" style="font-size:10px">心理学</a> <a href="/tags/%E7%94%9F%E6%B4%BB/" style="font-size:11.11px">生活</a> <a href="/tags/%E7%A8%8E%E6%94%B6/" style="font-size:10px">税收</a> <a href="/tags/%E7%AE%97%E6%B3%95/" style="font-size:14.44px">算法</a> <a href="/tags/%E7%BB%8F%E6%B5%8E/" style="font-size:15.56px">经济</a> <a href="/tags/%E8%90%A5%E9%94%80/" style="font-size:10px">营销</a> <a href="/tags/%E8%B4%A7%E5%B8%81/" style="font-size:10px">货币</a> <a href="/tags/%E9%9A%8F%E7%AC%94/" style="font-size:16.67px">随笔</a></div></div><div class="widget-wrap"><h3 class="widget-title">Recent Posts</h3><div class="widget"><ul><li><a href="/2024/04/economic/value-added-tax/">增值税与贫富差距</a></li><li><a href="/2024/01/Net/x-forward-for/">“真”的IP真的是真的吗？</a></li><li><a href="/2024/01/paper/MarkupLM-web-extract/">【译】基于MarkupLM的web数据抽取</a></li><li><a href="/2023/09/economic/tax-reform/">直接税改革——王朝周期律的胜负手</a></li><li><a href="/2023/09/Rust/macro-rules-learning/">Rust中的宏</a></li></ul></div></div><div class="widget-wrap"><h3 class="widget-title">网站运营不易</h3><div class="ads-wrapper"><div class="google_ads"><ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-7111912103882824" data-ad-slot="8429272980" data-ad-format="auto" data-full-width-responsive="true"></ins><script>(adsbygoogle=window.adsbygoogle||[]).push({})</script></div></div></div></aside></div><footer id="footer"><div class="outer"><div class="inner" id="footer-info"><p><a href="https://beian.miit.gov.cn/" target="_blank">赣ICP备17009276号</a><i class="far fa-copyright"></i>2016 ~ 2024 胡飞飞</p><p>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a><i class="fas fa-angle-right"></i>Theme by <a target="_blank" rel="noopener" href="https://github.com/holmofy/hexo-theme-paper">paper</a></p></div></div></footer></div><nav id="mobile-nav"><a class="mobile-nav-link" href="//www.hufeifei.cn">主页</a><a class="mobile-nav-link" href="/">博客</a><a class="mobile-nav-link" href="/archives">归档</a><a class="mobile-nav-link" target="_blank" rel="noopener" href="//algo.hufeifei.cn">算法</a><a class="mobile-nav-link" href="/book">书籍</a><a class="mobile-nav-link" href="/github">Github</a></nav><script src="//cdnjs.loli.net/ajax/libs/jquery/3.0.0/jquery.min.js"></script><link rel="stylesheet" href="//cdnjs.loli.net/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css"><script type="text/javascript" src="//cdnjs.loli.net/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js"></script><script type="text/javascript" src="/js/script.js"></script></div><script>
  $(document).ready(function() {
    $('figure.codeblock').find('.tab').click(function() {
        var $codeblock = $(this).parent().parent().parent();
        var $tab = $(this);
        // remove "active" css class on all tabs
        $tab.siblings().removeClass('active');
        // add "active" css class on the clicked tab
        $tab.addClass('active');
        // hide all tab contents
        $codeblock.find('.highlight').hide();
        // show only the right one
        $codeblock.find('.highlight.' + $tab.text()).show();
    });
  });
  </script><script>(function (w, d, s, id) {
            if (typeof (w.webpushr) !== 'undefined') return; w.webpushr = w.webpushr || function () { (w.webpushr.q = w.webpushr.q || []).push(arguments) }; var js, fjs = d.getElementsByTagName(s)[0]; js = d.createElement(s); js.id = id; js.async = 1; js.src = "https://cdn.webpushr.com/app.min.js";fjs.parentNode.appendChild(js);}(window, document, 'script', 'webpushr-jssdk'));webpushr('setup', { 'key': 'BPJzNs1QEtbYa3Bn0gMAQHBAzX3Jm71llGUKHTkKEUs3D9xiDYZ0DWJ3S9sfCAAJHxXEoBkUANFyONjeIlgrJUo'' });</script></body></html>
<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>holmofy</title>
  <icon>https://www.gravatar.com/avatar/438ae659a0ab370dfc751948582a82dc</icon>
  
  <link href="https://blog.hufeifei.cn/atom.xml" rel="self"/>
  
  <link href="https://blog.hufeifei.cn/"/>
  <updated>2024-05-03T05:17:06.703Z</updated>
  <id>https://blog.hufeifei.cn/</id>
  
  <author>
    <name>胡飞飞</name>
    <email>1938304905@qq.com</email>
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>增值税与贫富差距</title>
    <link href="https://blog.hufeifei.cn/2024/04/economic/value-added-tax/"/>
    <id>https://blog.hufeifei.cn/2024/04/economic/value-added-tax/</id>
    <published>2024-04-30T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.703Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>在中国，有18个税种(不含已经取消的营业税)，但最核心的绝对是增值税。<a href="https://www.gov.cn/xinwen/2022-01/29/content_5671104.htm">2021年财政收支情况</a>显示增值税收入63519亿元，占全国税收收入36.7%，而第二位的企业所得税42041亿元，占比只有24.3%。尤其是<a href="https://www.gov.cn/gongbao/content/2016/content_5088782.htm">2012到2016年执行营改增(取消营业税改为增值税)</a>之后，增值税进一步扩大了管辖范围。可以说在现在的中国增值税独霸天下，堪称万税之王。</p><p><img src="https://iknow-pic.cdn.bcebos.com/7af40ad162d9f2d3311ba193b9ec8a136327cc40" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer"></p><p>税收作为继市场分配后的政府二次分配手段，对于调节贫富差距有重要作用，但增值税作为间接税的一种，反而加重了贫富分化。为什么政府这么喜欢增值税，那是因为增值税的特性决定的。中国向来喜欢间接税，不喜欢收取直接税，比如由于<a href="https://www.moa.gov.cn/ztzl/lhnyjj_1/2004/200503/t20050302_327318.htm">三提五统</a>基层乱收费，于是2006年把延续了几千年的<a href="https://www.gov.cn/test/2006-03/06/content_219801.htm">农业税废除</a>了，这里的农业税就是一种直接税，直接税税痛非常明显。而间接税里面最容易收取的，就是增值税了。</p><h2>中国收税其实很困难</h2><p>在中国，税务局收税其实很困难，例如企业所得税，企业有太多的手段可以把企业做成亏损的，早年企业都有三套账，一套做成亏损给税务局看，一套做成盈利找银行贷款，一套真实的自己留着。</p><p>所以，如果按照企业上报的账本收税，那么收上来的税款就是零，你会发现中国所有企业全部亏损。</p><p>有人说税务局可以去查账啊，查到账目造假重罚，这话说的就太轻巧了，你去查查账试试？这账哪有这么好查，抽光税务局的会计师又能查几本账，耗时耗力，而且很多支出是根本核实不了的。</p><p>所以，在中国，从来都是以票控税，而不是以账控税，尽量降低征税成本，如果你征了10亿的税，结果养了一堆会计，征税成本花了5个亿，那就搞笑了，这不能证明你法网恢恢疏而不漏，只能证明你无能。而与此同时，另外一个人领导税务局，花了1个亿的征税成本，征了7个亿，你说谁的政绩高？</p><p>而以票控税之后，只要你开了发票，你就有据可查，尤其是金税盘系统上线之后，所有的发票全国联网，开票方和接收方的任何操作均在系统留痕，有任何疑点立刻就会被发现，这就大幅度的降低了征税成本和难度。</p><p>很多人教条主义的认为，中国的税收应该等于税基×法定税率，但是实际上中国的税收等于税基×法定税率×征管效率。会计学的课本上教导我们，企业的每一笔支出，哪怕是去买一把椅子，都应该是对公账户打款入对方账户，然后收取对应发票，做到银行流水、发票和账本的三位一体互相对应。</p><p>如果真能做到这个程度，那征管效率就会是100%，所有的应收税款全部一个不落，但是不用想也知道，这种理想的情况肯定不是可能的，如果真这么严格，小微企业一夜全部死绝，哪怕是大企业，也不可能做到这么规范，只能说是相对规范一点。</p><p>我举个例子，在中国很多小摊小店，税务局根本不查账征收，也不按票征收，直接估一个定额出来，按这个定额征收之后，就算你缴税了。为什么这么做呢，因为小摊小店根本不记账也不开票，如果不定额征收，那就根本无法征税，如果你为了征税硬要他开票做账，不然就强制关门倒闭，那就和征税的初衷本末倒置了，那也是税务人员无能的表现。</p><h2>增值税的强大</h2><p>那么这里你会说，既然你以票控税，那么我就不开票不就行了，只要我不开票，你还能收我的税？这就要介绍一下增值税了。</p><p>增值税作为一个年轻的税种，于1954年首创于资本主义法国，在近半个世纪的历程中，它的迅速风靡全球，而中国改革开放后就引入了增值税，然后迅速的喜欢上了他。</p><p>增值税最大的好处，就是他是链条税、流转税，流转环节的多个链条互相稽查，导致征税异常的简单。</p><h3>增值税链条抵扣机制</h3><p>我下面给大家举个例子。面粉厂A销售了100万的面粉给面包厂B，那么面粉厂A需要缴纳增值税16%，先拿出16万元给税务局才能获得这100万的增值税票，B拿到了100万的票，才愿意打100万货款给A，这个发票叫增值税专用发票，是A的销项票，因为是销售所用面包厂B把面粉做成面包之后，以200万元的价格卖给经销商，经销商C同样要求B开具200万的增值税票给他，这个时候B需要缴纳200*16%=32万给税务局，这也是销项票。但是这个时候，B拿着当初A开给他的100万增值税去税务局说这个是我们的成本，是进项。那么这100万就属于进项票，附带的16万税款，是可以抵扣的，所以B实际只需要缴纳16万税款就可以了。这就是增值税里面“增值”二个字的含义，在你这个流通环节，你的货物增值了，你只需要缴纳增值部分的税款就可以了，这里每个环节增值了100万，所以每个环节只需要缴纳16万的税款，大家只负责自己增值的那一部分。</p><p>增值税最大的好处并不是征税清楚，只对增值部分收税，而是<strong>上下游链条的互相稽查</strong>。我们从上文的例子可以看到，每一个环节在对上游购货的时候，都会要求对方给他开增值税发票，否则不予打款。因为如果对方不开票的话，自己就少了进项票，而你的下游却依然会要求你给他开增值税发票，那么你就自己默默的承担了所有的税款。所以你会坚决要求你的上游给你开增值税票，而你的上游会坚决要求他的上游给他开增值税票。</p><p>我们做个假设，面粉那个例子，假设可以交易5轮，ABCDE，每轮增值100万，那么价格涨到了500万，大家全部都不开票，那么成功偷税漏税，所有人都不需要缴税。但是假设在第四轮卡住了，D不想冒风险，要求C给他开具300万的发票，否则不会把300万的货款打给C，那C就傻眼了，一个人要承担300*16%=48万的税费，而如果C坚持要求B给他开票的话，C原本只需要承担16万的税费而已。所以整个交易链条，只要有一个人不愿意冒这个风险，坚持要求开票，那么整个链条所有的税费都会被激活，一分钱都跑不掉，增值税永远只能转移，而不能被消灭。</p><p>正是因为增值税具备这个特性，所以税务局就轻松太多了，根本不用担心企业不开票，企业自查自纠，人人都是小税务员，税务局都无需上门催收，坐在税务大厅里等别人上门交钱开票就可以了，这个征税成本，简直是低到了极致。</p><h2>增值税的不足</h2><p>那么增值税是不是完美无瑕的税种呢，不是的，增值税有很多不足，最大的不足，就是他具备<strong>间接税的通病，那就是不够公平</strong>。</p><p>增值税最大的特点，就是税率固定，所有消费者最终承担的税负都是一样的，不管是你，还是马云，购买一台电脑，所承担的税负是一样多的。你会纳闷了，这难道不是很公平的事情吗？</p><p>不是的，这种所有人都税负一样的税种，我们称之为<strong>累退税</strong>，和个人所得税的累进税特性是反过来的。个人所得税的特征是，你收入越高，你承担的税负越重，而增值税的特性是，你的收入越高，增值税在你生活中的税负占比越轻，越是低收入群体，增值税占他们消费支出的比例越高。</p><p>增值税的存在，不利于遏制贫富分化，所以说他“不公平”。而这种不公平，是间接税的通病，如果你要实现公平，那就只能推广直接税，以个人所得税为典型代表。</p><p>所以，财政部和国家税务总局就提出过“要逐渐把间接税向直接税转移”，意思就是以后要减少增值税的比重，提高所得税的比重，其核心立意，就是要减少贫富分化。</p><h2>个人所得税征收极度困难</h2><p>但是在中国，国情特殊，个人所得税的征收极度困难，在中国间接税还是比较好收的，但是直接税实在是太难收了。</p><p>中国财政收入以增值税为主，美国财政收入以个人所得税为主，美国联邦政府的收入中，企业所得税和个人所得税占据财政收入的比重为53.6%，其中个人所得税占据33.1%。</p><p>很明显个人所得税在遏制贫富分化上面更有效，这种征税方案有效的遏制了美国的贫富分化，那为什么美国可以收个人所得税而中国不行呢。</p><p>那是因为，美国税务系统的电子化领先中国20年，信用社会和诚信精神远远高于我国，美国的个人所得税大部分都是富人缴纳，而中国的个人所得税推行之后直接异化为工薪税，主要是中下层人员缴纳，富人全部是亏损，全都没有个人所得，也没有企业所得。</p><p>看到这里你会说中国的税务极其混乱，税务人员无能了，放任富人逃税。其实中国的税务体系已经进步太多了，我给你们讲一个小故事。</p><p>时间拨回到20年前，当时各地的征税工作完全依赖地方税务局，所以地方税务局的权利其实是很大的，当时税法规定，如果企业纳税有困难，税务机关可以酌情予以减免，这个酌情自由裁量权就太大了，减多少，免多少，什么时候减，什么时候免，全是地方税务局自己决定。而那个时候中国的税务还没有电子化全国联网，地方各管各的，那个时候有一个生意就是倒腾增值税票，因为国家规定出口企业可以出口退税，国家退还17%的增值税。这一下就有人钻空子了，去全国各地到处开增值税发票然后卖给出口企业退税，由于各地税务系统没有联通，谁开出去的增值税票，这个钱就算谁的政绩，所以各地税务局争相“抢生意”，当时是17%的税率，有税务局开价11%就给票，然后有人开价6%，还有人开价3%，最后竟然还有人开价2%，各地税务工作简直是一片混乱。价值一亿的出口货物，国家只收了200万的税，却要退给出口企业1700万的税款，给国库造成了巨大的损失，各地增值税的账本是对不上去的，当年增值税出口退税的骗税案件层出不穷，国家重拳整治之后才有好转迹象。</p><p>而即便到了现在，因为国家政策，对不同行业有不同的增值税率，有16%的，也有11%的，也有6%的，还有3%的，所以即便是增值税，都有很多企业虚报范围，尽量开较低的税率，连增值税都不能做到完美征收，何谈个人所得税。</p><h2>治理国家要尊重实际状况</h2><p>说这么多，是要告诉你们，这个世界远远没有你们想的那么简单，政府也不是神，国家管理起来是很难的。很多人默认政府是无所不能的上帝，征税自然是简单无比，怎么可能让富人逃税，但是实际上，中国的税务体系已经飞速进化了，但是底子太差，和美国税务体系一样是有20年的差距，所以中国喜欢增值税，而美国喜欢所得税。</p><!--关于名义上管理国家，和实际上管理国家的区别，我们可以参考纪晓岚和和珅的一段对话，清朝的吏治水平远远低于现代中国，贪腐状况比现代要严重太多了，那么和珅在手下贪官遍地，国库空虚，赈灾欠款不足的情况下，是怎么完成皇帝交付的赈灾任务的呢，当然不能靠书本上的管理方式。<iframe frameborder="0" width="647" height="363.9375" allow="autoplay; fullscreen" allowfullscreen="true" src="https://v.qq.com/txp/iframe/player.html?origin=https%3A%2F%2Fmp.weixin.qq.com&amp;vid=h05475s544t&amp;autoplay=false&amp;full=true&amp;show1080p=false&amp;isDebugIframe=false" style="margin: 0px; padding: 0px; max-width: 100%; box-sizing: border-box !important; word-wrap: break-word !important;"></iframe>看完这个，你就知道在历史上，为什么和珅能成为军机大臣而纪晓岚最多算个御用文人。虽然和珅贪腐，但是对于乾隆朝国家治理的贡献，在历史上的确比纪晓岚要高，乾隆并不傻。而类似的道理其实还有很多，比如廉租房不能建自己的卫生间，而应该用公共厕所，这并不是侵害穷人的利益，相反是在保护穷人的利益，否则的话，廉租房里住的全是权贵。还有就是小微企业的贷款利益，要高于普通贷款，而且是要显著高于才能有效，否则的结果就是小微企业贷不到一分钱，被迫只能找高利贷救急，允许银行以高利率给小微企业贷款，并不是在吸他们血，相反是在保护小微企业。--><p>国家是由人组成的，政府也是由人组成的，所有的政策也都是由人去执行的。所以政策制定都是必须考虑到国家实际状况的，否则就是一纸空文，看起来漂亮，实际上和废纸没区别，因为执行不下去。而增值税，就是目前税务系统最符合中国实际情况的税种，所以才会占据最重要最核心的地位。</p><p>而用所得税取代增值税，政府不仅想推，而且已经很用力的去推了，但是结果大家也看到了，橘生淮北而为枳，个税沦为工薪税。中国富人账面没有个人收入，企业账面全亏损，所得压根征不上来所得税。</p><p>以直接税取代间接税，以所得税取代增值税，能抑制贫富分化，这是大势所趋，是符合历史的方向的，但是中国目前还做不到。例如个人所得税，如果想强行推广个税来取代增值税，只能有一个后果，富人不仅不交个人所得税，连增值税都不交了，如果同时征收个税和增值税，那中国的税负又过于沉重了。。。</p><p>表面上是保护穷人，抑制富人的政策，一旦执行不利，立刻就会变成保护富人，剥削穷人的结果，名义效果和实际效果，有可能完全南辕北辙。</p><p>个人所得税，其实才是真正的万税之王，如果他执行起来不走样的话。</p><p>更多税制改革的文章：</p><ul><li><a href="http://qstheory.cn/2018-05/30/c_1122913492.htm">贾康：直接税改革是中国走向现代化的一个历史性考验——求是网</a></li><li><a href="https://www.gov.cn/xinwen/2021-04/08/content_5598274.htm">“十四五”现代财税体制如何加快建立？——来自财政部的权威解读</a></li></ul>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;在中国，有18个税种(不含已经取消的营业税)，但最核心的绝对是增值税。&lt;a href=&quot;https://www.gov.cn/xinwen/2022-01/29/content_5671104.htm&quot;&gt;2021年财政收支情况&lt;/a&gt;显示增值税收入63519亿元，占全国税收收入36.7%，而第二位的企业所得税42041亿元，占比只有24.3%。尤其是&lt;a href=&quot;https://www.gov.cn/gongbao/content/2016/content_5088782.htm&quot;&gt;2012到2016年执行营改增(取消营业税改为增值税)&lt;/a&gt;之后，增值税进一步扩大了管辖范围。可以说在现在的中国增值税独霸天下，堪称万税之王。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://iknow-pic.cdn.bcebos.com/7af40ad162d9f2d3311ba193b9ec8a136327cc40&quot; rel=&quot;external noreferrer nofollow noopener&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="经济与金融" scheme="https://blog.hufeifei.cn/categories/%E7%BB%8F%E6%B5%8E%E4%B8%8E%E9%87%91%E8%9E%8D/"/>
    
    
    <category term="经济" scheme="https://blog.hufeifei.cn/tags/%E7%BB%8F%E6%B5%8E/"/>
    
    <category term="税收" scheme="https://blog.hufeifei.cn/tags/%E7%A8%8E%E6%94%B6/"/>
    
  </entry>
  
  <entry>
    <title>“真”的IP真的是真的吗？</title>
    <link href="https://blog.hufeifei.cn/2024/01/Net/x-forward-for/"/>
    <id>https://blog.hufeifei.cn/2024/01/Net/x-forward-for/</id>
    <published>2024-01-11T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.703Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2>TLDR</h2><p>这篇文章比较长，介绍全面。恐怕很多人读不完，先来一个<strong>T</strong>oo <strong>L</strong>ong <strong>D</strong>on’t <strong>R</strong>ead的总结：</p><ul><li><p>从Http头中获取“真实客户端IP地址”时，请使用<code>X-Forwarded-For</code>列表中最右边的IP。</p></li><li><p><code>XFF</code>中最左边的IP通常被认为是“最接近客户端”和“最真实”的，但它很容易伪造被欺骗。不要将它用于任何与安全相关的事情。</p></li><li><p>选择最右边的<code>XFF</code>IP时，请确保使用该标头的最后一个真实地址。</p></li><li><p>使用由反向代理设置的特殊“真实客户端IP”头（如<code>X-Real-IP</code>, <code>True-Client-IP</code>等）可能很好，但这取决于 a)反向代理实际如何设置它；b)如果它已经存在/欺骗，反向代理是否设置它；c)如果有反向代理，如何配置反向代理。</p></li><li><p>任何非反向代理专门设置的标头都不可信。比如，如果您不检查<code>X-Real-IP</code>标头直接在 Nginx 后面追加，那你可能将读取欺骗值。</p></li><li><p>许多限速器都使用可欺骗的IP实现，这容易受到绕过限速器导致内存溢出攻击。</p></li></ul><p>如果你在代码或基础设施的任何地方使用所谓的“Real IP”，你现在就需要去检查你是如何提取它的。</p><p>下面将详细解释这些内容，因此请继续阅读。</p><h2>介绍</h2><p>使用<code>X-Forwarded-For</code>或其他HTTP标头获取所谓的“Real IP”，目前地使用状态非常糟糕。这些HTTP标头设计不正确、不一致，结果导致被不恰当地使用。这导致各种项目中的安全漏洞，并且肯定会在将来导致更多的问题。</p><p>在研究了一段时间的限速器之后，我开始关心 IPv6 处理。我写了<a href="https://adam-p.ca/blog/2022/02/ipv6-rate-limiting/">一篇文章</a>，详细介绍了IPv6限速如何导致速率限制器逃逸和内存溢出。然后，我转而担心限速器在负载均衡（或任何反向代理）后面时，如何确定要限速的IP。正如你所看到的，情况很糟糕。</p><p>但这不仅是关于限速器。如果你曾经接触过查看<code>X-Forwarded-For</code>标头的代码，或者如果你使用别人的代码去获取所谓的“RealIP”，那么你绝对需要小心谨慎。这篇文章将帮助你理解为什么。</p><h2>获得真正的客户端 IP 不会那么难，对吧？</h2><p>Web 服务对其客户端的 IP 地址感兴趣的原因有很多：地理统计、地理定位、审计、限速、防止滥用、会话历史记录等。</p><p>当客户端直接连接到服务器时，服务器可以看到客户端的 IP 地址。如果客户端通过一个或多个代理（任何类型的代理：正向、反向、负载均衡器、API 网关、TLS 卸载、IP 访问控制等）进行连接，则服务器只能直接看到客户端连接使用的最终代理的 IP 地址。</p><p>为了将原始 IP 地址传递到服务器，有几个常用的HTTP标头：</p><ul><li><p><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Forwarded-For"><code>X-Forwarded-For</code></a>是逗号分隔的 IP 列表，每个经过的代理都会将访问者追加到该IP列表。按照这个想法，第一个IP（由第一个代理添加）是真正的客户端IP。每个后续 IP 都是路径上的另一个代理。最后一个代理的 IP 不存在（因为代理不添加自己的 IP，并且因为它直接连接到服务器，因此其 IP 无论如何都可以直接使用）。后面将经常讨论这个问题，所以它将缩写为“XFF”。</p></li><li><p><a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Forwarded"><code>Forwarded</code></a>是最官方的标头但似乎使用最少。我们将在下面更详细地介绍它，但它实际上只是 XFF 的一个更高级版本，它具有我们将要讨论的相同问题。</p></li><li><p>还有特殊的单 IP 标头，如 X-Real-IP（Nginx）、CF-Connecting-IP（Cloudflare） 或 True-Client-IP（Cloudflare 和 Akamai）。我们将在下面详细讨论这些，但它们不是本文的主要重点。</p></li></ul><h2>陷阱</h2><p>在讨论如何正确使用 XFF 之前，我们将讨论使用<code>X-Forwarded-For</code>可能出错的多种形式。</p><h3>标头不可信</h3><p>首先，也是最重要的一点，您必须始终意识到，由不受您控制的任何代理添加（或似乎已经添加）的任何 XFF IP 都是完全不可靠的。任何代理都可以以任何它想要的方式添加、删除或修改标头。客户端也可以最初将标头设置为它想要的任何内容，以使欺骗球滚动。例如，如果您向 AWS 负载均衡器发出此请求：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST https://my.load.balanced.domain/login -H &quot;X-Forwarded-For: 1.2.3.4, 11.22.33.44&quot;</span><br></pre></td></tr></table></figure><p>负载均衡器后面的服务器将获得以下信息：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X-Forwarded-For: 1.2.3.4, 11.22.33.44, &lt;actual client IP&gt;</span><br></pre></td></tr></table></figure><p>还有这个：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -X POST https://my.load.balanced.domain/login -H &quot;X-Forwarded-For: oh, hi,,127.0.0.1,,,,&quot;</span><br></pre></td></tr></table></figure><p>会给你这个：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X-Forwarded-For: oh, hi,,127.0.0.1,,,,, &lt;actual client IP&gt;</span><br></pre></td></tr></table></figure><p>正如你所看到的，目前都只是通过，这个标头前面的信息不会被改变也不会被验证。最终的实际 IP 只是附加到已经存在的内容后。</p><p>（除了<code>curl</code> 和自定义客户端之外，还有类似于ModHeader的<a href="https://chromewebstore.google.com/detail/x-forwarded-for-header/hkghghbnihliadkabmlcmcgmffllglin">Chrome插件</a>可让您在浏览器请求中设置 XFF 标头。但是，如何设置标头对我们来说并不重要，重要的是攻击者可以利用这一点。</p><h3>多个标头</h3><p>根据 <a href="https://datatracker.ietf.org/doc/html/rfc2616#section-4.2">HTTP/1.1 RFC （2616）</a>:</p><blockquote><p>Multiple message-header fields with the same field-name MAY be present in a message if and only if the entire field-value for that header field is defined as a comma-separated list [i.e., #(values)]. It MUST be possible to combine the multiple header fields into one “field-name: field-value” pair, without changing the semantics of the message, by appending each subsequent field-value to the first, each separated by a comma. The order in which header fields with the same field-name are received is therefore significant to the interpretation of the combined field value, and thus a proxy MUST NOT change the order of these field values when a message is forwarded.</p></blockquote><p>这适用于 XFF，因为它是一个逗号分隔的列表。这可能使获取最右边（甚至最左边）的 IP 容易出错。</p><p>例如，Go语言有三种获取标头值的方法：</p><ul><li><a href="https://pkg.go.dev/net/http#Header.Get"><code>http.Header.Get(headerName)</code></a>以字符串形式返回第一个标头值。</li><li><a href="https://pkg.go.dev/net/http#Header.Values"><code>http.Header.Values(headerName)</code></a>返回一个字符串切片（数组），其中包含<code>headerName</code>标头的所有实例的值。(在查找之前<code>headerName</code>会被规范化)</li><li><code>http.Header</code>是个<code>map[string][]string</code>，可以直接访问。（map的key是规范化的标头名称。这类似于使用<code>Values</code>。</li></ul><p>所以这是攻击：</p><ul><li>Eve 使用两个伪造的 XFF 标头发出请求。</li><li>根据 RFC 要求，您的反向代理将 Eve 的真实 IP 添加到第二个 XFF 标头的末尾。</li><li>您调用<code>req.Header.Get(&quot;X-Forwarded-For&quot;)</code>并获取第一个标头。你把它分开，拿最右边的。</li><li>您选择了欺骗性 IP。你把它看作是值得信赖的。结果坏事了。</li></ul><p>与 Go 不同，Twisted 获取<a href="https://github.com/twisted/twisted/blob/ebb2d360070e468981377b917e3a728ff4e6c7f6/src/twisted/web/http.py#L1068">单个标头值的方法</a>返回最后一个值。（为什么没有标准的、通用的、公认的行为？这避免了上述攻击，但它可能会导致一个不同的（不太可能的）问题：如果你使用最右边的算法（如下所述），你需要从右边向后寻找第一个不受信任的IP。但是，如果您的一个反向代理添加了新的标头而不是附加（根据 RFC，这是一件有效的事情）怎么办？现在，您想要的 IP 在最后一个标头中无处可寻——它充满了受信任的反向代理 IP，而真正的 IP 位于 XFF 标头的先前实例中。</p><p>这里可能存在一种微妙的、假设的攻击：</p><ul><li>你（至少）有两个你信任的反向代理。</li><li>第二个反向代理不喜欢超长的标头，因此它会创建一个新的标头，而不是在 XFF 标头太长时附加。</li><li>夏娃知道这一点。她想向你隐瞒她的IP。</li><li>夏娃在她给你的请求中恶搞了一个长长的XFF。</li><li>您的第一个反向代理将她的真实 IP 添加到 XFF 标头。</li><li>您的第二个反向代理不喜欢该标头的长度，因此它会创建一个新标头。标头值是第一个反向代理的 IP。</li><li>您的服务器软件获取最后一个标头，它只有一个 IP，属于您的第一个反向代理。</li><li>你的逻辑是做什么的？使用该 IP？因为它是私人的/受信任的，所以把它当作特殊的？恐慌是因为这个IP不可能被信任？</li></ul><p>请注意，当我使用 AWS ALB 后面的服务器进行测试时，我发现 ALB 已经连接了 XFF 标头。所以这很好。我不知道其他反向代理是否也这样做，但我敢打赌没有真正的一致性。</p><p>最好的办法是自己合并所有 XFF 标头。</p><p>（值得询问和检查的是，确保反向代理附加到正确的标头，因为附加到错误的标头会破坏采取最正确的代理的可信度。我只检查了 AWS ALB 和 Cloudflare，他们做对了。如果有人发现做错了什么，请告诉我。</p><h3>私有 IP</h3><p>即使在完全非恶意的情况下，任何 XFF IP（尤其是最左边的 IP）也可能是私有/内部 IP 地址。如果客户端首先连接到内部代理，它可能会将客户端的私有 IP 添加到 XFF 标头中。这个地址永远不会对你有用。</p><h3>拆分 IP</h3><p>因为<code>X-Forwarded-For</code>不是官方标准，所以没有正式的规范。大多数示例显示 IP 地址以逗号空格（<code>, </code>） 分隔，但空格并不是严格要求的。（例如，HTTP/1.1 RFC 说像 XFF 这样的标头只是“逗号分隔”。我查看的大多数代码仅按逗号拆分，然后修剪值，但我发现至少有一个代码会查找逗号空间。</p><p>在测试时，在我看来，AWS ALB 在添加 IP 时使用逗号空间，但 Cloudflare 只使用逗号。</p><h3>未加密的数据始终不可信</h3><p>这应该不言而喻，但是如果您收到的是 HTTP-not-S 请求，那么任何人都可以在它们到达您之前修改标头。值得一提的是，闯入者无法搞砸“最右边”的方法（如下所述），因为他们无法搞砸从互联网到您的反向代理或服务器的最终连接的 IP。</p><p>所以只要加密你的流量，好吗？</p><h3>其他标头（X-Client-IP，True-Client-IP）可能存在并被欺骗</h3><p>一些反向代理会删除任何意外或不需要的标头，但有些（如AWS ALB）不会。因此，攻击者可以设置X-Client-IP、True-Client-IP标头，例如并直接连接到您的服务器。如果您的反向代理没有专门为您设置它们，您无需被愚弄使用它们。</p><h3>尝试了解X-Forwarded-For</h3><p>不幸的是，尝试让自己了解 XFF 也很困难。</p><p>MDN Web Docs 通常是此类内容的黄金标准，但关于 XFF 的页面根本没有提到这些风险; 它说“最右边的 IP 地址是最新代理的 IP 地址，最左边的 IP 地址是原始客户端的 IP 地址”，没有任何警告。维基百科条目要好得多：“由于很容易伪造<code>X-Forwarded-For</code>字段，因此应谨慎使用给定的信息。最右边的 IP 地址始终是连接到最后一个代理的 IP 地址，这意味着它是最可靠的信息来源。</p><p>【2022-03-09：为 MDN 文档创建了一个<a href="https://github.com/mdn/content/issues/13703">issue</a>。 2022-03-19：我重写了页面，对其进行了公关，更改现已生效。您可以在此处查看<a href="https://adam-p.ca/misc/MDN-XFF.pdf">原始<code>Forwarded</code>页面的 PDF</a>。现在要修复页面…】</p><p>其他来源也同样可变。有些人对标头被欺骗的可能性或私人地址的存在（<a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/x-forwarded-headers.html">1</a>、<a href="https://techcommunity.microsoft.com/t5/iis-support-blog/how-to-use-x-forwarded-for-header-to-log-actual-client-ip/ba-p/873115">2</a>、<a href="https://www.geeksforgeeks.org/http-headers-x-forwarded-for/">3</a>、<a href="https://developers.cloudflare.com/fundamentals/get-started/http-request-headers/">4</a>、<a href="https://www.keycdn.com/blog/x-forwarded-for-cdn">5</a>）一无所知。其他人在提及风险方面做得很好（<a href="https://totaluptime.com/kb/prevent-x-forwarded-for-spoofing-or-manipulation/">6</a>,<a href="https://docs.fastly.com/signalsciences/faq/real-client-ip-addresses/#x-forwarded-for-header-configuration">7</a>,<a href="https://datatracker.ietf.org/doc/html/rfc7239#section-8.1">8</a>），但有时您必须深入阅读才能获得警告。</p><h2>避免这些坑</h2><p>让我们做一些基线陈述：</p><ul><li><a href="https://adam-p.ca/blog/2022/03/x-forwarded-for/#fn:4">使用专用地址空间中的 IP 作为“真正的”客户端 IP 从来都不是正确的选择</a>.</li><li>使用实际上不是 IP 地址的值从来都不是正确的选择。</li><li>在没有诡计的情况下，最左边的非私有、非无效的 IP 是我们最接近“真实”客户端 IP。（以下简称“最左边”）。</li><li>我们唯一可以信任的客户端 IP 是我们控制的（反向）代理添加的第一个客户端 IP。（以下简称“最右边的”）。</li><li><strong>最左边的人通常是最“真实”的，而最右边的人是最值得信赖的</strong>。那么你应该使用哪个IP？这取决于你要用它做什么。</li></ul><p>如果你要做一些与安全有关的事情，你需要使用你信任的IP–最右边的IP。这里最明显的例子是限速。如果您为此使用最左边的 IP，攻击者可以在每个请求中欺骗不同的 XFF 前缀值，并完全避免受到限制。</p><p>此外，他们可能会通过强制您存储太多的单个条目来耗尽您的服务器内存——每个虚假 IP 一个条目。似乎很难相信将 IP 地址存储在内存中会导致耗尽 - 尤其是当它们存储在生存时间有限的缓存中时，但请记住：</p><ul><li>攻击者不会局限于 40 亿个 IPv4 地址。他们可以使用所有数以亿计的 IPv6 地址，如果限制器对前缀不智能。</li><li>由于许多限制器不检查有效的 IP，因此攻击者可以使用所需的任何随机字符串。</li><li>另请注意，这些字符串可能很大;例如，Go 的默认标头块大小限制为 1MB。这意味着单个随机字符串“IP”可能接近 1MB。这意味着每个请求增加 1MB 的内存使用量。</li></ul><p>对于所有攻击者和配置来说，它仍然不可行，但不应不加考虑地将其驳回。</p><p>或者，攻击者可以强制您对其他用户的 IP 地址进行速率限制/阻止。他们可以提供真实的 IP 地址，但不能提供他们的 IP 地址，您最终会被愚弄以限制其速率。（如果你使用“真实”的IP进行滥用报告，你最终可能会抱怨错误的人。</p><p>使用最右边的 IP 进行速率限制的缺点是，您可能会阻止一个代理 IP，该 IP 实际上不是滥用的来源，而只是被一堆不同的客户端使用，如果您只是使用最左边的 IP，您就会意识到这一点。是的，好吧。这似乎不太可能，而且它仍然比允许攻击者轻而易举地绕过您的速率限制器并使您的服务器崩溃要容易得多。</p><p>如果你正在做一些与安全无关的事情……认真考虑您的用例。假设您只想对您的统计数据进行 IP 地理位置查找。可能最左边的 IP 就是你想要的。您的绝大多数用户不会进行任何标头欺骗，并且随机互联网代理的地理位置对您没有好处，因此您可能会在最接近用户的 IP 上获得最佳结果。</p><p>另一方面，您可能需要考虑您期望拥有多少使用 Internet 代理的用户。可能足够少，如果你地理定位错误的东西，它不会损害你的统计数据。攻击者有没有办法通过故意歪曲你的地理统计数据来伤害你？可能不是，但花点时间认真考虑一下。</p><p>因此，在编写“GetRealClientIP（request）”函数时要小心。确保它有一个关于如何使用它的大警告注释。或者编写两个函数：<code>GetUntrustworthyRealClientIP(request)</code>和<code>GetTrustworthyButLessRealClientIP(request)</code>。这些都是可怕的名字。也许只是传递一面旗帜。无论如何，关键是要防止函数的调用者对结果的性质产生任何混淆。</p><p>使用该函数的结果时也要小心。编写代码很容易，让最左边的 IP 进行一些地理查找，然后决定您还需要进行速率限制……所以你不妨使用相同的“realClientIP”变量！哎呀。这可能是使错误的代码看起来错误的好时机。</p><p>请记住，最终代理 IP（或客户端的地址（如果直接连接）不在 XFF 标头中。为此，您需要查看您的请求连接信息。（在 Go 中的<code>http.Request.RemoteAddr</code>，许多 CGI 服务器的<code>REMOTE_ADDR</code>环境变量等）</p><h3>算法</h3><p>阅读本文时，请记住，最终的代理 IP 不在 XFF 列表中，而是<code>RemoteAddr</code>。另请注意，<code>RemoteAddr</code>它可能具有<code>ip:port</code>形式，具体取决于您的平台（就像在 Go 中一样）——当然可以确保只使用 IP 部分。</p><h4>第一：收集所有IP</h4><p>列出所有<code>X-Forwarded-For</code>标头中的所有IP。<code>RemoteAddr</code>也是有用的。</p><h4>第二：确定您的安全需求是什么</h4><p>默认使用最右边的方法。仅在必要时使用最左边的，并确保谨慎使用。</p><h4>最左边：最接近“真实IP”，但完全不可信</h4><p>如果您的服务器直接连接到 Internet，则可能有 XFF 标头，也可能没有（取决于客户端是否使用代理）。如果存在 XFF 标头，请选择最左侧的 IP 地址，该地址是有效的非专用 IPv4 或 IPv6 地址。如果没有 XFF 标头，请使用<code>RemoteAddr</code>。</p><p>如果您的服务器位于一个或多个反向代理后面，请选择最左边的 XFF IP 地址，该地址是有效的非私有 IPv4 或 IPv6 地址。（如果没有 XFF 标头，则需要立即修复网络配置问题。</p><p>永远不要忘记安全隐患！</p><h4>最右边的：唯一值得信赖的有用IP</h4><p>如果您的服务器直接连接到互联网，则 XFF 标头不可信。使用<code>RemoteAddr</code>。</p><p>如果您的服务器位于一个或多个反向代理后面，并且无法从 Internet 直接访问，则需要知道这些反向代理的 IP 地址或请求将通过的 IP 数量。我们将这些称为“受信任的代理 IP”和“受信任的代理计数”。（最好使用“受信任的代理 IP”，原因如“网络体系结构更改”部分所述。</p><p>受信任的代理 IP 或受信任的代理计数将告诉您在找到不属于某个反向代理的第一个 IP 之前，您需要检查距离 XFF 标头的右侧多远。此 IP 是由您的第一个受信任的代理添加的，因此是您唯一可以信任的 IP。使用它。</p><p>（请注意，我在这里说的不是“有效的非私有IP”。这样做很诱人，只是为了更加安全，如果你这样做，我不会责怪你，但如果你不能相信你自己的反向代理来添加适当的IP，那么你就会遇到更大的问题。</p><p>同样，如果您支持一个或多个反向代理并且没有 XFF 标头，您需要立即弄清楚人们如何直接连接到您的服务器。</p><h5>暂定变化：最右边的非私有IP</h5><p>如果您的所有反向代理都与您的服务器位于同一私有 IP 空间中，我认为可以使用最右边的非私有 IP，而不是使用“受信任的代理 IP”或“受信任的代理计数”。这相当于将所有专用 IP 范围添加到“受信任的代理 IP”列表中。</p><p>这不起作用的一个例子是，如果您位于外部反向代理服务（如 Cloudflare）后面——它不在您的私有地址空间中。</p><h2>掉进那些坑里</h2><p>让我们看看真实世界的例子！</p><p>警告：我在这里有点得意忘形。我只打算看看几个我熟悉的项目，但危险使用最左边的命中率太高了，所以我一直在寻找。（即使做得好，也有一些有趣和有教育意义的方面。</p><p>（如果这里没有提到某个工具或服务，那是因为我没有看过它，或者找不到足够的信息。我包括了所有的成功和失败。</p><h3>Cloudflare、Nginx、Apache</h3><p>让我们从一些好消息开始。</p><p>Cloudflare 将<code>CF-Connecting-IP</code>标头添加到通过它的所有请求中;它添加<code>True-Client-IP</code>为需要向后兼容性的企业用户的同义词。这些标头的值是单个 IP 地址。我能找到的对这些标头的最完整描述听起来像是它们只是使用最左边的 XFF IP，但这个例子不够完整，我自己也尝试了一下。令人高兴的是，看起来他们实际上使用了最正确的方法。</p><p>Nginx 提供了一个默认<a href="https://nginx.org/en/docs/http/ngx_http_realip_module.html">未启用的模块</a>，用于添加 X-Real-IP 标头。这也是一个单一的IP。正确且完全配置时6，它还使用不在“受信任”列表中的最右边的 IP。所以，最右边的IP。也不错。</p><p>同样，当配置为 查看<code>X-Forwarded-For</code> 时，Apache 的<a href="https://httpd.apache.org/docs/trunk/mod/mod_remoteip.html">mod_remoteip</a>会选择最右边的不受信任的 IP 进行设置<code>REMOTE_ADDR</code>。</p><h3>Akamai公司</h3><p>Akamai 做了非常错误的事情，但至少对此发出了警告。以下是有关它如何处理<code>X-Forwarded-For</code>和<code>True-Client-IP</code>（原始强调）的<a href="https://community.akamai.com/customers/s/article/Difference-Between-Akamai-True-Client-IP-header-and-Default-X-Forwarded-For">文档</a>：</p><blockquote><p>X-Forwarded-For header is the default header proxies use to report the end user IP that is requesting the content. However, this header is often overwritten by other proxies and is also overwritten by Akamai parent servers and thus are not very reliable.</p><p>The True-Client-IP header sent by Akamai does not get overwritten by proxy or Akamai servers and will contain the IP of the client when sending the request to the origin.</p><p>True-Client-IP is a self provisioned feature enabled in the Property Manager.</p><p>Note that if the True-Client-IP header is already present in the request from the client it will not be overwritten or sent twice. It is not a security feature.</p><p>The connecting IP is appended to X-Forwarded-For header by proxy server and thus it can contain multiple IPs in the list with comma as separator. True-Client-IP contains only one IP. If the the end user uses proxy server to connect to Akamai edge server, True-Client-IP is the first IP from in X-Forwarded-For header. If the end user connects to Akamai edge server directly, True-Client-IP is the connecting public IP seen by Akamai.</p></blockquote><p>相关位是“<code>True-Client-IP</code>是<code>X-Forwarded-For</code>标头中的第一个 IP”和“如果 True-Client-IP 标头已经存在于来自客户端的请求中，则不会被覆盖”。因此，<code>True-Client-IP</code>要么是最左边的 XFF IP，要么是保留客户端欺骗的原始值。只是最糟糕的事情。</p><p>但是，也有一句话“这不是安全功能”。嗯，这当然是真的。这个警告可以吗？没有大量 Akamai 用户出于安全相关目的使用<code>True-Client-IP</code>的可能性有多大？</p><p>（我不确定如何解释上面的内容，当它说 XFF 标头“被 Akamai 父服务器覆盖”时。当它说“覆盖”时，它是否意味着“附加到”？还是 Akamai 实际上吹走了现有的标头值？这将违背XFF的精神。</p><h3>Fastly</h3><p>Fastly 添加具有单个 IP 值的 Fastly-Client-IP 标头。我认为它使用了最正确的 XFF IP：</p><p>从本质上讲，<code>Fastly-Client-IP</code>是向 Fastly 发出请求的非 Fastly 事物。</p><p>但是：</p><p>该值在 Fastly 网络的边缘不受修改保护，因此如果客户端自己设置此标头，我们将使用它。如果你想防止这种情况[你需要做一些额外的配置]。</p><p>因此，默认情况下，它是微不足道的欺骗性的。同样，似乎很有可能有很多人将其默认行为用于与安全相关的目的，并使自己容易受到攻击。Fastly-Client-IP</p><blockquote><p>原文地址：<a href="https://adam-p.ca/blog/2022/03/x-forwarded-for/">https://adam-p.ca/blog/2022/03/x-forwarded-for/</a></p></blockquote>]]></content>
    
    
    <summary type="html">x-forward-for头信息</summary>
    
    
    
    <category term="网络" scheme="https://blog.hufeifei.cn/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="HTTP" scheme="https://blog.hufeifei.cn/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>【译】基于MarkupLM的web数据抽取</title>
    <link href="https://blog.hufeifei.cn/2024/01/paper/MarkupLM-web-extract/"/>
    <id>https://blog.hufeifei.cn/2024/01/paper/MarkupLM-web-extract/</id>
    <published>2024-01-10T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.707Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2>摘要</h2><p>网站在当今数字时代已成为许多组织获取信息的关键来源。然而，从多个网站的网页中提取和组织半结构化数据存在挑战，尤其是在希望保持广泛适用性的同时实现高度自动化时。在追求自动化的过程中，自然而然的发展是将网页数据提取的方法从仅能处理单个网站扩展到通常在同一领域内处理多个网站。尽管这些网站共享相同的域，但数据的结构可能差异巨大。一个关键问题是在保持足够准确性的同时，这样的系统能够通用地涵盖大量网站。该论文检查了在多个瑞典保险公司网站上进行的自动化网络数据提取的效率。先前的工作表明，使用包含多个领域网页的已知英语数据集可以取得良好的结果。选择了最先进的模型MarkupLM，并使用监督学习使用两个预训练模型（一个瑞典模型和一个英语模型）在标记的汽车保险客户网络数据的训练集上进行零样本学习。结果显示，这样的模型可以通过利用预训练模型，在源语言为瑞典的情况下，以相对较小的数据集在领域范围内取得良好的准确性。</p><h2>1、介绍</h2><p>数字时代使互联网成为主要信息来源。互联网上的数据丰富且复杂度增加，同时对更复杂服务的需求也在不断增加。尽管有大量数据可供探索，一个关键挑战是在满足数据质量和有效性要求的前提下，尽可能高效而准确地提取和结构化信息。数据的结构范围从非结构化数据（如文本）到半结构化数据（如超文本标记语言（HTML））再到结构化数据，后者可以采用表格或数据库生成的HTML形式 [1, 2]。<br>尽管人类可以手动提取这些数据，但自动化这一过程是非常可取的，即最小化人工劳动、错误和干预。存在一些可自动提取信息的网络数据提取方法，但它们的使用高度依赖于泛化和鲁棒性要求。<br>另一种选择是网站提供 Web 应用程序编程接口（API），使用诸如 RESTful API 或 GraphQL API 等技术。然而，在本论文中不会探讨这种替代方案。<br>另一种选择是网页的行业标准格式。通过模板对网站进行一些标准化，如[3]所述，但本论文不会关注这种替代方案。</p><h3>1.1、背景</h3><p>自动化网络数据提取的一个主要问题是系统的灵活性和通用性。根据Sergio Flesca等人的说法，许多系统依赖于包装器，“一组适用于从网站提取信息的提取规则” [4]，这些规则与其训练时紧密耦合的网站的底层文档对象模型（DOM）[5]树结构相关。这使得系统对结构的变化非常敏感，除非进行包装器维护 [6]，同时在未在训练集中的网站上提取正确数据方面效果不佳。任何这类系统的一个极具吸引力的特征是从先前未见过的网站提取数据（即，它应具有泛化能力），并且在满足使用提取数据的应用程序的具体要求的同时保持足够的准确性。尝试在生成和维护这样的系统期间最小化涉及的手动人工劳动会进一步增加问题的复杂性。<br>问题的一个有趣的限定是将自动化网络数据提取系统的泛化能力缩小到一组具有一些相似之处的网站。其中一种方法是创建一个特定领域的系统，旨在从同一垂直（即领域）内的多个网站中提取相同类型的对象（例如，图书）。这使系统能够充分利用这些网站在信息和结构上潜在共享的相似之处。</p><h3>1.2、问题</h3><p>这个问题在很大程度上依赖于所需数据的复杂性（例如，结构水平和目标属性数量），以及目标领域网站表示（即，HTML布局）的相似性。另一个方面是网站的语言，这是一个依赖自然语言处理（NLP）从文本中提取语义意义的系统（即，模型）中的因素。在训练数据有限时，预训练表示通常对提高性能至关重要。虽然英语有大量高质量的预训练模型，但瑞典语的数量并不如此之多。问题的一个有趣方面是预训练表示对网页数据提取模型性能的影响。<br>一个带有监督学习的网络数据提取模型能够从未见过的瑞典保险网站中提取信息的效果如何？</p><h3>1.3、宗旨</h3><p>该论文旨在探索自动化从同一垂直内的多个网站中提取网络数据的可能性。具体而言，将使用瑞典保险网站的用户网页，其中包含其保险计划的摘要。这将有望为使用当前先进技术（SOTA）模型从瑞典保险网站提取数据的可能性和效率提供一些见解。</p><h3>1.4、目标</h3><p>该论文旨在确定一个适用的网络数据提取模型，然后在瑞典汽车保险网站上对其进行修改和评估。子目标包括：</p><ul><li>获取数据集，</li><li>确定适用的模型，</li><li>修改模型，以及</li><li>评估模型。</li></ul><h3>1.5、研究方法</h3><p>项目中采用的研究方法将是设计科学 [7]，并使用实验方法进行评估。设计科学是一种范式，其中通过设计的工件产生知识和解决方案。<br>该论文将采用 MarkupLM 模型（参见第2.4.5节），并进行必要的修改以使其与瑞典语兼容。该模型（即，工件）将通过实验评估，以确定它在测试数据集中从未见过的保险网站中提取数据的效果如何。准确性将使用三个指标进行测量：精确度、召回率和 F-分数（这些指标在第2.3节中描述）。</p><h3>1.6、限制</h3><p>该论文探讨并评估单一模型的变种，而非多个不同模型。所使用的数据将仅为瑞典语且为HTML格式。对于数据集的基准真实性，将不进行手动标注。相反，将使用公司（即，Insurely）开发的手工提取机制生成基准真实性。</p><h3>1.7、结构</h3><p>第二章介绍了有关自动化网络数据提取的相关背景信息。第三章介绍了解决问题所使用的方法和方法论。第四章描述了对先进技术（SOTA）模型的修改。第五章呈现了对模型进行评估的结果。第六章讨论了所获得的结果，最后第七章提出了论文的结论并提出未来的工作。</p><h2>2、背景</h2><p>这一章概述了与网页数据提取领域（第2.1节）和深度学习（第2.2节）相关的技术，这些技术可能在网页数据提取系统中使用。第2.3节描述了用于评估网页数据提取系统的一些性能指标。不同的网页数据提取方法和三个先进技术（SOTA）模型作为相关工作被介绍（第2.4节）。</p><h3>2.1 网页数据提取</h3><p>网页数据提取是指从网页中提取信息的过程。软件系统通过在内容更改时自动和重复地从网页中提取数据来执行网页数据提取 [8]。每个网页将如第2.1.1节所述表示，页面的特定部分将如第2.1.2节所述被处理。</p><h4>2.1.1 文档对象模型</h4><p>文档对象模型（DOM）是一个API，使得文档（如HTML和可扩展标记语言（XML）文档）能够被表示为逻辑树（如图2.1所示），由节点组成，每个节点包含对象。通过将文档表示为DOM，然后操作DOM，可以以编程方式更改网页（例如，结构、样式或内容）[5]。</p><img width="438" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/b88c232a-1c66-406b-8305-5e46531e3601"><h4>2.1.2 XML路径语言</h4><p>XML路径语言（XPath）以路径符号提供了一种灵活的方法来寻址XML或HTML对象的部分。XML路径语言（XPath）表达式可用于在HTML文件的DOM树中导航，而无需依赖DOM核心特性，例如Document和Node接口，这些接口提供了getElementById()和ChildNodes等方法和属性 [9]。图2.2显示了应用于同一HTML对象的两个XPath表达式的示例。</p><img width="498" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/83f5f693-eadc-45e1-947e-620aeedae10e"><h4>2.1.3 JavaScript对象表示法</h4><p>JavaScript对象表示法（JSON）是一种轻量级的与语言无关的数据格式 [10]。JSON具有易于阅读和编写的文本格式，如图2.3所示。它基于两种结构：一组键/值对和一个有序列表。键/值对的集合称为对象，其中键/值对在左括号和右括号之间列出，键/值之间用冒号分隔。有序列表可以包含多个对象。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">[</span></span><br><span class="line">  <span class="punctuation">{</span></span><br><span class="line">    ”name”<span class="punctuation">:</span> ”Alice”<span class="punctuation">,</span></span><br><span class="line">    ”age” <span class="punctuation">:</span> <span class="number">25</span></span><br><span class="line">  <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">  <span class="punctuation">{</span></span><br><span class="line">    ”name”<span class="punctuation">:</span> ”Bob”<span class="punctuation">,</span></span><br><span class="line">    ”age” <span class="punctuation">:</span> <span class="number">26</span><span class="punctuation">,</span></span><br><span class="line">    ”height”<span class="punctuation">:</span> <span class="number">174.5</span></span><br><span class="line">  <span class="punctuation">}</span></span><br><span class="line"><span class="punctuation">]</span></span><br></pre></td></tr></table></figure><h3>2.2 深度学习</h3><p>深度学习是机器学习的一个子集，其中建模并训练神经网络，试图模拟人脑在学习过程中的行为 [11]。在深度学习中，需要较少的数据预处理，可以使用非结构化数据，如文本和图像。使用深度学习的一个显著优势是自动特征提取，机器决定哪些特征是相关的，而无需依赖人类专家。使深度学习网络“深”的主要因素包括层中神经元的数量、这些层之间连接的复杂方式以及训练网络所需的大量计算能力 [12]。<br>以下小节介绍了几个深度学习概念，这些概念对理解模型架构很重要，具体包括卷积神经网络（CNNs）（第2.2.1节）、循环神经网络（RNNs）（第2.2.2节）和变压器（第2.2.3节），以及迁移学习的概念（第2.2.4节）。</p><h4>2.2.1 卷积神经网络</h4><p>卷积神经网络（CNNs）是深度网络的主要架构之一，其目标是通过利用卷积进行特征检测，学习数据中的高阶特征。这通过对两组信息应用数学运算来实现 [12]。CNNs主要用于机器视觉（例如，图像分类），但也适用于文本分析。在建模数据（如图像）时，CNNs具有较高的计算效率，否则在全连接网络中可能导致连接数量激增。<br>主要的三个层组包括：输入层、特征提取层和分类层，如图2.4所示。架构各层之间的主要区别在于特征提取层，它包含两种类型的层：卷积层和池化层。</p><img width="455" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/ff250a43-04cc-480e-9c33-fb3817ac2fa3"><p>卷积层在数据中寻找特征，通过对输入应用滤波器将这些特征组合成高阶特征。图2.5中显示了一个这样的滤波器，其核（即，滤波器）向量的权重为[1/3, 1/3, 1/3]。在一层中可以应用多个不同的滤波器。在应用滤波器后，激活函数用于决定哪些神经元应该被激活并传播其值。两种这样的激活函数是修正线性单元（ReLU）和高斯误差线性单元（GELU）。线性函数ReLU对于所有非负输入都输出相应的输入，否则输出零，即max(0, x)。而GELU [13] 是一个更复杂的非线性函数，可以看作是ReLU的一个更平滑的版本。</p><img width="429" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/ec51720d-1956-41cb-80f1-3a7827281ed2"><p>池化层在卷积层之后使用，以减小（即，下采样）数据表示的空间大小。这有助于减少网络记忆训练数据的自由度（即，过拟合），而是迫使其进行学习泛化；因此，在未见过的数据上表现更好。最大池化是其中的一种常见变体，它选择滤波器区域中的最大值。</p><h4>2.2.2 循环神经网络</h4><p>RNN与其他类型的神经网络有所不同，因为它们具有对数据的时间维度（即，时间依赖性）进行建模的能力。RNN在每个输入（即，时间步）之间保留状态，它使用这些状态对数据进行建模，然后将状态传递到下一个时间步。这种时间反馈使模型能够捕捉上下文，特别是对于需要基于当前和先前输入生成/推断序列的敏感数据，如语言、音频和文本 [12]。<br>长短时记忆（LSTM）[14]是最常见的RNN架构之一。其主要优势在于它能够在时间步之间保持内存不变。这种特性使其能够克服梯度消失问题，即模型由于模型（即，权重）的更新变得非常小，导致模型停止学习，无法进一步捕获任何输入。</p><h4>2.2.3 变压器</h4><p>变压器是由Ashish Vaswani等人在他们的论文《Attention is all you need》[15]中提出的最新架构之一。它是一种完全基于注意机制而非循环或卷积的架构。与具有顺序性质的循环相比，这种结构在训练期间具有更大的并行性，其中新的隐藏状态是作为过去状态的函数而生成的。<br>变压器架构基于一个编码器-解码器结构，包括编码器和解码器堆栈，每个堆栈由六个相同的层组成。编码器堆栈负责将输入的符号序列映射为连续表示。解码器堆栈生成一个符号序列，其中每次生成一个符号，并在下一生成步骤中用作额外的输入。</p><h4>2.2.4 迁移学习</h4><p>迁移学习是通过从相关领域传递信息来改进某一领域中的学习者的一种方式。在神经网络中，由于需要更大的数据集来训练网络以避免过拟合 [16]，迁移学习可以发挥重要作用，特别是在训练集有限的情况下。与从头开始训练一个模型不同，可以利用已经使用与目标域相关的更大数据集进行训练的模型，用于任务如文本情感分析和图像分类 [17]。迁移学习可以在包含两个阶段的学习框架中形式化：预训练和微调 [18]。<br>预训练阶段包括捕捉一个或多个任务的知识。这可以通过大规模未标记的语料库来学习良好的表示，然后在其他任务中使用这个表示。预训练的一些优势包括学习通用语言表示、更好的模型初始化以及在小数据集上防止过拟合的正则化效果 [16]。微调阶段使用预训练模型，并进一步使用代表特定问题的较小数据集进行所谓的下游（即，目标）任务的训练。</p><h3>2.3 评估指标</h3><p>该模型的三个评估指标将是：精确度、召回率和F分数。在关注分类性能的机器学习应用中，这些是关键指标。<br>精确度衡量正类别的预测值，同时避免将负类别错误地分类为正类别 [19]。具体而言，正确定义的预测中实际正确的比例：</p><p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.059ex" xmlns="http://www.w3.org/2000/svg" width="32.144ex" height="5.285ex" role="img" focusable="false" viewBox="0 -1426 14207.6 2336"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">精</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">确</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">度</text></g><g data-mml-node="mo" transform="translate(2977.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4033.6,0)"><g data-mml-node="mtext" transform="translate(2209,676)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">真</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">例</text></g><g data-mml-node="mtext" transform="translate(220,-710)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">真</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">例</text><path data-c="20" d="" transform="translate(2700,0)"></path><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" transform="translate(2950,0)"></path><path data-c="20" d="" transform="translate(3728,0)"></path><text data-variant="normal" transform="translate(3978,0) scale(1,-1)" font-size="884px" font-family="serif">假</text><text data-variant="normal" transform="translate(4878,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(5778,0) scale(1,-1)" font-size="884px" font-family="serif">例</text></g><rect width="6878" height="60" x="120" y="220"></rect></g><g data-mml-node="mstyle" transform="translate(11151.6,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(12151.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(12540.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(13818.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p><p>召回率衡量正类别的预测值，同时避免将正类别错误地分类为负类别 [19]。具体而言，正确定义的预测与所有实际正类别的比例：</p><p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.059ex" xmlns="http://www.w3.org/2000/svg" width="32.144ex" height="5.285ex" role="img" focusable="false" viewBox="0 -1426 14207.6 2336"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">召</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">回</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">率</text></g><g data-mml-node="mo" transform="translate(2977.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4033.6,0)"><g data-mml-node="mtext" transform="translate(2209,676)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">真</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">例</text></g><g data-mml-node="mtext" transform="translate(220,-710)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">真</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">正</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">例</text><path data-c="20" d="" transform="translate(2700,0)"></path><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" transform="translate(2950,0)"></path><path data-c="20" d="" transform="translate(3728,0)"></path><text data-variant="normal" transform="translate(3978,0) scale(1,-1)" font-size="884px" font-family="serif">假</text><text data-variant="normal" transform="translate(4878,0) scale(1,-1)" font-size="884px" font-family="serif">负</text><text data-variant="normal" transform="translate(5778,0) scale(1,-1)" font-size="884px" font-family="serif">例</text></g><rect width="6878" height="60" x="120" y="220"></rect></g><g data-mml-node="mstyle" transform="translate(11151.6,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(12151.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(12540.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(13818.6,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p><p>F分数，即F1分数，是精确度和召回率之间的调和平均值。基于F-beta分数，其中精确度和召回率根据beta值具有不同的权重 [19]。当beta为1时，精确度和召回率具有相等的权重（即，相等的重要性）。</p><p><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.081ex" xmlns="http://www.w3.org/2000/svg" width="43.105ex" height="5.574ex" role="img" focusable="false" viewBox="0 -1543.9 19052.4 2463.9"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="46" d="M128 619Q121 626 117 628T101 631T58 634H25V680H582V676Q584 670 596 560T610 444V440H570V444Q563 493 561 501Q555 538 543 563T516 601T477 622T431 631T374 633H334H286Q252 633 244 631T233 621Q232 619 232 490V363H284Q287 363 303 363T327 364T349 367T372 373T389 385Q407 403 410 459V480H450V200H410V221Q407 276 389 296Q381 303 371 307T348 313T327 316T303 317T284 317H232V189L233 61Q240 54 245 52T270 48T333 46H360V0H348Q324 3 182 3Q51 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path><path data-c="2D" d="M11 179V252H277V179H11Z" transform="translate(653,0)"></path><path data-c="62" d="M307 -11Q234 -11 168 55L158 37Q156 34 153 28T147 17T143 10L138 1L118 0H98V298Q98 599 97 603Q94 622 83 628T38 637H20V660Q20 683 22 683L32 684Q42 685 61 686T98 688Q115 689 135 690T165 693T176 694H179V543Q179 391 180 391L183 394Q186 397 192 401T207 411T228 421T254 431T286 439T323 442Q401 442 461 379T522 216Q522 115 458 52T307 -11ZM182 98Q182 97 187 90T196 79T206 67T218 55T233 44T250 35T271 29T295 26Q330 26 363 46T412 113Q424 148 424 212Q424 287 412 323Q385 405 300 405Q270 405 239 390T188 347L182 339V98Z" transform="translate(986,0)"></path><path data-c="65" d="M28 218Q28 273 48 318T98 391T163 433T229 448Q282 448 320 430T378 380T406 316T415 245Q415 238 408 231H126V216Q126 68 226 36Q246 30 270 30Q312 30 342 62Q359 79 369 104L379 128Q382 131 395 131H398Q415 131 415 121Q415 117 412 108Q393 53 349 21T250 -11Q155 -11 92 58T28 218ZM333 275Q322 403 238 411H236Q228 411 220 410T195 402T166 381T143 340T127 274V267H333V275Z" transform="translate(1542,0)"></path><path data-c="74" d="M27 422Q80 426 109 478T141 600V615H181V431H316V385H181V241Q182 116 182 100T189 68Q203 29 238 29Q282 29 292 100Q293 108 293 146V181H333V146V134Q333 57 291 17Q264 -10 221 -10Q187 -10 162 2T124 33T105 68T98 100Q97 107 97 248V385H18V422H27Z" transform="translate(1986,0)"></path><path data-c="61" d="M137 305T115 305T78 320T63 359Q63 394 97 421T218 448Q291 448 336 416T396 340Q401 326 401 309T402 194V124Q402 76 407 58T428 40Q443 40 448 56T453 109V145H493V106Q492 66 490 59Q481 29 455 12T400 -6T353 12T329 54V58L327 55Q325 52 322 49T314 40T302 29T287 17T269 6T247 -2T221 -8T190 -11Q130 -11 82 20T34 107Q34 128 41 147T68 188T116 225T194 253T304 268H318V290Q318 324 312 340Q290 411 215 411Q197 411 181 410T156 406T148 403Q170 388 170 359Q170 334 154 320ZM126 106Q126 75 150 51T209 26Q247 26 276 49T315 109Q317 116 318 175Q318 233 317 233Q309 233 296 232T251 223T193 203T147 166T126 106Z" transform="translate(2375,0)"></path></g><g data-mml-node="mo" transform="translate(3152.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mfrac" transform="translate(4208.6,0)"><g data-mml-node="mrow" transform="translate(220,710)"><g data-mml-node="mo"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="msup" transform="translate(389,0)"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mn" transform="translate(599,363) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1613.8,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mn" transform="translate(2614,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(3114,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(3725.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mtext" transform="translate(4725.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">精</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">确</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">度</text></g><g data-mml-node="mo" transform="translate(7647.7,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mtext" transform="translate(8647.9,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">召</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">回</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">率</text></g></g><g data-mml-node="mrow" transform="translate(1470.2,-719.9)"><g data-mml-node="msup"><g data-mml-node="mi"><path data-c="1D6FD" d="M29 -194Q23 -188 23 -186Q23 -183 102 134T186 465Q208 533 243 584T309 658Q365 705 429 705H431Q493 705 533 667T573 570Q573 465 469 396L482 383Q533 332 533 252Q533 139 448 65T257 -10Q227 -10 203 -2T165 17T143 40T131 59T126 65L62 -188Q60 -194 42 -194H29ZM353 431Q392 431 427 419L432 422Q436 426 439 429T449 439T461 453T472 471T484 495T493 524T501 560Q503 569 503 593Q503 611 502 616Q487 667 426 667Q384 667 347 643T286 582T247 514T224 455Q219 439 186 308T152 168Q151 163 151 147Q151 99 173 68Q204 26 260 26Q302 26 349 51T425 137Q441 171 449 214T457 279Q457 337 422 372Q380 358 347 358H337Q258 358 258 389Q258 396 261 403Q275 431 353 431Z"></path></g><g data-mml-node="mn" transform="translate(599,289) scale(0.707)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g></g><g data-mml-node="mo" transform="translate(1224.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mtext" transform="translate(2225,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">精</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">确</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">度</text></g><g data-mml-node="mo" transform="translate(5147.2,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mtext" transform="translate(6147.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">召</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">回</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">率</text></g></g><rect width="11547.9" height="60" x="120" y="220"></rect></g><g data-mml-node="mstyle" transform="translate(15996.4,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(16996.4,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(17385.4,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="33" d="M127 463Q100 463 85 480T69 524Q69 579 117 622T233 665Q268 665 277 664Q351 652 390 611T430 522Q430 470 396 421T302 350L299 348Q299 347 308 345T337 336T375 315Q457 262 457 175Q457 96 395 37T238 -22Q158 -22 100 21T42 130Q42 158 60 175T105 193Q133 193 151 175T169 130Q169 119 166 110T159 94T148 82T136 74T126 70T118 67L114 66Q165 21 238 21Q293 21 321 74Q338 107 338 175V195Q338 290 274 322Q259 328 213 329L171 330L168 332Q166 335 166 348Q166 366 174 366Q202 366 232 371Q266 376 294 413T322 525V533Q322 590 287 612Q265 626 240 626Q208 626 181 615T143 592T132 580H135Q138 579 143 578T153 573T165 566T175 555T183 540T186 520Q186 498 172 481T127 463Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(18663.4,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container><br><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -2.059ex" xmlns="http://www.w3.org/2000/svg" width="32.541ex" height="5.285ex" role="img" focusable="false" viewBox="0 -1426 14383 2336"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtext"><path data-c="46" d="M128 619Q121 626 117 628T101 631T58 634H25V680H582V676Q584 670 596 560T610 444V440H570V444Q563 493 561 501Q555 538 543 563T516 601T477 622T431 631T374 633H334H286Q252 633 244 631T233 621Q232 619 232 490V363H284Q287 363 303 363T327 364T349 367T372 373T389 385Q407 403 410 459V480H450V200H410V221Q407 276 389 296Q381 303 371 307T348 313T327 316T303 317T284 317H232V189L233 61Q240 54 245 52T270 48T333 46H360V0H348Q324 3 182 3Q51 3 36 0H25V46H58Q100 47 109 49T128 61V619Z"></path><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z" transform="translate(653,0)"></path></g><g data-mml-node="mo" transform="translate(1430.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(2486.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(3208.8,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mfrac" transform="translate(4209,0)"><g data-mml-node="mrow" transform="translate(247.8,676)"><g data-mml-node="mtext"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">精</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">确</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">度</text></g><g data-mml-node="mo" transform="translate(2922.2,0)"><path data-c="D7" d="M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z"></path></g><g data-mml-node="mtext" transform="translate(3922.4,0)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">召</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">回</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">率</text></g></g><g data-mml-node="mtext" transform="translate(220,-710)"><text data-variant="normal" transform="scale(1,-1)" font-size="884px" font-family="serif">精</text><text data-variant="normal" transform="translate(900,0) scale(1,-1)" font-size="884px" font-family="serif">确</text><text data-variant="normal" transform="translate(1800,0) scale(1,-1)" font-size="884px" font-family="serif">度</text><path data-c="20" d="" transform="translate(2700,0)"></path><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z" transform="translate(2950,0)"></path><path data-c="20" d="" transform="translate(3728,0)"></path><text data-variant="normal" transform="translate(3978,0) scale(1,-1)" font-size="884px" font-family="serif">召</text><text data-variant="normal" transform="translate(4878,0) scale(1,-1)" font-size="884px" font-family="serif">回</text><text data-variant="normal" transform="translate(5778,0) scale(1,-1)" font-size="884px" font-family="serif">率</text></g><rect width="6878" height="60" x="120" y="220"></rect></g><g data-mml-node="mstyle" transform="translate(11327,0)"><g data-mml-node="mspace"></g></g><g data-mml-node="mo" transform="translate(12327,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(12716,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path><path data-c="2E" d="M78 60Q78 84 95 102T138 120Q162 120 180 104T199 61Q199 36 182 18T139 0T96 17T78 60Z" transform="translate(500,0)"></path><path data-c="34" d="M462 0Q444 3 333 3Q217 3 199 0H190V46H221Q241 46 248 46T265 48T279 53T286 61Q287 63 287 115V165H28V211L179 442Q332 674 334 675Q336 677 355 677H373L379 671V211H471V165H379V114Q379 73 379 66T385 54Q393 47 442 46H471V0H462ZM293 211V545L74 212L183 211H293Z" transform="translate(778,0)"></path></g><g data-mml-node="mo" transform="translate(13994,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></svg></mjx-container></p><p>在优先考虑精确度或召回率的情况下，高度依赖于具体情境。由于它们通常对彼此产生相反的影响 [20]，最大化其中一个可能会降低另一个。在医学诊断中，假负例可能比假正例更昂贵（即，致命），因此在这种情况下可能更重要，应相应地加以权重。</p><h3>2.4 相关工作</h3><p>存在一些可以构建在其基础上的相关工作。具体而言，有关网络数据提取文献的调查（第2.4.1节），语言模型Bidirectional Encoder Representations from Transformers（BERT）（第2.4.3节）以及SOTA模型MarkupLM（第2.4.5节），本论文使用它们作为基础。</p><h4>2.4.1 网络数据提取调查</h4><p>Emilio Ferrara等人进行了一项调查，全面概述了网络数据提取领域的文献，并为网络数据提取应用提供了分类框架 [21]。他们确定了两种主要的算法方法：树匹配和机器学习算法。</p><h5>2.4.1.1 树匹配算法</h5><p>树匹配算法利用Web页面的半结构化特性，以HTML的形式表示为带有标签的有序根树，即DOM树。</p><p>这些类型的算法使用XPath语法处理DOM树中的特定元素。它们依赖于XPath表达式，以找到两个文档之间相似树的所谓树编辑距离匹配。类似于字符串编辑距离问题，两个有序树可以通过尽可能少的操作（即，节点删除、插入或替换）来相互转换以匹配。简单的树匹配算法 [22]是树编辑距离匹配问题的高效且易于实现的解决方案 [23]。</p><h5>2.4.1.2 机器学习算法</h5><p>机器学习算法是一种适用于具有不同结构的多个网站的领域特定提取的良好方法。这些算法依赖于手动标记的网站，以获取领域专业知识，一些最早使用机器学习的系统包括WIEN [24]、Rapier [25]和WHISK [26]。</p><p>WIEN专注于归纳学习技术，以自动生成包装器。生成的规则可能类似于“忽略所有字符，直到找到第一个’.’并提取餐厅名称，该字符串以第一个’:’结束。然后，再次忽略所有字符，直到找到’(‘并提取以’)’结束的字符串。” [27]。类似这样的规则会在存在多个对象的情况下重复，直到无法与其他对象匹配。</p><p>Rapier使用有限的句法和语义信息学习规则，而无需在文档之前进行解析或后处理。规则分为三种模式：前填充器、填充器和后填充器。其中前填充器和后填充器充当左右分隔符，而填充器模式描述目标信息结构。</p><p>WHISK生成可以处理各种结构的文档（从自由文本到HTML）的规则。这些规则是一种特殊类型的正则表达式（即，尝试与输入文本匹配的模式），由两个组件组成。第一个组件负责确定短语必须处于其中以使其相关的正确上下文，而另一个指定要提取的短语的哪些部分。</p><h4>2.4.2 网页表提取调查</h4><p>Shuo Zhang等人进行了一项调查 [28]，研究了有关网页表提取的文献。其目的是确定和描述几个网页表提取任务及其相互依赖关系。他们确定了六个主要类别，用于对文献进行分类。这些类别包括：表提取、表解释、表搜索、问题回答、知识库增强和表增强。</p><p>他们定义了一个表由以下元素组成：页面标题、标题、列、单元格、行、列和实体。提出了一种表分类方案，通过两个维度内容和布局来区分表。</p><h5>2.4.2.1 表提取</h5><p>表提取是在网页上检测和提取表格，然后以一致的格式存储的过程。在网上提取表格的第一步是过滤掉“不好的”表格（例如，用于布局或格式目的的表格）。这通常通过关系表分类来完成，以识别包含关系数据的表格。在这里，可以使用具有布局或内容类型特征的机器学习分类器。布局特征可以是行数、列数或平均单元格字符串长度。而内容类型特征可以是表体中非字符串数据的百分比、带</p><p>有数字字符的单元格的比例，或包含 <code>&lt;span&gt;</code> 标签的单元格的比例。类似的方法也可以用于表头检测和表类型分类，前者检测表是否包含标题行或列，而后者根据预定义的分类法对表进行分类。</p><h5>2.4.2.2 表解释</h5><p>表解释旨在发现网页上表格的语义，以便对表格中的数据进行智能处理。使用分类法来了解表列的含义以及它们是否与其他列相关。主要的任务有列类型识别、实体链接和关系提取。</p><p>列类型识别涉及确定列类型并定位核心列（即，主体列），通常是最左边的列。实体链接是指检测实体（例如，人物、组织和地点），这对于揭示语义至关重要。关系提取旨在将一对列与其内容之间的关系关联起来。</p><h5>2.4.2.3 表搜索</h5><p>表搜索通过关键字查询返回带有排名列表的表，其中查询可以是一个表或多个关键字。主要有基于关键字和基于表的两种搜索类型。基于关键字的搜索返回给定关键字查询的表的排名列表。</p><h5>2.4.2.4 问题回答</h5><p>问题回答试图使用表格中的结构化数据回答自然语言处理问题。使用表格回答问题的主要挑战是将非结构化查询与表格中的结构化信息匹配。将查询解析为形式化表示的任务称为语义解析，其中生成逻辑表达式，可在知识库上执行。</p><h5>2.4.2.5 知识库增强</h5><p>知识库增强使用表格数据来探索、扩展或构建知识库。知识探索可以在具有属性搜索查询或实体关系查询的表格上进行。通过使用知识库进行注释，然后从表格中提取信息，可以扩展现有的知识库。如果表格包含丰富的信息，它可以转化为新的知识库。</p><h5>2.4.2.6 表增强</h5><p>表增强通过添加附加数据扩展现有表格。它可以分为三个任务：行扩展、列扩展和数据完成。行扩展通常应用于水平关系表。相反，列扩展通常通过查找相似的表格，然后评估这些表格中的列标题和值来添加额外的列。数据完成可以应用于整个列，通过匹配来自其他表格的类似列，或在单个单元格上使用机器学习算法，例如k最近邻或线性回归。</p><h5>2.4.3 双向编码器表示转换器</h5><p>Jacob Devlin等人提出了一种名为BERT的新语言表示模型 [29]。预训练语言模型已被证明可以在句子和标记级别的任务上提高几种自然语言处理问题。然而，以前的技术限制了预训练模型的体系结构选择，使其能够联合条件化左侧和右侧（即双向）上下文，这对于标记级别的任务如问答至关重要。BERT通过利用Transformer体系结构（第2.2.3节）和两个预训练目标实现了双向预训练。</p><p>该体系结构是一个多层双向Transformer编码器，并具有需要最小更改用于最终下游体系结构的属性。输入表示可以处理单个和多个句子作为输入序列，并以三种方式嵌入：令牌、段和位置嵌入。这三种嵌入求和以表示输入嵌入，如图2.6所示。一个令牌可以是三种情况之一：特殊的序列开始令牌（[CLS]），一个单词或一个分隔令牌（[SEP]）以区分句子。特定于序列中的令牌所属的段嵌入（例如，句子A或B）。位置嵌入编码了序列中令牌的位置。</p><img width="499" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/a80b8b0a-5db7-48fc-a524-5d582cf98928"><p>两个目标，遮蔽语言建模（MLM）和下一句预测（NSP），在预训练期间被使用。MLM通过随机遮蔽输入标记的一部分，然后训练模型预测被遮蔽标记，使模型学习双向表示。NSP使模型学习两个句子之间的关系。选择两个句子A和B，其中句子B一半的时间被随机替换，要求模型预测句子B是否跟随句子A。</p><p>BERT使用两个数据集进行预训练：BooksCorpus [30]（800M字）和English Wikipedia（2500M字）。BERT是第一个基于微调的表示模型，在多个标记和句子级任务上取得了SOTA结果，如通用语言理解评估（GLUE）[31]、斯坦福问答数据集（SQuAD）[32]和带有对抗生成的情境（SWAG）[33]。</p><h4>2.4.4 SimpDOM</h4><p>Yichao Zhou等人探索了在相同垂直领域内从多个网站提取数据的可能性 [34]。他们提出的模型∗，称为SimpDOM，在使用Few-Shot Learning（FSL）准确提取未见网站的数据时取得了SOTA结果。</p><p>SimpDOM模型的主要思想是专注于HTML页面的DOM树表示，并为每个变量节点构建丰富的表示。该方法避免了昂贵的网页呈现过程，利用DOM树中节点属性值的语义。</p><p>该架构由DOM树简化模块、离散特征模块和文本编码器组成。DOM树简化模块提取具有不同值的所有节点的上下文（因为在数据点之间具有相同值的节点不感兴趣）。上下文是其友好节点（即附近节点）的特征。离散特征模块通过添加额外的离散特征（例如XPath、叶节点类型和相对节点位置）来增强节点表示。文本编码器是CNN-LSTM的组合，对字符和单词级特征进行编码。</p><p>使用Structured Web Data Extraction（SWDE）数据集对SimpDOM进行评估。该数据集最初由郝强等人创建 [35]，包含来自80个不同网站的124,000个标记页面，分为八个垂直领域（例如汽车、图书和电影），每个领域包含3到5个感兴趣的属性（例如标题和作者）。在每个垂直领域中，使用10个网站中的5个作为种子站点（即训练集中的站点），SimpDOM实现了93.75的平均F1分数。</p><p>SimpDOM的作者选择使用一个基于Global Vectors for Word Representation（GloVe）[36]架构训练的，包含60亿标记的著名预训练词嵌入来初始化他们的模型。</p><h4>2.4.5 MarkupLM</h4><p>Junlong Li等人研究了创建一个模型∗，能够解决多个文档理解任务，适用于视觉丰富的标记文档，如HTML和XML文件 [37]。任务包括文档理解、类型分类和视觉问答。通过利用DOM树，可以对文档的不同元素之间建模位置关系，而不是使用显式的2D表示，这对文档渲染的设备高度依赖。通过使用DOM树建模位置关系而不使用渲染的2D可视化，简化了预训练，同时仍然利用了文档布局。</p><p>BERT [29]体系结构被用作编码器，其中嵌入层扩展了额外的输入XPath嵌入。然后，该模型通过三个主要目标进行预训练：遮蔽标记语言建模（MMLM），节点关系预测（NRP）和标题页匹配（TPM）。MMLM是MLM的扩展，通过使用文本和标记作为输入，遮</p><img width="496" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/03eed6a4-bfc1-40bc-a231-8ed78c21932d"><h4>2.4.6 DOM-LM</h4><p>邓翔等人提出了一种能够解决类似文档理解任务的模型，与MarkupLM一样，利用了DOM树表示法，就像以前的工作所做的一样 [39]。该模型基于BERT（与MarkupLM相同），其参数是从预训练的BERT模型（对非结构化文本进行预训练）中初始化的，然后进一步训练以捕获HTML文档的结构和布局信息。该模型以两个目标进行预训练：遮蔽节点预测（MNP）和遮蔽标记预测（MTP）。MTP类似于BERT中执行的MLM目标（以及MarkupLM中的修改变体MMLM）。MNP通过不仅遮蔽输入标记而且遮蔽整个节点来进一步概括模型，以迫使模型学习树级上下文化，并对布局具有整体视图。</p><p>该模型的主要方法是将文档编码为一组子树，其中嵌入了位置信息，并采用了自监督预训练。首先通过去除与网页结构和语义无关的所有DOM节点（例如，<code>&lt;script&gt;</code> 和 <code>&lt;style&gt;</code> 元素），然后将树分割成子树来构建一组子树。分割是通过在整个DOM树上应用具有固定步长（即单位）的滑动窗口来完成的。滑动是这样进行的，以便在同一直接周围的节点被捕获在同一子树中。</p><p>在培训过程中使用的数据量与SimpDOM和MarkupLM中使用的数量有所不同。DOM-LM仅使用了10％的种子站点（2和5）的数据，而不是所有的数据，这与SimpDOM和MarkupLM不同。结果可见于表2.2。</p><img width="494" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/6c4a8b89-49a5-4e4b-ae9d-533391a8c3b4"><h3>2.5 总结</h3><p>本章在第2.1节介绍了相关的关键网络技术DOM和XPath，第2.2节介绍了深度学习架构，如RNN和Transformer，第2.3节介绍了度量标准，第2.4节介绍了相关工作，如BERT和MarkupLM。</p><h2>3、方法</h2><p>在本章中，介绍了研究方法。研究过程在第3.1节中描述，数据收集过程在第3.2节中描述，最后，在第3.3节中描述了实验设计和评估框架。</p><h3>3.1 研究过程</h3><p>该论文遵循设计科学研究过程，该过程可以分为六个活动，如Ken Peffers等人在[40]中提出的。这些活动包括：问题识别和动机、解决方案目标、设计和开发、演示、评估和沟通。根据这个过程，研究人员并不被期望按顺序进行这些活动，而是取决于所选择的方法（例如，问题中心或目标中心）。<br>问题识别和动机的活动涉及具体说明研究问题并证明解决方案的价值。这可以通过获取有关问题状态和解决方案重要性的知识来实现。<br>解决方案目标指的是解决方案的定量或定性目标。这些目标通常涉及所期望的解决方案，该解决方案应更好或解决未解决的问题。在这个阶段，需要了解当前解决方案。</p><p>设计和开发涉及创建一种工件解决方案（例如，构造、模型、方法）。在创建解决方案之前，需要理解理论，决定工件的功能和架构。</p><p>演示工件在解决问题时的有效性。这可以通过实验、模拟、证明或案例研究来完成。</p><p>评估是衡量工件支持问题解决的效果。通过使用相关的度量和分析技术，可以确定工件的有效性，并作为迭代回活动3（设计和开发）的基础，以尝试在可行的情况下改进工件。</p><p>沟通是最后的活动，在其中整个过程都被记录在研究论文中。这包括问题及其重要性、工件及其效用、研究的设计以及与社区的相关性。</p><p>问题是在主机公司识别的，解决方案得到了证明。随后进行文献研究以更好地了解问题的状态和当前的解决方案。然后确定了建立在当前解决方案基础上以在新环境中解决问题的目标。工件的评估类似于相关工作中的模型。最后，在这篇论文中记录了整个过程。</p><h3>3.2 数据收集</h3><p>汽车保险数据来自几家瑞典保险公司，其中主机公司目前使用和维护手工制作的包装器。数据将采用HTML的形式，并附有JSON文件，表示由包装器提取的值的基本事实。敏感用户信息在用于模型之前被混淆。仅使用具有不为空的JSON对应文件的HTML文件。如果JSON中没有提取的值，则假定包装器失败或用户在给定网站上没有保险。</p><h3>3.3 实验设计</h3><p>实验设计遵循相关工作中使用的设计[34, 35, 37]，在k个种子站点上对模型进行微调，然后在其余的n−k个站点上进行评估（即零-shot学习）。评估指标是页面级F1分数，最终F1分数是每个k的所有排列的平均值。模型使用一个瑞典和一个英文预训练模型初始化，然后进行实验性评估和比较。</p><p>模型在深度学习的Amazon Machine Image（AMI）[41]上进行训练，实例类型为G4dn [42]，具有以下规格：1个Nvidia Tesla T4图形处理单元（GPU），8个Intel Cascade Lake虚拟中央处理单元（CPU），32GB内存。</p><h2>4、实现</h2><p>本章描述了获取数据集和修改针对性网站的开源模型的步骤。数据预处理步骤在第4.1节中介绍，MarkupLM模型的实施和修改细节在第4.2节中给出。</p><h3>4.1 数据预处理</h3><p>在使用模型训练数据之前，数据需要进行处理。从公司收到的数据包括三种类型的文件：HTML、JSON和文本（日志）文件。HTML文件包含用户的保险数据，并且仅限于包含单一保险的页面（省略包含多个保险的HTML文件）。JSON文件包含目标属性的提取数据，公司手动开发的包装器执行提取。最初的计划是使用JSON数据作为数据集的基本事实，但由于某些值是使用正则表达式进行转换的，因此与HTML中的文本不是精确匹配，这是不可能的。日志文件包含包装器整个执行流程的日志消息。幸运的是，提取的值在转换之前被转储到日志中，因此可以使用日志中的数据作为基本事实。<br>模型要提取的属性数量被限制为三家选定公司的较大部分数据中出现的五个属性：Trygg-Hansa、If和Moderna。数据集中仅使用包含所有属性的数据点。这五个属性是：保险覆盖类型、保险单号、年度保费金额、续保日期和车辆注册号。每家公司的数据点数量如表4.1所示，每个属性的统计信息如表4.2所示。</p><img width="427" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/d24d2b15-9220-40ac-ad36-81a77e4b61a5"><img width="527" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/d4d515e7-8d6e-4d9b-81b2-474df1cea7ba"><h3>4.1.1 基本事实</h3><p>通过解析包含以JSON格式提取和未经处理的值的日志，生成了包含HTML和基本事实文件的数据集。基本事实JSON中的对象通过保险类型（即汽车保险）进行过滤。如果网页上有其他类型的保险或超过一种汽车保险，则会省略数据点。之所以这样做，是因为三家公司中有两家公司在单个网页上显示客户的所有保险，而在DOM树中没有区分。这意味着所有保险都以相同的HTML列表对象的方式列出，而且在其中没有任何特定顺序，这样模型就很难学习上下文如何区分一个保险对象和另一个保险对象。</p><h3>4.1.2 数据模糊化</h3><p>在数据集可以传输到AMI并在模型中使用之前，必须模糊化可以与特定个人关联的所有敏感数据。属性保单持有人、地址、保险单号和车辆注册号都被替换为随机生成的值。使用网站www. fejk.se生成虚假姓名、个人身份号码和地址，而使用Python脚本生成保险和车辆注册号。</p><h2>4.2 实施</h2><p>所使用的模型基于开源模型MarkupLM [37]，该模型在第2.4.5节中有描述。此模型使用Python编写，使用Pytorch机器学习框架 [43] 和提供API以轻松下载和训练SOTA预训练模型的Transformers库 [44]。模型的执行步骤如图4.1所示。<br>第一步将HTML文件打包成适当的Python数据对象，然后将它们序列化为单个文件，这是使用pickle库 [45] 完成的。第二步创建了每个HTML文件与相应基本事实之间的映射，并将其作为pickle文件分别存储在每个网站上。最后一步使用所有种子站点的排列训练和评估模型，其中在训练之前使用预训练的模型初始化。模型在多个周期（即在训练集中循环）中进行训练，最后在未被种子化的每个网站上进行评估。</p><img width="261" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/a30c1520-1efe-46c8-a94b-aefa952e42a1"><p>大部分的修改发生在数据准备和评估步骤。数据准备步骤，即HTML与基本事实之间的映射，需要修改以处理瑞典字符，并处理网站的边缘情况，其中基本事实的值并未单独位于正确的节点中，而必须使用正则表达式进行匹配。评估步骤通过更详细的记录和在每个周期后进行模型评估，引入了早停机制，以在训练损失不再降低时终止训练。<br>在对保险数据集进行微调之前，MarkupLM模型是使用预训练模型初始化的。论文中使用的两个预训练模型是MarkupLMLARGE和来自瑞典国家图书馆的瑞典BERT模型。</p><h3>4.2.1 MarkupLM-LARGE</h3><p>MarkupLM论文的作者们 [37] 也开源了两个预训练模型，MarkupLMBASE和MarkupLMLARGE。他们首先在Common Crawl（CC）数据集∗的 2400 万个英语网页上对MarkupLM模型进行了预训练，该数据集使用了原始论文作者发布的Robustly Optimized BERT pretraining Approach (RoBERTa)模型进行初始化 [46]。然后在SWDE数据集上对该模型进行了微调。MarkupLMLARGE在SWDE上的性能见表2.1。</p><h3>4.2.2 瑞典BERT</h3><p>瑞典国家图书馆（瑞典文：Kungliga biblioteket）于2020年发布了三个基于BERT和A Lite BERT (ALBERT) [47] 的预训练瑞典语言模型。这些模型是在一个18,341 MB的瑞典文语料库上进行训练的，该语料库由报纸、政府报告、法定电子存档、社交媒体评论和维基百科的文本组成。他们的预训练BERT模型名为KB-BERT，用于在微调之前初始化模型。初始化是通过使用Transformers库实现的，加载托管在AI社区站点Hugging Face [48] 上的预训练模型，该站点还负责Transformers库。表4.3显示了两个预训练模型的一些关键模型配置参数，这些参数遵循原始BERT论文的设置（除了词汇表大小）。</p><img width="434" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/05e280a7-f189-49d5-82ac-9bb5631dedfb"><h2>5、结果</h2><p>这一章介绍了模型评估的结果。以精确度、召回率和F1分数为指标，展示了两个模型的页面级结果，并详细分析了属性级结果。</p><p>两个模型的总体结果显示在表5.1中。使用KB-BERT初始化的模型在训练过程中使用一个种子站点时，最佳F1分数为41.4，当使用两个种子站点时为47.3。使用MarkupLMLARGE初始化的模型在使用一个种子站点进行训练时，最佳F1分数为80.2，使用两个种子站点时为88.9。在评估过程中变化的最佳设置分别在表5.2和表5.3中显示，对应着一个和两个种子站点。</p><img width="517" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/01b15133-6bd0-4cdc-ab57-c92db267599e"><img width="499" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/da7cffd5-148d-4ef0-8d24-6d1e4258e5ea"><p>使用KB-BERT初始化的模型每个属性的F1分数显示在表5.4中。该模型无法学习保单号的表示，同时在处理年度保费属性时也存在一些问题。</p><img width="496" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/029d6b49-02a7-471d-8d09-a28180880c8d"><p>使用MarkupLMLARGE初始化的模型每个属性的F1分数显示在表5.5中。该模型对大多数属性学到了一个表示，但在处理保险类型属性时并不那么成功。</p><img width="497" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/13558459-3124-4480-998b-3cb114459e0d"><h2>6、讨论</h2><p>这一章将讨论第5章中提出的结果，同时也将包括对实现目标（第1.4节）和研究问题（第1.2节）的探讨。</p><h3>6.1 结果</h3><p>结果表明，尽管MarkupLMLARGE模型并不“理解”瑞典语，而是学会了HTML的一般结构，但它在预训练模型的强大性上表现出色。这一事实事后看来并不令人惊讶，因为选择的五个属性中有四个不特定于瑞典语。</p><p>使用MarkupLMLARGE初始化的模型在三个属性上表现非常好：保险单号、续保日期和车辆注册号，在使用一个和两个种子站点时，F1分数均超过94%。保险单号具有特定格式（例如123 456 789、AB00123456.2.3和123456-78），每家公司有时甚至有几种格式。续保日期始终以YYYY-MM-DD的格式呈现，而车辆注册号有两种格式之一，即ABC123或ABC12D。年度保费这个属性的得分相对较低，这很可能是因为它在不同公司之间的格式不同，有时包含瑞典语词汇（例如“年”这个瑞典词）。然而，即使对于只包含瑞典语词汇的保险类型属性，该模型在某种程度上也成功地学到了，特别是在将种子站点数量从一个增加到两个时。</p><p>与MarkupLMLARGE初始化的模型相比，使用KB-BERT初始化的模型表现相对较差。使用一个和两个种子站点时，得分最高的属性是覆盖类型和续保日期，F1分数均超过71%。覆盖类型通常是“halvförsäkring”、“helförsäkring”、“trafikförsäkring”或其变体中的一个词，这是模型在这方面优于MarkupLMLARGE初始化的模型的唯一属性。令人惊讶的是，该模型无法学习保险单号的表示，对于使用一个和两个种子站点时的F1分数均低于4%。这可能是由于不同公司之间的格式不一致，再加上一些格式包含标点符号，这可能使学习变得更加困难，因为BERT将标点符号视为输入序列中“句子”的分隔符。</p><p>另一个方面是，瑞典BERT使用了较小的BERTBASE的参数，而MarkupLMLARGE使用了较大的BERTLARGE，它们在隐藏层的数量、隐藏层的大小以及每个隐藏层的注意头的数量上存在差异（如表4.3所示）。然而，在原始的BERT论文[29]中，BERTLARGE在GLUE基准上的得分约高出BERTBASE约3%，而在使用5个种子站点时，MarkupLMLARGE在SWDE数据集上的得分比MarkupLMBASE高出约1.5%。这应该表明，性能的这种大差异不能仅通过网络大小的差异来解释。</p><p>在表5.2和表5.3中显示的设置是为了寻找最佳精度而进行的调整的设置。在表现最佳的运行之间，最常见的批量大小为2。这似乎是合理的，因为数据集很小，数据集中最大的公司有100个数据点，而最小的公司只有23个。用于上下文的前面节点的最佳数量是4。训练时间的巨大差异可以通过两个预训练模型之间的参数差异（主要是层数和层大小）来解释。作为参考，BERT论文的作者使用4个云张量处理单元（TPU）[49]对BERTBASE进行了训练，分别对BERTLARGE进行了16个云TPU的训练，分别进行了4天的训练。</p><h3>6.2 指标选择</h3><p>在网络数据提取领域存在多种度量标准，然而，本论文专注于三个准确性指标：召回率、精确度和F分数。尽管这些指标并非完美[50]，但它们在机器学习评估中被广泛使用。由于大多数相关工作都在使用这些指标，尽管它们在处理负面例子时表现不佳，但它们被选择了。F分数的beta值被选择为1（即F1分数），因为没有（通过主机公司）明确要求将精确度优先于召回率，反之亦然。</p><h3>6.3 达到目标</h3><p>在第1.4节中提到的四个子目标是：数据集获取、模型识别、模型修改和模型评估。根据结果，可以说这四个子目标都已经实现。</p><p>收集到的数据比预期的要小，无论是从公司和网站的数量上还是从每家公司和网站的数据点数量上。然而，尽管数据集相对较小，MarkupLMLARGE模型取得了相对较好的分数，展示了预训练模型的强大性能。</p><p>模型的识别是成功的，并导致了SOTA模型MarkupLM的产生，尽管最初选择的是SimpDOM（第2.4.4节），这在第7章中作为一个局限性进一步讨论。模型修改按照最初的计划使用了一个预训练的瑞典BERT</p><p>模型，尽管其性能不及MarkupLM作者发布的预训练模型。最后，该模型使用了两个不同的预训练模型，在使用一个和两个种子站点时进行了评估。</p><h3>6.4 回答研究问题</h3><p>最初提出的研究问题是：</p><p>一个带有监督学习的网络数据提取模型在从未见过的瑞典保险网站中提取信息的能力如何？</p><p>最初的假设是这样的系统必须对瑞典语有一个良好的表示才能有效，因此需要使用在瑞典语上进行预训练的语言模型进行探索。然而，结果表明，这种对语言的依赖性表示不一定是必要的，至少当大多数属性不是语言特定的或者在其上下文中不被语言特定的文本包围时。此外，即使对于语言特定的属性，例如保险类型，也是在既预训练于英语语言又预训练于网页的模型表现得更好，而后者仅在瑞典语上进行了预训练。</p><p>对研究问题的回答是这样的模型实际上在瑞典保险网站上表现良好，达到了与在SWDE数据集上的SOTA模型相似的结果（如表2.1所示）。</p><h2>7、结论与未来工作</h2><h3>7.1 结论</h3><p>最初的假设认为在瑞典网站上，以英语数据为基础的模型性能较差。然而，结果表明，如果属性不包含特殊的瑞典字符，这样的模型表现良好。这种模型的学习强调HTML文档结构，特别是当值嵌入在结构化格式（如表格）中时。虽然没有达到100%的准确性，但在手动创建的包装器因站点故障或HTML更改而失败的情景下，该模型可能会很有价值。</p><h3>7.2 限制</h3><p>显著的限制包括有限的可用数据量，导致较少的候选公司可供论文使用。数据的倾斜和耗时的预处理影响了模型的探索。尝试复制 SimpDOM 的努力没有成功，妨碍了与 MarkupLM 的潜在比较。</p><h3>7.3 未来工作</h3><p><strong>尚未完成的工作</strong></p><ul><li>探索提取不可靠出现在大多数客户数据中的属性。</li><li>调查在网页上显示多个保险政策的情况。</li><li>为潜在的准确性提升调整学习率和丢失概率等超参数。</li></ul><p><strong>下一个明显需要做的事</strong></p><ul><li>评估在其他行业培训模型的好处。</li><li>探索少样本学习，对目标网站进行更多的手动标记。</li><li>考虑混合方法，利用开源模型提取特定属性。</li></ul><h3>7.4 反思</h3><p>从经济角度来看，所探讨的模型减少了在相同行业内设置数据提取的手动工作，并减少了对覆盖的网站进行的维护。与模型培训相关的计算成本可以通过使用开源预训练模型来缓解。伦理考虑涉及根据政府政策和法规处理客户数据。敏感数据的混淆是一种方法，但自动确定哪些数据是敏感并需要混淆是本工作范围之外的问题。</p><p>引用：</p><ul><li>[1] R. Kosala and H. Blockeel, “Web mining research: a survey,” ACM SIGKDD Explorations Newsletter, vol. 2, no. 1, pp. 1–15, Jun. 2000. doi: 10.1145/360402.360406. [Online]. Available: <a href="https://dl.acm.org/doi/10.1145/360402.360406">https://dl.acm.org/doi/10.1145/360402.360406</a> [Page 1.]</li><li>[2] J. Wang and F. H. Lochovsky, “Data extraction and label assignment for web databases,” in Proceedings of the twelfth international conference on World Wide Web - WWW ’03. Budapest, Hungary: ACM Press, 2003. doi: 10.1145/775152.775179. ISBN 978-1-58113-680-7 p. 187. [Online]. Available: <a href="http://portal.acm.org/citation.cfm?doid=775152.775179">http://portal.acm.org/citation.cfm?doid=775152.775179</a> [Page 1.]</li><li>[3] A. Troestler and H. P. Lee, “The adaptation and standardization on websites of international companies : Analysis and comparison from websites of United States, Germany and Taiwan,” Ph.D. dissertation, Linköping University, 2007. [Online]. Available: <a href="http://urn.kb.se/resolve?urn=urn:nbn:se:liu:diva-9801">http://urn.kb.se/resolve?urn=urn:nbn:se:liu:diva-9801</a> [Page 1.]</li><li>[4] S. Flesca, G. Manco, E. Masciari, E. Rende, and A. Tagarelli, “Web wrapper induction: a brief survey,” AI Communications, vol. 17, no. 2, pp. 57–61, Apr. 2004. [Online]. Available: <a href="https://dl.acm.org/doi/10.5555/1218702.1218707">https://dl.acm.org/doi/10.5555/1218702.1218707</a> [Page 2.]</li><li>[5] “Document Object Model (DOM),” Dec. 2021. [Online]. Available: <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model">https://developer.mozilla.org/en-US/docs/Web/API/Document_Object_Model</a> [Pages 2 and 5.]</li><li>[6] K. Lerman, S. N. Minton, and C. A. Knoblock, “Wrapper Maintenance:A Machine Learning Approach,” Journal of Artificial Intelligence Research, vol. 18, pp. 149–181, Feb. 2003. doi: 10.1613/jair.1145. [Online]. Available: <a href="https://jair.org/index.php/jair/article/view/10325">https://jair.org/index.php/jair/article/view/10325</a> [Page 2.]</li><li>[7] Hevner, March, Park, and Ram, “Design Science in Information Systems Research,” MIS Quarterly, vol. 28, no. 1, p. 75, 2004. doi: 10.2307/25148625. [Online]. Available: <a href="https://www.jstor.org/stable/10.2307/25148625">https://www.jstor.org/stable/10.2307/25148625</a> [Page 3.]</li><li>[8] R. Baumgartner, W. Gatterbauer, and G. Gottlob, “Web Data Extraction System,” in Encyclopedia of Database Systems, L. Liu and M. T.Özsu, Eds. Boston, MA: Springer US, 2009, pp. 3465–3471. ISBN978-0-387-39940-9. [Online]. Available: <a href="http://link.springer.com/10.1007/978-0-387-39940-9_1154">http://link.springer.com/10.1007/978-0-387-39940-9_1154</a> [Page 5.]</li><li>[9] “XPath,” Jan. 2022. [Online]. Available: <a href="https://developer.mozilla.org/en-US/docs/Web/XPath">https://developer.mozilla.org/en-US/docs/Web/XPath</a> [Page 6.]</li><li>[10] “Introducing JSON.” [Online]. Available: <a href="https://json.org/json-en.html">https://json.org/json-en.html</a> [Page 6.]</li><li>[11] “What is Deep Learning?” May 2020. [Online]. Available: <a href="https://www.ibm.com/cloud/learn/deep-learning">https://www.ibm.com/cloud/learn/deep-learning</a> [Page 7.]</li><li>[12] J. Patterson and A. Gibson, Deep learning: a practitioner’s approach, 1st ed. Sebastopol, CA: O’Reilly, 2017. ISBN 978-1-4919-1425-0 [Pages 7, 8, and 9.]</li><li>[13] D. Hendrycks and K. Gimpel, “Gaussian Error Linear Units (GELUs),” arXiv:1606.08415 [cs], Jul. 2020. [Online]. Available: <a href="http://arxiv.org/abs/1606.08415">http://arxiv.org/abs/1606.08415</a> [Page 9.]</li><li>[14] S. Hochreiter and J. Schmidhuber, “Long Short-Term Memory,” Neural Computation, vol. 9, no. 8, pp. 1735–1780, Nov. 1997. doi:10.1162/neco.1997.9.8.1735. [Online]. Available: <a href="https://direct.mit.edu/neco/article/9/8/1735-1780/6109">https://direct.mit.edu/neco/article/9/8/1735-1780/6109</a> [Page 9.]</li><li>[15] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, ff. Kaiser, and I. Polosukhin, “Attention is All you Need,” in Advances in Neural Information Processing Systems, I. Guyon, U. V.Luxburg, S. Bengio, H. Wallach, R. Fergus, S. Vishwanathan, and R. Garnett, Eds., vol. 30. Curran Associates, Inc., 2017. [Online]. Available: <a href="https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf">https://proceedings.neurips.cc/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf</a> [Page 10.]</li><li>[16] X. Qiu, T. Sun, Y. Xu, Y. Shao, N. Dai, and X. Huang, “Pretrained models for natural language processing: A survey,” ScienceChina Technological Sciences, vol. 63, no. 10, pp. 1872–1897, Oct. 2020. doi: 10.1007/s11431-020-1647-3. [Online]. Available: <a href="https://link.springer.com/10.1007/s11431-020-1647-3">https://link.springer.com/10.1007/s11431-020-1647-3</a> [Page 10.]</li><li>[17] K. Weiss, T. M. Khoshgoftaar, and D. Wang, “A survey of transfer learning,” Journal of Big Data, vol. 3, no. 1, p. 9, Dec. 2016. doi: 10.1186/s40537-016-0043-6. [Online]. Available: <a href="http://journalofbigdata.springeropen.com/articles/10.1186/s40537-016-0043-6">http://journalofbigdata.springeropen.com/articles/10.1186/s40537-016-0043-6</a> [Page 10.]</li><li>[18] X. Han, Z. Zhang, N. Ding, Y. Gu, X. Liu, Y. Huo, J. Qiu, Y. Yao, A. Zhang, L. Zhang, W. Han, M. Huang, Q. Jin, Y. Lan, Y. Liu, Z. Liu,Z. Lu, X. Qiu, R. Song, J. Tang, J.-R. Wen, J. Yuan, W. X. Zhao, and J. Zhu, “Pre-trained models: Past, present and future,” AI Open, vol. 2, pp. 225–250, 2021. doi: 10.1016/j.aiopen.2021.08.002. [Online]. Available: <a href="https://linkinghub.elsevier.com/retrieve/pii/S2666651021000231">https://linkinghub.elsevier.com/retrieve/pii/S2666651021000231</a> [Page 10.]</li><li>[19] G. Bonaccorso, Machine Learning Algorithms, 2nd ed. Packt, 2018. ISBN 978-1-78934-799-9 [Page 11.]</li><li>[20] M. Buckland and F. Gey, “The relationship between Recall and Precision,” Journal of the American Society for Information Science, vol. 45, no. 1, pp. 12–19, 1994. [Page 11.]</li><li>[21] E. Ferrara, P. De Meo, G. Fiumara, and R. Baumgartner, “Web data extraction, applications and techniques: A survey,” Knowledge-Based Systems, vol. 70, pp. 301–323, Nov. 2014. doi: 10.1016/j.knosys.2014.07.007. [Online]. Available: <a href="https://linkinghub.elsevier.com/retrieve/pii/S0950705114002640">https://linkinghub.elsevier.com/retrieve/pii/S0950705114002640</a> [Page 12.]</li><li>[22] S. M. Selkow, “The tree-to-tree editing problem,” Information Processing Letters, vol. 6, no. 6, pp. 184–186, Dec. 1977. doi: 10.1016/0020-0190(77)90064-3. [Online]. Available: <a href="https://linkinghub.elsevier.com/retrieve/pii/0020019077900643">https://linkinghub.elsevier.com/retrieve/pii/0020019077900643</a> [Page 12.]</li><li>[23] P. Kilpeläinen, “Tree matching problems with applications to structured text databases,” Ph.D dissertation, University of Helsinki, Department of Computer Science, Helsinki, Finland, Nov. 1992. [Page 12.]</li><li>[24] N. Kushmerick, D. S. Weld, and R. B. Doorenbos, “Wrapper Induction for Information Extraction,” in IJCAI, 1997. [Page 12.]</li><li>[25] R. Mooney, “Relational learning of pattern-match rules for information extraction,” in Proceedings of the sixteenth national conference on artificial intelligence, vol. 328, 1999, p. 334. [Page 12.]</li><li>[26] S. Soderland, “Learning information extraction rules for semi-structured and free text,” Machine learning, vol. 34, no. 1, pp. 233–272, 1999, publisher: Springer. [Page 12.]</li><li>[27] I. Muslea and others, “Extraction patterns for information extraction tasks: A survey,” in The AAAI-99 workshop on machine learning for information extraction, vol. 2. Orlando Florida, 1999, issue: 2. [Page 13.]</li><li>[28] S. Zhang and K. Balog, “Web Table Extraction, Retrieval, and Augmentation: A Survey,” ACM Transactions on Intelligent Systems and Technology, vol. 11, no. 2, pp. 1–35, Apr. 2020. doi: 10.1145/3372117. [Online]. Available: <a href="https://dl.acm.org/doi/10.1145/3372117">https://dl.acm.org/doi/10.1145/3372117</a> [Page 13.]</li><li>[29] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding,” arXiv:1810.04805 [cs], May 2019. [Online]. Available: <a href="http://arxiv.org/abs/1810.04805">http://arxiv.org/abs/1810.04805</a> [Pages 15, 17, and 36.]</li><li>[30] Y. Zhu, R. Kiros, R. Zemel, R. Salakhutdinov, R. Urtasun, A. Torralba, and S. Fidler, “Aligning books and movies: Towards story-like visual explanations by watching movies and reading books,” in Proceedings of the IEEE international conference on computer vision, 2015, pp. 19–27.[Page 16.]</li><li>[31] A. Wang, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman, “GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding,” arXiv:1804.07461 [cs], Feb. 2019. [Online]. Available: <a href="http://arxiv.org/abs/1804.07461">http://arxiv.org/abs/1804.07461</a> [Page 16.]</li><li>[32] P. Rajpurkar, J. Zhang, K. Lopyrev, and P. Liang, “SQuAD: 100,000+Questions for Machine Comprehension of Text,” arXiv:1606.05250 [cs], Oct. 2016. [Online]. Available: <a href="http://arxiv.org/abs/1606.05250[Page">http://arxiv.org/abs/1606.05250[Page</a> 16.]</li><li>[33] R. Zellers, Y. Bisk, R. Schwartz, and Y. Choi, “SWAG: A LargeScale Adversarial Dataset for Grounded Commonsense Inference,” arXiv:1808.05326 [cs], Aug. 2018. [Online]. Available: <a href="http://arxiv.org/abs/1808.05326">http://arxiv.org/abs/1808.05326</a> [Page 16.]</li><li>[34] Y. Zhou, Y. Sheng, N. Vo, N. Edmonds, and S. Tata, “Simplified DOM Trees for Transferable Attribute Extraction from the Web,”arXiv:2101.02415 [cs], Jan. 2021. [Online]. Available: <a href="http://arxiv.org/abs/2101.02415">http://arxiv.org/abs/2101.02415</a> [Pages 16, 18, 19, 22, and 41.]</li><li>[35] Q. Hao, R. Cai, Y. Pang, and L. Zhang, “From one tree to a forest: a unified solution for structured web data extraction,” in Proceedings of the34th international ACM SIGIR conference on Research and development in Information - SIGIR ’11. Beijing, China: ACM Press, 2011. doi:10.1145/2009916.2010020. ISBN 978-1-4503-0757-4 p. 775. [Online]. Available: <a href="http://portal.acm.org/citation.cfm?doid=2009916.2010020">http://portal.acm.org/citation.cfm?doid=2009916.2010020</a> [Pages 17, 18, 22, and 40.]</li><li>[36] J. Pennington, R. Socher, and C. Manning, “Glove: Global Vectors for Word Representation,” in Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). Doha, Qatar: Association for Computational Linguistics, 2014. doi: 10.3115/v1/D14-1162 pp. 1532–1543. [Online]. Available: <a href="http://aclweb.org/anthology/D14-1162">http://aclweb.org/anthology/D14-1162</a> [Page 17.]</li><li>[37] J. Li, Y. Xu, L. Cui, and F. Wei, “MarkupLM: Pre-training of Text and Markup Language for Visually-rich Document Understanding,”arXiv:2110.08518 [cs], Oct. 2021. [Online]. Available: <a href="http://arxiv.org/abs/2110.08518">http://arxiv.org/abs/2110.08518</a> [Pages 17, 22, 27, and 29.]</li><li>[38] B. Y. Lin, Y. Sheng, N. Vo, and S. Tata, “FreeDOM: A Transferable Neural Architecture for Structured Information Extraction on Web Documents,” in Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining. Virtual Event CA USA: ACM, Aug. 2020. doi: 10.1145/3394486.3403153. ISBN 978-1-4503-7998-4 pp. 1092–1102. [Online]. Available: <a href="https://dl.acm.org/doi/10.1145/3394486.3403153">https://dl.acm.org/doi/10.1145/3394486.3403153</a> [Page 18.]</li><li>[39] X. Deng, P. Shiralkar, C. Lockard, B. Huang, and H. Sun, “DOMLM: Learning Generalizable Representations for HTML Documents,” arXiv:2201.10608 [cs], Jan. 2022. [Online]. Available: <a href="http://arxiv.org/abs/2201.10608">http://arxiv.org/abs/2201.10608</a> [Page 18.]</li><li>[40] K. Peffers, T. Tuunanen, C. E. Gengler, M. Rossi, W. Hui, V. Virtanen, and J. Bragge, “Design Science Research Process: A Model for Producing and Presenting Information Systems Research,” arXiv:2006.02763 [cs], Jun. 2020. [Online]. Available: <a href="http://arxiv.org/abs/2006.02763">http://arxiv.org/abs/2006.02763</a> [Page 21.]</li><li>[41] “AWS Deep Learning AMIs.” [Online]. Available: <a href="https://aws.amazon.com/machine-learning/amis/">https://aws.amazon.com/machine-learning/amis/</a> [Page 23.]</li><li>[42] “Amazon EC2 G4 Instances.” [Online]. Available: <a href="https://aws.amazon.com/ec2/instance-types/g4/">https://aws.amazon.com/ec2/instance-types/g4/</a> [Page 23.]</li><li>[43] “Pytorch.” [Online]. Available: <a href="https://pytorch.org/">https://pytorch.org/</a> [Page 27.]</li><li>[44] “Transformers.” [Online]. Available: <a href="https://huggingface.co/transformers">https://huggingface.co/transformers</a> [Page 27.]</li><li>[45] “pickle — Python object serialization,” Apr. 2022. [Online]. Available: <a href="https://docs.python.org/3/library/pickle.html">https://docs.python.org/3/library/pickle.html</a> [Page 27.]</li><li>[46] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy, M. Lewis, L. Zettlemoyer, and V. Stoyanov, “RoBERTa: A Robustly Optimized BERT Pretraining Approach,” arXiv:1907.11692 [cs], Jul. 2019. [Online]. Available: <a href="http://arxiv.org/abs/1907.11692">http://arxiv.org/abs/1907.11692</a> [Page 29.]</li><li>[47] M. Malmsten, L. Börjeson, and C. Haffenden, “Playing with Words at the National Library of Sweden – Making a Swedish BERT,” arXiv:2007.01658 [cs], Jul. 2020. [Online]. Available: <a href="http://arxiv.org/abs/2007.01658">http://arxiv.org/abs/2007.01658</a> [Page 29.]</li><li>[48] “The AI community building the future.” [Online]. Available: <a href="https://huggingface.co/">https://huggingface.co/</a> [Page 29.]</li><li>[49] “Cloud TPU.” [Online]. Available: <a href="https://cloud.google.com/tpu/">https://cloud.google.com/tpu/</a> [Page 36.]</li><li>[50] D. M. W. Powers, “Evaluation: from precision, recall and F-measure to ROC, informedness, markedness and correlation,” arXiv:2010.16061 [cs, stat], Oct. 2020. [Online]. Available: <a href="http://arxiv.org/abs/2010.16061">http://arxiv.org/abs/2010.16061</a> [Page 36.]</li></ul>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2&gt;摘要&lt;/h2&gt;&lt;p&gt;网站在当今数字时代已成为许多组织获取信息的关键来源。然而，从多个网站的网页中提取和组织半结构化数据存在挑战，尤其是在希望保持广泛适用性的同时实现高度自动化时。在追求自动化的过程中，自然而然的发展是将网页数据提取的方法从仅能处理单个网站扩展到通常在同一领域内处理多个网站。尽管这些网站共享相同的域，但数据的结构可能差异巨大。一个关键问题是在保持足够准确性的同时，这样的系统能够通用地涵盖大量网站。该论文检查了在多个瑞典保险公司网站上进行的自动化网络数据提取的效率。先前的工作表明，使用包含多个领域网页的已知英语数据集可以取得良好的结果。选择了最先进的模型MarkupLM，并使用监督学习使用两个预训练模型（一个瑞典模型和一个英语模型）在标记的汽车保险客户网络数据的训练集上进行零样本学习。结果显示，这样的模型可以通过利用预训练模型，在源语言为瑞典的情况下，以相对较小的数据集在领域范围内取得良好的准确性。&lt;/p&gt;</summary>
    
    
    
    <category term="算法" scheme="https://blog.hufeifei.cn/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="https://blog.hufeifei.cn/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="Web挖掘" scheme="https://blog.hufeifei.cn/tags/Web%E6%8C%96%E6%8E%98/"/>
    
  </entry>
  
  <entry>
    <title>直接税改革——王朝周期律的胜负手</title>
    <link href="https://blog.hufeifei.cn/2023/09/economic/tax-reform/"/>
    <id>https://blog.hufeifei.cn/2023/09/economic/tax-reform/</id>
    <published>2023-09-25T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.703Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2>关于财产私有制</h2><p>在讨论《苏联解体的根本原因》时，提到了几个问题。其中有一个是：</p><p>那场运动其悲怆性在于试图挑战： A.人性  B.财产私有制。注意不是生产资料私有制，是财产私有制。</p><p>多数人选的是人性。早半年前，我也会选人性。但后来想想，并不究竟。这种所谓的人性很大程度上是财产私有制铸就的。<strong>人性本身没有善恶，它随环境的改变而改变，好的环境(或者说好的制度)造就好的人性，坏的环境造就坏的人性</strong>。大家仔细琢磨琢磨这句话，是不是？</p><p>疫情期间，内地各省医护人员驰援武汉，其中固然有行政指令，但很多都是志愿出征。相比之下，香港疫情期间则是七千医护人员大罢工，韩国则有过十三万医护人员大罢工。你总不能说因为他们天生自私，而内地人民天生就无私吧。当然是受制度影响。<strong>人性和制度之间，一定程度上是有驯化关系的</strong>。大家看到的损公肥私，人不为己天诛地灭，本质上都是财产私有制外化为人性之后的表现。</p><p>之前聊过两次避税的问题，我发现很多人都把逃税问题道德化了。明星、网红挣了那么多钱，怎么还逃税呢？说实话，易地而处，换了你我，赚了那么多，也会想方设法少交税的，这是财产私有制所决定的。只要有可能，每个人都会试图最大化私人占有。你之所以不避税，是因为你无税可避。这不是道德问题，当你把矛头直指明星的时候，问题的关键就被忽略掉了。为什么税收洼地的bug会有这么多呢？再有，许多人有个天真的逻辑，认为人有钱了就应该慷慨一些，你都那么有钱了为什么不多交点税呢？注意，钱少的时候叫零花钱，钱多的时候叫什么？<strong>钱多了就要拿来投资，获取利润或者孳息，这个时候它的名字叫资本。</strong></p><p><strong>资本以增值为核心，对成本费用最是锱铢必较</strong>。所以，当一个人非常有钱的时候，就要为资本考量利弊得失了。当你只有100块钱的时候，投资回报率从1%增长到2%也才涨了1块钱；当你有100亿的时候，1%的投资增长将为你带来1个亿的投资回报。有钱人在生活花费上可能会非常慷慨，但是在投资和生意场上则一定上精打细算，分斤拨两。你肯定见过这样的老板，红包一甩就是好几千，送礼也毫不吝啬，但是一转头管理公司的时候，对费用卡扣就非常严格，你部门那小打印机有年头了，总卡纸不好用，想买个新的，报上去都不给批。</p><p>再次回顾一下王朝周期律吧。王朝中后期土地兼并，而占有大量土地的士绅不纳税，底层又交不上税，财政困难，接着就引向了两个结果。要么是没钱养不起兵，被外族击溃，要么是就是向底层加税，官逼民反。换到近现代依旧适用，只是士绅换成了资本家，土地兼并放大为财富兼并。</p><p>我之前说周期律运转的源动力是不公平，其实不对。周期律的起点是什么，是兼并。那我们再问一句，为什么要兼并？财产私有制嘛。财产私有制之下，人们会不遗余力地扩大私人占有，所以才会造就古代版的官僚资本主义。官僚大地主联合集团，有了兼并也才会引发后续的连锁反应。所以，不公平是结果，<strong>周期律运转的源动力是财产私有制</strong>。正因如此我才会在苏联解体那期最后的小结里说，财产私有制是带有自毁倾向的，是所有帝国走向熵增的源头。</p><p>那为什么王朝周期律可以周而复始呢？因为历经起义或革命之后，兼并在相当程度上被打破，王朝初期重新实行均田，或者类似均田的政策，近现代则叫土改。</p><p>我们讲历代王朝经济恢复，经常会提到王朝初期的帝王轻徭薄赋、无为而治、与民休息…其实这些都是表象，内在原因是兼并被打破，经济、社会重新焕发活力。革命的本质是什么？革命的本质是打破兼并，是激烈的产权关系调整，是将合法利益非法化。再说直白一点，是对财产私有制的一次具备正当性的集体侵犯。为防有人挑刺，我强调一下，这里的“侵犯”是站在和平年代视角回望之下的叙事。所以大家一定要明白，为什么学历史的时候书上会说，“私有财产神圣不可侵犯”是资产阶级宪法原则。因为当你将财产私有制神圣化的时候，底层的起义、革命的正当性就被彻底否定了。我说这些并不是在批判或者否定财产私有制，大家去价值化的看，这是客观存在的历史、经济规律，不以人的意志为转移。</p><p>财产私有制是具有双面性的。一方面，它是目前为止人类社会一切伦理的基础，是个人奋斗的出发点，可以想一想，你的大部分喜怒忧思惊恐悲都和财产私有制有直接或间接的关系。但另一方面，它也是一切政治经济问题的总根源。所以为什么说“悲怆”，表面上看他是在斗官僚资本主义，限制资产阶级法权，实质上他在做什么？他是在挑战财产私有制作为源动力的王朝周期律。这是不可能成功的。时代和一辈人还为此付出了巨大的代价。不可为而为之，是为“悲怆”。</p><h2>关于按劳分配</h2><p>我解释按劳分配的时候，举了一个金某、慕某做鞋的例子。说金某手速快，慕某手速慢，结果金某鞋子做的就多，差量累计，金某财富超过慕某，甚至还能开工厂、财富传承后代。在这个过程中，赤中生白，所以叫资产阶级权利。</p><p>有朋友提出问题了，说我讲的不是按劳分配，是按要素分配。这个例子确实不对，但又要分两个层次来说。</p><p>第一层，我并没说这个故事中每个环节都是按劳分配，我只强调两个人的起点是按劳分配，由这个起点开始，由于天赋差异逐渐形成财富分化，金家拥有了更多的生产要素——资本、土地、技术，而慕家始终只有劳动力要素。按要素分配导致两家的经济基础进一步分化，也就是说是按劳分配促成了后来的按要素分配。这个过程的叙事问题不大。</p><p>第二层，金某、慕某各自做鞋，两个人明显属于个体户。个体户劳动所得是否属于按劳分配？这里就有问题了。</p><p>大家初中时代就学过，有三种劳动所得：按劳分配所得、按劳动要素分配所得、按个体劳动成果所得。同样做鞋子赚钱，你在国企，那就是按劳分配所得；你在私企，那就是按劳动要素分配所得；你是个体户，那就是按个体劳动成果分配所得。为啥会有这样的分法，仅仅是按照公有制、私有制、个体经济来做的区分吗？往深了不太好讲，只能简单解释下。一家私企，老板投资，工人干活，老板投入的是资本要素，工人投入的是劳动力要素，分钱的时候，按生产要素分配，老板拿的那部分就是资本要素所得，工人拿的那部分就是劳动要素所得。切换到国企，工人拿完工资之后，剩下的归公司或上交国家，而国家是代劳动者管理生产资料，也就是说公司、国家的那部分归根到底也是劳动者的，只不过留作扩大再生产罢了，这个时候理论上只有劳动者在分账，所以是按劳分配。如果是个体户，交完给国家的税费，剩下的都是自己的，没有众多劳动者分账这一步，所以叫按个体劳动成果分配。但从宽泛的意义上来看，个体劳动成果分配是按劳分配的一种极端形式。所以我那个例子可以做个修正，说金某和慕某都是某国企鞋厂员工。咱们现在一般就是这么作区分的，但是，前述的区分方式很笼统。大家要知道一件事，打从建国以来，中国语境里的“按劳分配”就和马克思所说的“按劳分配”不是一回事儿。咱们只是借用了概念，内涵有非常大的区别。我们说的“按劳分配”其实是“按劳动力贡献分配”。具体有点小复杂，我就不展开说了。</p><p>还有，我想再强调一下，苏联解体那期，我不是在否定按劳分配。如果把那期看完，应该能明白我的意思。但是很遗憾，苏联解体那期分为两个版本，一个是拆分版、一个是完整版。数据显示拆分版完播率50%，完整版只有28%，明白了吧，大家没有必要在评论区吵，多数人只看了几分钟就来下结论了，网络就是这样的。</p><h2>直接税改革</h2><p>直接税改革事关税基调整，事关财政，而充裕的财政于国运、于亿万人民之未来至关重要。帝国的灭亡往往直接肇因于财政的崩溃，而<strong>直接税改革是巩固财政，打破王朝周期律的关键</strong>。</p><h3>帝国亡于财政</h3><p>首先要明白财政的重要性。说来很有意思，聊到个人，聊到公司，我们都能明白钱有多重要。可是一说到国家，好多人就忽然闹不明白了，堕陷到文化传统、意识形态之类的赛道里争辩，却忽略了财政的决定性作用。</p><p>不论资社，这个世界很现实，只要做事就得花钱，基本建设、科教文卫、社会保障、企业扶持、国防安全…干啥都要花钱。各国政府就是这个世界上最大的烧钱主体。只要有钱，啥事儿都好办，摆平了就风平浪静，没钱了，妖魔鬼怪就一股脑儿冒出来。</p><p>大家读历史一定有一个感觉，每到王朝末期，天灾就集体上线，旱灾、蝗灾、洪涝、地震、瘟疫…似乎天人感应一般，水利设施也都荒废破坏了，这所有的一切恶化了老百姓的生存条件，成为王朝灭亡的加速器。结果就是农民起义风起云涌，中原大地王朝兴替。</p><p>实际上，管他是发大水还是闹蝗灾，国家只要能够拨款赈灾，这事儿就解决了，解决了就没有后续了，大家也就不记得有这回事儿了，没解决，亡国了，大家也就跟着记住了这些事儿了。本质上是幸存者偏差。</p><p>那么为什么没解决呢？因为历代王朝到了末年，除了官僚主义之外，都不约而同的罹患同一种癌症——财政危机。</p><p>没钱消灾、没钱维护基础设施、没钱支付军费…啥都干不了。贫穷王朝百事哀，结果要么是分裂割据，要么是外敌捅进家门，王朝可不久灭亡了吗！无论是唐宋元明清，还是罗马拜占庭奥斯曼苏联，细查历史你会发现，他们衰弱的原因或许各有不同，但最终都直接或间接死于财政危机。</p><p>其实很好理解，一家公司只要还能搞到钱，就有可能度过危机起死回生，一旦资金链断了，基本就玩完了。而帝国就像是一家巨型公司，所以美国就在悬崖边儿溜达呢，如果不能解决财政问题，搞不好就要步各大帝国的后尘。</p><p>刚才还提到清朝，好多人有个误解，以为清朝是财政崩溃的例外，说大清寿终正寝的时候，账上还趴着三亿两银子，是康乾盛世的十倍。这个就开玩笑了，那个数字其实是1911年的财政收入，是收入而不是盈余，收入再多也得看够不够花。对于大清来讲，不够，远远不够，光是外债就压力山大，所以清末财政赤字严重，常年如此，要不然干嘛找列强借款啊，要不然也不至于要把民间集资的铁路权收归国有，白嫖人家筹集的资金，结果闹出了湖广四川轰轰烈烈的“保路运动”，清廷紧急抽调湖北新军镇压，武汉空虚，阴差阳错之下，武昌就起义了，大清就没了。</p><p>就近来说，去年疫情，也能够看出财政的重要性，中国所以疫情控制得好，一方面是大家看到国家重视、上下齐心，一竿子插到底的组织能力…另一方面，是大家没太注意的，就是防疫投入舍得砸钱。患者治疗、物资采购、医护补助、火神山雷神山方舱医院、疫苗研发，哪一方面都花销不菲。2020年疫情防控，各级财政支出超过了4000亿人民币。对比下印度就知道，钱都花在军费上，边境闹的挺欢，等到防疫没钱了，倒是印共马执政的喀拉拉邦，一直在医疗教育上舍得投入，加上认真的执行方一政策，疫情期间相对而言表现就还不错。另外，为啥印度近些年一直在大搞私有化，变卖国有资产，还是财政缺钱，私有化的众多领域之中就包括电力，印度最近缺电这事儿，和电力私有化就有关系。</p><p>其实我们日常生活之中所面临的问题，八成都是钱的问题，还有一成是需要加钱的问题。国家也一样，大多数问题都是财政问题。</p><p>那问题来了，为什么帝国一到后期就都没钱了？</p><h3>财政死于兼并</h3><p>这部分内容我在之前的那期，从唐宪宗到唐玄宗漫谈中晚唐财政危机中提过。我复述一下。那么唐朝又缘何陷入财政危机呢？土地兼并。</p><p>回看古代史，各个朝代都亡于土地兼并所引发的财政崩溃。唐朝初年实行均田制，在均田制的基础之上，税收是租庸调制，有田则有租，有家则有调，有身则有庸。注意租庸调制是以人丁数量为基础课税的，不看财产多寡。土地兼并大量开始之后，均田制瓦解了，农民失去了土地，没了土地也就没了收成，没了收成也就交不起税了。要么逃亡，要么是投靠大地主做佃户。而对朝廷来讲，收自耕农的税比较容易，而收大地主的税是很难的。因为大地主往往是贵族豪强，隐瞒人口、隐瞒土地，有各种各样的免税权和逃税手段，所谓“士绅不纳粮”。所以土地兼并之后，国家的税源就少了，最终引发财政危机。到了明清两代，国家税收以田赋为主，田赋是按田产计征，但是继承了同样的病根儿，宗室贵族、官绅豪强本来就有大量的免税土地，还一边兼并土地，一边瞒报土地，导致税基严重萎缩，税收不足，财政紧张。财政没钱了，但是花钱的地方可一样都不少啊。像明朝末年，灾荒、瘟疫、外敌入侵，三合一大礼包哪样都得砸钱。国家既然收不到官绅豪强的税，那就只能向底层加税，辽饷、剿饷、练饷一键三连，底层遭不住，农民起义就上演了。也是为了缓解财政压力，崇祯裁撤驿站，辞退驿卒，而辞退的驿卒中有个人叫李自成。旧王朝灭亡，血洗一遍之后，新王朝建立，重新丈量分配土地，也就重建了税基，于是财政恢复生机。等到王朝中后期，土地兼并旧疾复发，以上循环再来一遍。这个就是王朝周期律。</p><p>许多史书或传奇，喜欢把王朝末年的问题统统甩锅给皇帝，其实是一种浅薄的叙事方式，以戏剧化的演绎替代了历史真相。</p><p>那么，时至当代，刚才的这套历史周期律还适用吗？适用。<strong>古代的兼并是土地兼并，现代的兼并进化为资本兼并，但是依旧会造成贫富悬殊，侵蚀税基，祸及财政</strong>。因为“士绅”依旧不纳粮，哪个国家都不例外。</p><p>大家应该听过，巴菲特交的税比他秘书还少，他说过，美国占1%的富人所负担的税率比我们的接待员甚至清洁工都要低。那是因为富豪的避税手段花样百出，比如说大家最熟知的一种，美国富豪动辄投设私人慈善基金，巴菲特、比尔盖茨、扎克伯格、贝索斯…无一例外，那当然不是在搞慈善了，而是在避税。按照美国法律，慈善基金免税，每年只要用掉5%，用于慈善相关事宜即可，20年后取消限制。这个相关的说道就大了，富豪让子女或者干脆自己出任基金的管理人，把吃喝玩乐的开销全都列支到这5%的开支里。同时自己只从公司象征性的拿点工资，这么一来，当然就交不了多少税了。但是，这样的避税手段门槛太高，普通人玩不起，结果就是，在税收这个问题上，美国政府只能狠盯着中产薅羊毛，富人的毛就算长到拖地了，他们也薅不着。美国现在联邦财政收入的90%左右都来自个税和社保。翻译过来就是，90%左右的税都来自普通人而不是富人。相比之下美国前1%的富人占据了全社会40%的财富，前10%的富人占据了全社会77%的财富，税收贡献与财富拥有量彻底倒挂。</p><p>那么中国情况如何呢？先看贫富问题。虽然没有美国那样的富人财富量占比的数字，但是大家从各类统计数据中也能间接的感受到点什么，比如2020年全年全国居民人居可支配收入32189元，换算到月就是2682元，另外一个数字超7成网民收入低于5000元。反过来再看税收，中国财政收入90%以上来自税收，而税收的70%又来自间接税收入和工资税收入，而间接税和工资税主要是普通人贡献的，也就是说从税收的人群结构上来讲中国面临的问题和美国类似。</p><p>说到这大家应该明白，<strong>古代最好收税的是自耕农，现代最好收税的是中产</strong>。中产没有严格的标准，反正你把这标准线压低一点。要想保证财政长青，就要保证自耕农或者中产阶级作为税基的规模存在。然而，<strong>兼并会摧毁税基</strong>。古代兼并导致自耕农逃亡，现代兼并导致中产萎缩，最后就是贫富悬殊，穷人没钱交不起税，富人又避税手段太多收不上税，国家陷入财政危机。</p><p>尤其是工业社会，生产效率极大提高，物质财富创造速度的同时兼并速度也更加凶猛，尤其是在互联网大数据的加持之下，如果不加干预，贫富差距会以肉眼可见的速度迅即拉大，王朝周期律也会加速运转。</p><p>那么怎么解决这个问题呢？就是常说的两个方法：做大蛋糕、重切蛋糕。</p><p>大英帝国当年做过示范。一边鼓励底层走出去，变现帝国红利，这是做大蛋糕。另一边是推进税制改革，提高直接税比重，这是重切蛋糕。只要蛋糕能持续的做大，富人吃肉，普通人再怎么也能跟着喝口汤。怕就怕增长放缓，这时候就必须考虑怎么重切蛋糕了。</p><p>大家感觉现在社会越来越卷，就和增长放缓是有关系的。</p><p>中国美国处境类似，只是中国依旧有做大蛋糕的空间，所以问题还没显得那么紧迫。</p><p>说到这中国做大蛋糕的一个方向就是高端制造业，这就抢了美国的蛋糕了，所以近几年中美矛盾才那么激烈。看中国目前的做法大致是这样的，就做大蛋糕这种做法呢，是朝两个方向，横向上以一带一路，纵向上攀爬科技树。重切蛋糕这种做法呢，就是直接税改革（还有抑制兼并）。</p><p>做大蛋糕是大家一起赚钱，不过是赚多赚少的区别而已，阻力在外部，主要来自美国。重切蛋糕却是从富人的口袋里掏钱，困难在内部。大家读历史都知道，内部阻力比外部敌人可要难处理多了。</p><p>接下来解释解释什么是直接税。</p><h3>直接税与间接税</h3><p>按照学界标准，直接税和间接税的划分标准是税负能否转嫁。</p><p>先看间接税。<strong>一般来讲，对商品和服务课税的税种属于间接税</strong>。比如增值税、消费税、关税，还有以前的营业税。厂商、进口商等这些主体是纳税人，交钱纳税，但是他们会把<strong>税额加进价格里，最后让消费者来承担，这个就是税负转嫁</strong>。比如本来这个东西不交税只卖10块钱，但是我交了1块钱税，我现在就11块钱卖给你。大家到超市买包薯片、买瓶水交钱的时候，其实都负担了几毛钱的增值税。如果买的是进口薯片，你可能还负担了关税。总的来讲，间接税相对隐蔽，就像温水煮青蛙，如果不说，大多数老百姓这辈子都不会知道。</p><p>再看直接税。<strong>大致来说，对收入和财产进行课税的税种属于直接税</strong>。比如所得税、财产税。<strong>直接税并不明显转嫁，由纳税人直接负担</strong>。比如，作为搬砖人，大家应该都知道自己每个月的工资扣完了社保，又扣了个税之后才会到手里。<strong>和间接税相比，直接税一目了然，就像是割肉一样，税痛非常直接</strong>。</p><p>说完了这些，就可以明白，间接税收入主要是由普通人所贡献的，因为间接税转嫁的终端通常是消费者，而消费者绝大多数都是普通人。对个人来讲，随着收入和财富值的增加，消费所占的比重会逐渐变小。富人总共就那么些，他们再怎么花天酒地，再怎么一掷千金，也比不上几亿人消费的总和。所以市场上才会有那句话，得屌丝者得天下。抖音、拼多多、樊登读书会、蜜雪冰城…他们都是从下沉市场打出来的。而经济增长放缓的时候，财富就会在内部调整，贫富差距拉大，会侵蚀普通人的购买力，也就是损害税基。大家消费少了，间接税就贡献得少了。还会影响到企业利润，进而影响到给职工开的工资收入。每个环节都会导致税收的减少，而职工收入少了消费就更少了，陷入恶性循环。要解决这个问题就需要对富人征税，做一次再分配，把从富人那挣来的钱拿来夯实底层税基。比方说，投到西部建设、扶贫工作中去，一步步培育出新的购买力，进而消化更多的工业产品，实现内循环。在这个过程之中，他们获得的收入要缴税，从他们手里赚取收益的企业也在缴税。人民有生活、企业有发展、国家有税收，一切步入正向循环。而对富人征税的关键就是直接税，尤其是直接税中的财产税。</p><h3>向来难</h3><p>直接税并不都是富人税，直接税主要包括所得税和财产税。所得税又分为企业所得税和个人所得税，其中个人所得税主要是个穷人税。众所周知，个人所得税包括很多个税目，工资薪金所得、劳务利得、财产所得、财产转让所得…都要课税。但是从结果上看，我国个人所得税收入六成以上都来自刚才说的第一项——工资薪金所得，也就是俗称的工资税。那么哪些人是拿工资的呢，打工人、上班族。富人的主要收入可不是工资，而是资本利得。这是为什么，我前面提到中国税收的70%来自间接税收入和工资税收入，那里我说的是工资税收入，而不是全部的个人所得税收入。所以，刨掉个税，也暂时不谈企业所得税，这是个大话题这里不展开。<strong>直接税改革的关键就在于财产税</strong>。</p><p><strong>财产税以财产为基础课征</strong>。包括但不限于房产税、遗产税、赠与税、资本离境税…现阶段为止，中国几乎没有财产税，之前那个房产税试点是蜻蜓点水，几同于无。所以我们税收之中，富人的贡献率非常低。但是，进一步说，真想征到财产税也没那么容易。美国早就开征了财产税，前面所说的财产税，美国一样没拉下。然而现在还是我前面说的那个情况，联邦财政90%左右来自个税和社保。以遗产税为例，美国的大富豪们几乎就没人交过。前美国白宫经济委员会主任柯恩公开说，只有税务筹划做的很糟糕的有钱人才缴遗产税。</p><p>不光美国搞不定，中国古代也搞不定，这种税收改革其实不是什么新鲜事儿，历朝历代都搞过。唐朝时杨炎的两税法，宋朝时王安石的方田均税法，明朝时张居正的一条鞭法，清朝时雍正的摊丁入亩，全都是类似性质的改革。大体思路就是减少按人头征收的人丁税，也就是穷人税，增加按田产征收的财产税，也就是富人税。但是结果如何，大家都有感受，大多都是人亡政息。这几个主持改革的人，翻看史书就会发现，都是负面评价一大把，顶好也是极富争议。原因很简单，改革触犯了既得利益集团，官僚阶层与地主豪强总有千丝万缕的联系，而读书人主要出身于这个阶级，你得罪了他们，也就惹毛了读书人，笔杆子一抖，身后评价，危矣。</p><p>最具代表性的就是雍正，给世人留下的都是刻薄寡恩的形象。雍正推行改革，肃清吏治、摊丁入亩、火耗归公、官绅一体当差纳粮，每一项都是对着官绅豪强骑脸输出，也因此给乾隆打了一个相当不错的底子，于是才有了后来的康“乾”盛世，可是雍正本人却不在这个词里面。乾隆上台之后把老爹的改革给废掉了，对官绅豪强宽厚为怀，于是后世的读书人对乾隆大夸特夸，却把雍正给骂惨了。当代有些事是类似的，刚才说的只是王朝中期的改革。事实上放眼中国古代时，中国税制也是从以丁身为本，到以资产为宗。早期主要是收人头税，到了明清两代，田赋已经成了主流。即便如此，政府还是收不到富人的税。宗室贵族、官绅豪强一边兼并土地，一边瞒报偷税，清代的时候最是猖狂。众所周知，清代的国土面积远远大过明朝，然而有清一代登记在册的田亩面积数值居然都没能超过明朝。</p><p>时间来到现在，事情依旧不好做。直接税改革喊话很多年了，一直有阻力，这个就有类似的原因。故事中的地主豪强不过是换成资本家而已。</p><p>可是，税改这个东西要么主动改，要么被动改。主动改就是直接税，劫富济贫；被动改就是财政危机，触发周期律，社会动荡，推倒重来。后者未免代价太大，而且鉴于我们的政权性质，开征直接税，也是人民主体地位的必然要求。所以难做也得做，或者说正是因为难做才更要做，越是难啃的骨头啃下来收益越大，受益越久。不管国家、公司还是个人都是如此。</p><h2>结语</h2><p>以当前的国内环境和国际环境而言，大概就是推行税改最好的时机了。</p><p>国内环境，反腐消解了部分阻力，而且人民史观重回舆论视野。群众基础是改开以来空前。</p><p>国际环境，各国都开始关注税收问题。经合组织CRS成员国交换涉税银行账户信息，狠挖逃税资产。欧美国家也联手对富人征税，G7集团开会统一所得税政策，防止资产转移。</p><p>这样有利的大背景之下，政府正在紧锣密鼓的推进，很多零散的新闻单看没有什么，如果联系到一起，似乎就是一盘大棋了。比如税务部门扩权，政务数字化，金税四期，数字货币…一张又一张的网正在密密叠叠的展开。</p><p>与历史相比，今天有更好的技术手段，有空前的组织效率，相信改革的结果会有所不同。</p><p>事关国运，也关乎所有人的未来，改革的结果也会揭示历史的走向，让我们拭目以待吧！</p>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2&gt;关于财产私有制&lt;/h2&gt;&lt;p&gt;在讨论《苏联解体的根本原因》时，提到了几个问题。其中有一个是：&lt;/p&gt;</summary>
    
    
    
    <category term="经济与金融" scheme="https://blog.hufeifei.cn/categories/%E7%BB%8F%E6%B5%8E%E4%B8%8E%E9%87%91%E8%9E%8D/"/>
    
    
    <category term="随笔" scheme="https://blog.hufeifei.cn/tags/%E9%9A%8F%E7%AC%94/"/>
    
    <category term="经济" scheme="https://blog.hufeifei.cn/tags/%E7%BB%8F%E6%B5%8E/"/>
    
  </entry>
  
  <entry>
    <title>Rust中的宏</title>
    <link href="https://blog.hufeifei.cn/2023/09/Rust/macro-rules-learning/"/>
    <id>https://blog.hufeifei.cn/2023/09/Rust/macro-rules-learning/</id>
    <published>2023-09-02T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.703Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2>什么是宏？</h2><p>宏是一种元编程的方式，和Java1.6引进的AnnotationProcessor类似，它可以在编译时生成源代码。这种元编程技术可以让我们从样板代码中解脱出来，比如Lombok。</p><p>Rust对标的是C/C++。C/C++中也有宏（Macro）的概念，可以简单地理解为：宏即编译时将执行的一系列指令。其重点在于「<strong>编译时</strong>」，尽管宏与函数（或方法）形似，<strong>函数是在运行时发生调用的，而宏是在编译时执行的</strong>。</p><p>不同于C/C++中的宏，Rust的宏并非简单的文本替换，而是在词法层面甚至语法树层面作替换，其功能更加强大，也更加安全。</p><p>如下所示的一个C++的宏SQR的定义</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> SQR(x) (x * x)</span></span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span> </span>{</span><br><span class="line">    std::cout &lt;&lt; <span class="built_in">SQR</span>(<span class="number">1</span> + <span class="number">1</span>) &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">}</span><br></pre></td></tr></table></figure><p>我们希望它输出4，但很遗憾它将输出3，因为SQR(1 + 1)在预编译阶段通过文本替换展开将得到(1 + 1 * 1 + 1)，并非我们所期望的语义。</p><p>而在Rust中，按如下方式定义的宏：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">macro_rules!</span> sqr {</span><br><span class="line">    ($x:expr) =&gt; {$x * $x}</span><br><span class="line">}</span><br><span class="line"></span><br><span class="line"><span class="keyword">fn</span> <span class="title function_">main</span>() {</span><br><span class="line">    <span class="built_in">println!</span>(<span class="string">"{}"</span>, sqr!(<span class="number">1</span> + <span class="number">1</span>));</span><br><span class="line">}</span><br></pre></td></tr></table></figure><p>将得到正确的答案4。这是因为Rust的宏展开发生在语法分析阶段，此时编译器知道sqr!宏中的<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.452ex" xmlns="http://www.w3.org/2000/svg" width="21.656ex" height="2.149ex" role="img" focusable="false" viewBox="0 -750 9572 950"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mi"><path data-c="1D465" d="M52 289Q59 331 106 386T222 442Q257 442 286 424T329 379Q371 442 430 442Q467 442 494 420T522 361Q522 332 508 314T481 292T458 288Q439 288 427 299T415 328Q415 374 465 391Q454 404 425 404Q412 404 406 402Q368 386 350 336Q290 115 290 78Q290 50 306 38T341 26Q378 26 414 59T463 140Q466 150 469 151T485 153H489Q504 153 504 145Q504 144 502 134Q486 77 440 33T333 -11Q263 -11 227 52Q186 -10 133 -10H127Q78 -10 57 16T35 71Q35 103 54 123T99 143Q142 143 142 101Q142 81 130 66T107 46T94 41L91 40Q91 39 97 36T113 29T132 26Q168 26 194 71Q203 87 217 139T245 247T261 313Q266 340 266 352Q266 380 251 392T217 404Q177 404 142 372T93 290Q91 281 88 280T72 278H58Q52 284 52 289Z"></path></g><g data-mml-node="mi" transform="translate(572,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">变</text></g><g data-mml-node="mi" transform="translate(1472,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">量</text></g><g data-mml-node="mi" transform="translate(2372,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">是</text></g><g data-mml-node="mi" transform="translate(3272,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">一</text></g><g data-mml-node="mi" transform="translate(4172,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">个</text></g><g data-mml-node="mi" transform="translate(5072,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">表</text></g><g data-mml-node="mi" transform="translate(5972,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">达</text></g><g data-mml-node="mi" transform="translate(6872,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">式</text></g><g data-mml-node="mi" transform="translate(7772,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">（</text></g><g data-mml-node="mi" transform="translate(8672,0)"><text data-variant="italic" transform="scale(1,-1)" font-size="884px" font-family="serif" font-style="italic">用</text></g></g></g></svg></mjx-container>x:expr标记），所以在展开后它知道如何正确处理，会将其展开为((1 + 1) * (1 + 1))。</p><p>C/C++中宏很容易出现莫名其妙的问题，所以在很多场景不推荐使用宏。而Rust改进了这点，而且提供了更多的功能，让Rust有了更灵活的表达方式。</p><h2>Rust中的宏</h2><div class="plantuml"><svg xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" contentStyleType="text/css" preserveAspectRatio="none" version="1.1" viewBox="0 0 915 158" zoomAndPan="magnify"><defs></defs><g><rect fill="#F1F1F1" height="36.2969" rx="12.5" ry="12.5" style="stroke:#181818;stroke-width:1.5;" width="34" x="10" y="60.0195"></rect><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="14" x="20" y="83.0146">宏</text><rect fill="#F1F1F1" height="36.2969" rx="12.5" ry="12.5" style="stroke:#181818;stroke-width:1.5;" width="150" x="94" y="20"></rect><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="130" x="104" y="42.9951">声明宏 macro_rules</text><path d="M44,78.168 L54,78.168 C69,78.168 69,38.1484 84,38.1484 L94,38.1484 " fill="none" style="stroke:#181818;stroke-width:1.0;"></path><rect fill="#F1F1F1" height="36.2969" rx="12.5" ry="12.5" style="stroke:#181818;stroke-width:1.5;" width="196" x="94" y="76.2969"></rect><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="176" x="104" y="99.292">过程宏 procedural-macros</text><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="560" x="343" y="56.5498">派生宏（Derive macro）：用于结构体（struct）、枚举（enum）、联合（union）类型</text><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="198" x="343" y="72.8467">可为其实现函数或特征（Trait）</text><path d="M290,94.4453 L300,94.4453 C315,94.4453 315,59.8516 330,59.8516 L340,59.8516 " fill="none" style="stroke:#181818;stroke-width:1.0;"></path><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="526" x="343" y="91.1436">属性宏（Attribute macro）：用在结构体、字段、函数等地方，为其指定属性等功能</text><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="326" x="343" y="107.4404">如标准库中的#[inline]、#[derive(...)]等都是属性宏</text><path d="M290,94.4453 L300,94.4453 C315,94.4453 315,94.4453 330,94.4453 L340,94.4453 " fill="none" style="stroke:#181818;stroke-width:1.0;"></path><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="499" x="343" y="125.7373">函数式宏（Function-like macro）：用法与普通的规则宏类似，但功能更加强大</text><text fill="#000000" font-family="sans-serif" font-size="14" lengthAdjust="spacing" textLength="224" x="343" y="142.0342">可实现任意语法树层面的转换功能。</text><path d="M290,94.4453 L300,94.4453 C315,94.4453 315,129.0391 330,129.0391 L340,129.0391 " fill="none" style="stroke:#181818;stroke-width:1.0;"></path><path d="M44,78.168 L54,78.168 C69,78.168 69,94.4453 84,94.4453 L94,94.4453 " fill="none" style="stroke:#181818;stroke-width:1.0;"></path><!--SRC=[NP9TJnD158RlzrTCmar9qqO86iCLAcA29HBvk452bkr89kpEDjFP6kzQgBHys6eA21KBGIEzi1z4DANTuezXPxQzwb_mR1SnuMftptlUzpnpTiRYN6NS83Hgg34bY4GrhmJXyRKk3tBmWGnLO-OIitGSzuJEdunRtlQ463Cr7BMOgeVwFPuSN4BouihTFOQ6dfqTnumai1_HipTxTj7TBJlDdDigo5BQQHUW9ywPfN5GhvCfMIewZIieOcePVgcJsXKVib2oA34frDppbYXjlw8YNtCQJV7kjwYMt5nTPDfohowp- -xcfRXAWM6MgSJBzR74UKacptoiHvmpicpnksJYg7nB1gD5vPEi_l9U-jbkPLCSrUN-PS_UyIVBdOoe5lraJzqwxgotWUpxcZp9YCo6Q1QSHiKjfWSM2DK9nOiGDh0GxMyb40w71nV1rbrlouFQBTyDRd-aiFC-yOH5DGxd3-bazIwr_BddD7BoiDfD5c5MvomjieTWWqKvjkt1jZTyDFdvGcoT2Biflftr5-YlpccrP3hVgLKWIPvy5EThtI-dNbBxXtn_wbklaslA68PBSdDHb6bTfNnkAe8IcCM130s5X-yDZuJlBsEk3WNcw2ertr2acKQCw1XnOk119V1iEeBYfiKqZA8axly5C0ygasf2HIyjwlMDeXSnJ2V7d_yheASqGPX93KovCZa_zR_XmKZeCU5e1ZF0GFDJoZX-hLew1uTcHWbT6KLpinEXXqf4fIkMkWBPc2fFJCXbRq6R-Gi0]--></g></svg></div><h2>声明宏</h2><p>先挑声明宏这个软柿子捏，声明宏的语法和match的语法非常类似，区别是使用了<code>macro_rules!</code>关键字。</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">match</span> target {</span><br><span class="line">    模式<span class="number">1</span> =&gt; 表达式<span class="number">1</span>,</span><br><span class="line">    模式<span class="number">2</span> =&gt; {</span><br><span class="line">        语句<span class="number">1</span>;</span><br><span class="line">        语句<span class="number">2</span>;</span><br><span class="line">        表达式<span class="number">2</span></span><br><span class="line">    },</span><br><span class="line">    _ =&gt; 表达式<span class="number">3</span></span><br><span class="line">}</span><br></pre></td></tr></table></figure><p>以一个简化版的vec!为例：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#[macro_export]</span></span><br><span class="line"><span class="built_in">macro_rules!</span> vec {</span><br><span class="line">    ( $( $x:expr ),* ) =&gt; {</span><br><span class="line">        {</span><br><span class="line">            <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">temp_vec</span> = <span class="type">Vec</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line">            $(</span><br><span class="line">                temp_vec.<span class="title function_ invoke__">push</span>($x);</span><br><span class="line">            )*</span><br><span class="line">            temp_vec</span><br><span class="line">        }</span><br><span class="line">    };</span><br><span class="line">}</span><br></pre></td></tr></table></figure><p><code>#[macro_export]</code> 注释将宏进行了导出，这样其它的包就可以将该宏引入到当前作用域中，然后才能使用。可能有同学会提问：我们在使用标准库<code>vec!</code>时也没有引入宏啊，那是因为 Rust 已经通过<code>std::prelude</code>的方式为我们自动引入了。</p><p>紧接着，就使用<code>macro_rules!</code>进行了宏定义，需要注意的是宏的名称是<code>vec</code>，而不是<code>vec!</code>，后者的感叹号只在调用时才需要。</p><p>vec 的定义结构跟 match 表达式很像，但这里我们只有一个分支，其中包含一个模式 <code>( $( $x:expr ),* )</code>，跟模式相关联的代码就在<code>=&gt;</code>之后。一旦模式成功匹配，那这段相关联的代码就会替换传入的源代码。</p><p>由于 vec 宏只有一个模式，因此它只能匹配一种源代码，其它类型的都将导致报错，而更复杂的宏往往会拥有更多的分支。</p><p>虽然宏和 match 都称之为模式，但是前者跟后者的模式规则是不同的。如果大家想要更深入的了解宏的模式，可以查看<a href="https://doc.rust-lang.org/reference/macros-by-example.html">官方文档</a>。</p><h3>模式解析</h3><p>而现在，我们先来简单讲解下<code>( $( $x:expr ),* )</code>的含义。</p><p>首先，我们使用圆括号<code>()</code>将整个宏模式包裹其中。紧随其后的是<code>$()</code>，跟括号中模式相匹配的值(传入的Rust源代码)会被捕获，然后用于代码替换。在这里，模式<code>$x:expr</code>会匹配任何 Rust 表达式并给予该模式一个名称<code>$x</code>。</p><p><code>$()</code>之后的逗号说明在<code>$()</code>所匹配的代码的后面会有一个可选的逗号分隔符，紧随逗号之后的<code>*</code>说明<code>*</code>之前的模式会被匹配零次或任意多次(类似正则表达式)。</p><p>当我们使用<code>vec![1, 2, 3]</code>来调用该宏时，<code>$x</code>模式将被匹配三次，分别是1、2、3。为了帮助大家巩固，我们再来一起过一下：</p><p>1、<code>$()</code>中包含的是模式<code>$x:expr</code>，该模式中的<code>expr</code>表示会匹配任何Rust表达式，并给予该模式一个名称<code>$x</code></p><p>2、因此<code>$x</code>模式可以跟整数<code>1</code>进行匹配，也可以跟字符串<code>"hello"</code>进行匹配: <code>vec!["hello", "world"]</code></p><p>3、<code>$()</code>之后的逗号，意味着<code>1</code>和<code>2</code>之间可以使用逗号进行分割，也意味着<code>3</code>既可以没有逗号，也可以有逗号：<code>vec![1, 2, 3,]</code></p><p>4、<code>*</code>说明之前的模式可以出现零次也可以任意次，这里出现了三次</p><p>接下来，我们再来看看与模式相关联、在 =&gt; 之后的代码：</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">{</span><br><span class="line">    {</span><br><span class="line">        <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">temp_vec</span> = <span class="type">Vec</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line">        $(</span><br><span class="line">            temp_vec.<span class="title function_ invoke__">push</span>($x);</span><br><span class="line">        )*</span><br><span class="line">        temp_vec</span><br><span class="line">    }</span><br><span class="line">};</span><br></pre></td></tr></table></figure><p>这里就比较好理解了，<code>$()</code> 中的<code>temp_vec.push()</code>将根据模式匹配的次数生成对应的代码，当调用<code>vec![1, 2, 3]</code>时，下面这段生成的代码将替代传入的源代码，也就是替代<code>vec![1, 2, 3]</code>:</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">{</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">temp_vec</span> = <span class="type">Vec</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line">    temp_vec.<span class="title function_ invoke__">push</span>(<span class="number">1</span>);</span><br><span class="line">    temp_vec.<span class="title function_ invoke__">push</span>(<span class="number">2</span>);</span><br><span class="line">    temp_vec.<span class="title function_ invoke__">push</span>(<span class="number">3</span>);</span><br><span class="line">    temp_vec</span><br><span class="line">}</span><br></pre></td></tr></table></figure><p>如果是<code>let v = vec![1, 2, 3]</code>，那生成的代码最后返回的值<code>temp_vec</code>将被赋予给变量<code>v</code>，等同于 :</p><figure class="highlight rust"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">let</span> <span class="variable">v</span> = {</span><br><span class="line">    <span class="keyword">let</span> <span class="keyword">mut </span><span class="variable">temp_vec</span> = <span class="type">Vec</span>::<span class="title function_ invoke__">new</span>();</span><br><span class="line">    temp_vec.<span class="title function_ invoke__">push</span>(<span class="number">1</span>);</span><br><span class="line">    temp_vec.<span class="title function_ invoke__">push</span>(<span class="number">2</span>);</span><br><span class="line">    temp_vec.<span class="title function_ invoke__">push</span>(<span class="number">3</span>);</span><br><span class="line">    temp_vec</span><br><span class="line">}</span><br></pre></td></tr></table></figure><p>至此，我们定义了一个宏，它可以接受任意类型和数量的参数，并且理解了其语法的含义。</p><p>对于<code>macro_rules</code>来说，它是存在一些问题的，因此，Rust 计划在未来使用新的声明式宏来替换它：工作方式类似，但是解决了目前存在的一些问题，在那之后，<code>macro_rules</code>将变为 deprecated 状态。</p><p><a href="https://zhuanlan.zhihu.com/p/494952481">知乎</a>也有一篇文章介绍macro_rules目前存在的一些问题，可以看看这本书 “The Little Book of Rust Macros”。</p>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2&gt;什么是宏？&lt;/h2&gt;&lt;p&gt;宏是一种元编程的方式，和Java1.6引进的AnnotationProcessor类似，它可以在编译时生成源代码。这种元编程技术可以让我们从样板代码中解脱出来，比如Lombok。&lt;/p&gt;</summary>
    
    
    
    <category term="Rust" scheme="https://blog.hufeifei.cn/categories/Rust/"/>
    
    
    <category term="Rust" scheme="https://blog.hufeifei.cn/tags/Rust/"/>
    
    <category term="Macro" scheme="https://blog.hufeifei.cn/tags/Macro/"/>
    
  </entry>
  
  <entry>
    <title>货币与经济周期</title>
    <link href="https://blog.hufeifei.cn/2023/08/economic/currency/"/>
    <id>https://blog.hufeifei.cn/2023/08/economic/currency/</id>
    <published>2023-08-27T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.703Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2>货币是未兑现的劳动剩余</h2><blockquote><p>人类驯化五谷禽畜后便进入了农业社会，农业社会更易产生劳动剩余，劳动剩余的权属和继承问题催生了私有制</p></blockquote><p>张三是种小麦的，今年有200斤的收成，自家吃了100斤，还剩100斤。这剩下的100斤是张三的劳动剩余。</p><p>李四是捕鱼的，今年捕了100斤，自家吃了50斤，还剩50斤。李四吃鱼吃腻了，想用剩下的50斤鱼换张三的小麦做面包。碰巧张三也想吃鱼，两个人把自己的劳动剩余交换了。交易产生了。</p><p>张三李四的村子里，还有种红薯的、种西瓜的、打猎的。他们都想用自己的劳动剩余换别人的劳动剩余，为了方便交易，他们约定在村头建一个农贸市场。最原始的以物易物的市场经济产生了。</p><p>张三想换李四的鱼，每次都要背好多斤小麦去集市，很不方便。其他人也觉得以物易物的方式很不方便，所以大家约定用村子里很稀有的一种贝壳作为交换的凭证。用于流通的货币随之产生，交易的效率也提高了。跟贝币相关联的汉字也由此而生：贵、贱、贪、财、贷、货、贿、赂、贫、购、资。</p><p><img src="https://bkimg.cdn.bcebos.com/pic/b90e7bec54e736d1f87026e790504fc2d46269fa?image_d2F0ZXIvYmFpa2U4MA==,g_7,xp_5,yp_5/format,f_auto" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="贝币"></p><p>李四有一次捕鱼去了很远的海边，他发现海边有很多这样的贝壳，他偷偷地把贝壳带回家，自己捕鱼就可以偷懒了，每天用贝壳到集市上换别人的劳动剩余就能吃吃喝喝过得很好。货币注水出现了。</p><p>久而久之，市面上流通的贝壳越来越多，但是生产力没有提高，大家的劳动剩余并没有增多，能用贝壳换的东西就那么些。张三发现了这个现象，他开始让自家的小麦涨价，以前1个贝壳换1斤小麦，现在得要2个贝壳换1斤小麦了。市面上卖其他商品的村民为了保障自己的劳动剩余价值不受损都纷纷开始涨价。通货膨胀产生了。</p><p>最终大家找到了罪魁祸首李四，大家发现李四家有好多从海边捡来的贝壳。从此大家再也不用贝壳交易了。货币信用第一次崩塌了。</p><p>但是以物易物的方式效率太低了，大家都不想回到以前，最终大家先后找到了铜、金、银这种稀缺的金属作为货币。“金钱”也因此而来。</p><p><img src="https://e0.ifengimg.com/02/2019/0227/BC237C1F4A22A5CFBCE824F75F4DEA7C00C4B1EB_size117_w1000_h788.jpeg" alt="中国金属货币"></p><h2>货币是国家信用的派生</h2><p>随着贸易市场和货币体系的稳定，周围好几百里的村子都建立了自己的贸易市场，村子与村子间也开始进行交易。</p><p>家住山下的老王发现自己村子都是打猎的，鱼很少，卖的很“贵”，而海边的村子都是捕鱼的，鱼非常便宜。于是他开始做起了长途贸易，将海边的鱼运到鱼少的地方赚取差价。利用信息差的中间商出现了。</p><p>随着老王的生意越做越大，老王发现每次自己都要带大量铜钱或万两黄金去海边采购，重几百斤的贵金属不仅不方便携带，还容易被人抢，他敏锐地发现了这个需求，于是他率先建立了跨城市的钱庄。把黄金存在钱庄，钱庄给你开相应的票据，拿这个票据可以到另一个城市的钱庄取出黄金。最早的银行出现了。这种“纸质兑换券”在唐宋曾盛行一时，这种票据被称为“飞钱”——钱无翅而飞。</p><p><img src="https://bkimg.cdn.bcebos.com/pic/8640bf8b5b1c036c9f2fb47b?x-bce-process=image/format,f_auto" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="交子"></p><p>随着钱庄的客户越来越多，大家干脆就直接用钱庄开的票据进行交易。金本位的货币兑换体系诞生了。</p><p>钱庄私自开票咋办，要是能私自开票，人人都去开钱庄就能收割别人的劳动剩余了。最后国家介入，用国家信用做担保，开办银行，负责货币的发行。</p><p>世界上最早的纸币就是北宋时期的中国人发明的，名为“交子”。那要是国家随便印钞票咋办？这个收割劳动剩余的方式也被称为“铸币税”。蒙古人入主中原后，汉人的统治艺术没学到多少，印纸币倒是学的很快，元朝第一次将纸币称为“钞”，从字面上就能看出这个字的意思。站在“钞”的使用者角度，他比铜钱更轻便；站在“钞”的发行者角度看，他可以轻松地掠夺民间财富。从此“金钱”变成了“钞票”。</p><p><img src="https://img1.artron.net/auction/old/art8178/d/art81784015.jpg" alt="银票"></p><h2>生产力的提高促进劳动剩余的积累</h2><p>有一天，大洋彼岸的英格兰王国有位聪明的小伙子瓦特发明了一种动力机器——蒸汽机，有人基于这个蒸汽机制造了纺织机、远洋货轮、火车。以前需要10个纺织工人10天干的活，现在利用机器一个纺织工人一两天就能干完。有了火车和远洋货轮，这些商品可以运往欧洲大陆的各个地方销售。</p><p><img src="https://ts1.cn.mm.bing.net/th/id/R-C.735eddf84cf044e181fb9a2619cc7dde?rik=L2DXAA1tOobBWQ&riu=http://5b0988e595225.cdn.sohucs.com/q_70,c_zoom,w_640/images/20181126/31c08ba24581413eaa2eeca2bc769e4c.jpeg&ehk=Oz+YHEGO70hXDEJQdIXY+5T8q95hMnkTHfWV4OQP/ig=" alt="1800年英国纺织厂"></p><p>英格兰使用蒸汽机提高了生产力，劳动剩余越来越多，而且价格便宜，其他国家商品价格根本竞争不过英格兰，其他国家对英格兰都产生了巨大的贸易逆差，黄金大量流入英格兰（资本家的口袋）。</p><p>由于成本低廉，英格兰的商品对其他国家的商品产生了价格上的碾压，其他国家纷纷建立起了关税政策。要想把商品卖到我们国家必须交高昂的关税。这种行为叫做“贸易保护主义”。</p><p>与此同时，其他国家纷纷引进英格兰的机器和技术改进自己的生产方式，工业革命的号角声吹遍了欧洲大陆的每一个角落。</p><h2>经济危机是生产过剩供求失衡导致的货币流通性危机</h2><p>在这场工业革命中，最聪明的那批人率先引进了机器并用机器改进了原有的生产方式。为了规模化生产，他们建立起工厂，雇佣那些没有机器的人为它们工作。</p><p>这些机器和生产技术被一个叫马克思的人称为生产资料，工人们使用生产资料为老板创造商品，老板通过商品的利润迅速积累财富。</p><p>使用黄金作为货币会出现一个问题：工人用赚取的工资消费最终都流向了掌握生产资料的老板手里。地球上的黄金是有限的，最终只会富人越来越富，穷人越来越穷，导致市场上流通的黄金越来越少，于是市场上出现一种现象：工厂生产的商品卖不出去，穷人没钱购买商品。经济危机出现了。</p><p><img src="https://img-nos.yiyouliao.com/alph/557627b3bcab14f42999bcb08dd4a7bb.jpg" alt="资本家倒牛奶"></p><p>在这个分配制度下，穷人只能在社会底层内卷，有的人因生活所迫被逼无奈成了罪犯，而有些人冒险去新大陆寻找更多的黄金，这之中有一个叫哥伦布的发现了美洲大陆，后面有人在这块大陆上发现了金矿，这个发现金矿的地方被人叫做旧金山。那新金山是哪儿呢？英国有一群罪犯被流放到了尚是一片蛮荒的澳大利亚大陆，穷人们在澳大利亚又发现了一个金矿，现在澳大利亚的国际都市墨尔本也被称为新金山。只要资本主义雇佣关系的分配制度不变，在地球上所有黄金都被发现后，金本位的货币制度就会崩塌。</p><p>纸币的出现解决了这个问题。最先工业化的英国最先实行金本位，伟大的科学家牛顿还做过皇家铸币局的局长；后来英格兰银行开始发行纸质的银行券，马克吐温《百万英镑》的故事就是在这个背景下创作的。金本位时期，黄金可以作为货币之锚，是因为生产力低下，财富不会飞速聚集；生产力的提高会加速财富聚集速度，货币最终与黄金脱钩，回归了货币最原始的本质————<strong>劳动剩余才是货币之锚</strong>。</p><p>但是经济危机的时候，直接印钞票给穷人发钱会导致市场上的货币贬值，因为市场上没有那么多对应的劳动剩余，富人们会把手里那些纸币换成真正有价值的劳动剩余，市场上的资产价格会飙升。前面给穷人发钱还算好的情况，大多数政府不会把白花花的钞票直接发给穷人，这些货币流通到市场，实际上使持有货币的无产者财富缩水，<strong>穷人的财富形式是货币，富人的财富形式是生产资料</strong>，富人在通货膨胀的过程中反而财富增值了。</p><p><img src="https://d.ifengimg.com/w800_h600_q90_webp/e0.ifengimg.com/11/2019/0722/94E2376E6A265CC40A2C5440A228F3CB9CC74977_size72_w800_h600.jpeg" alt="工人失业"></p><p>1936年，英国有个叫凯恩斯经济学家的在《就业、利息和货币通论》中提到，政府通过财政政策和货币政策调节市场需求以解决经济危机。以工代赈的方式，人为的创造需求，让穷人通过劳动的方式换取货币进行消费；降低银行利率的方式促进企业和个人的借贷，通过借贷增加市场上货币的流通量。</p><h2>金融周期的本质是信贷周期</h2><p>正是信贷的出现，使得市场变幻莫测。举个简答的例子，A欠B1元，B欠C1元，C又欠A1元，这时市场上有3块钱的债务，如果A不还B的钱，B也没钱还C的钱，C也没钱还A的钱，整个经济就陷入了死循环。如果此时凭空印1块钱借给A让他去还债，那这个债务链条就全部解除了。这是因为一个人的负债本质上是另一个人的信用资产，如果把信用资产和负债放到一张资产负债表中，这三个人本质上都是0负债。</p><p>信贷另一个魔幻的特点是周期性。一个人今天借了100块钱，债务规定的N年后要还100钱+m块钱的利息，借钱肯定要花出去，而一个人的支出等于另一个人的收入，环环相扣就使得整个社会的交易量大大提升。</p><p>另外国家可以通过中央银行调节借贷的利率，来控制这个借钱的行为，利率高的时候人们借贷的意愿就会下降，因为他们怕未来连本带息还不上，而利率低的时候人们的借贷意愿就会增强。瑞·达利欧在他的《原则》一书中，把这个周期称谓<strong>短期债务周期</strong>。国家市场经济不好的时候降低利率，促进企业和个人贷款，刺激消费，从而增加市场上的货币供应量；在经济好转的时候提高利率，让借贷的人减少，从而减少市场上的货币供应量。</p><p>但是通过债务只能延缓货币流通性危机的发生，并不能完全解决这个问题。当经济大萧条的时候，大家对未来的信心丧失殆尽，银行再怎么调节利率即使降为零，大家都不敢借债了，此时<strong>长期债务周期</strong>就出现了。国家除了调节利率这个工具，还有加大政府投资的工具。在经济萧条时，政府投资基建，为失业人群提供工作机会，保证失业人群有收入从而保证货币的流通。这种政府在宏观层面主动调节市场的经济行为被称为“凯恩斯主义”。</p><p><img src="https://img1-cdn-picsh.aigupiao.com/live_msg/2022-12-27/1672139349180=865X582.png"></p><p>当市场上许多人开始借钱消费的时候，经济一片繁荣，大家对未来信心十足，也会催生出更多的借贷，此时市场上的资产价格也会上涨；当大多数人开始还钱时，市场上流通的货币变少，经济开始萎缩，经济周期因此出现。当市场上人们的信心一蹶不振的时候，大家都不敢借贷，不敢过度消费，经济开始萧条。</p><h2>马克思与凯恩斯的对决</h2><p><img src="https://www.marxist.com/images/stories/britain/2020_May/marxism_Keynesianism_Image_Socialist_Appeal.jpg" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="马克思主义与凯恩斯主义"></p><p>马克思最早发现了资本主义雇佣关系的根本矛盾，掌握生产资料的有产阶级会源源不断的积累财富，而不掌握生产资料的无产阶级最终会一贫如洗。所以马克思和恩格斯起草了《共产党宣言》，通过社会革命建立一套生产资料公有制的社会制度，从根本上解决经济周期性危机的问题。</p><p>凯恩斯则寄希望于财政和货币政策调节市场推迟危机的到来，期望在推迟后的这段时间内出现科技革命改变市场上生产资料的分配关系。</p><p>历史告诉我们这两个解决方案都不完美。人类社会至今还没有找到最优解。</p>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2&gt;货币是未兑现的劳动剩余&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;人类驯化五谷禽畜后便进入了农业社会，农业社会更易产生劳动剩余，劳动剩余的权属和继承问题催生了私有制&lt;/p&gt;
&lt;/blockquote&gt;</summary>
    
    
    
    <category term="经济与金融" scheme="https://blog.hufeifei.cn/categories/%E7%BB%8F%E6%B5%8E%E4%B8%8E%E9%87%91%E8%9E%8D/"/>
    
    
    <category term="随笔" scheme="https://blog.hufeifei.cn/tags/%E9%9A%8F%E7%AC%94/"/>
    
    <category term="经济" scheme="https://blog.hufeifei.cn/tags/%E7%BB%8F%E6%B5%8E/"/>
    
    <category term="货币" scheme="https://blog.hufeifei.cn/tags/%E8%B4%A7%E5%B8%81/"/>
    
  </entry>
  
  <entry>
    <title>唯物主义历史观</title>
    <link href="https://blog.hufeifei.cn/2023/08/economic/economic_and_history/"/>
    <id>https://blog.hufeifei.cn/2023/08/economic/economic_and_history/</id>
    <published>2023-08-05T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.703Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><blockquote><p>人猿相揖别。只几个石头磨过，小儿时节。铜铁炉中翻火焰，为问何时猜得？不过几千寒热。人世难逢开口笑，上疆场彼此弯弓月。流遍了，郊原血。<br>一篇读罢头飞雪，但记得斑斑点点，几行陈迹。五帝三皇神圣事，骗了无涯过客。有多少风流人物？盗跖庄屩流誉后，更陈王奋起挥黄钺。歌未竟，东方白。<br>贺新郎·读史————毛泽东</p></blockquote><h2>农业时代的生产力发展</h2><p>人类出现了语言，使得人类之间能传递更加复杂的信息。系统的语言体系让人类个体间能团队协作，完成难度更高的任务。这是人类能超越各种体型比自己更大的猛兽站在食物链顶端的决定性因素。<strong>我把语言的出现看作人类的第一次信息革命</strong>。由于语言本质是声音，是一种能量波，没有稳定的物质载体，现今的考古学也无法论证语言的起源。</p><p>其次，人类还学会了利用火，火的利用不仅改变了人类的饮食习惯，还为陶器、青铜器等制造技术奠定了基础。中国历史上的“燧人氏”发明了钻木取火，因此被称为“三皇之首”，西方神话中也把普罗米修斯被视为人类之师。<strong>我把“火”的利用看作人类的第一次能量革命</strong>。恩格斯说：“就世界的解放作用而言，摩擦生火还是超过了蒸汽机。因为摩擦生火第一次使得人支配了一种自然力，从而最后与动物界分开。”赵朴初作诗赞道：“燧人取火非常业，世界从此日日新。”</p><p>石斧磨缺，人猿揖别，但此时的智人还处在迁徙状态，哪里有食物，就往哪里走。那是什么让人类开始定居下来？是农业。想象一下，远古的某个人类族群在费尽心力追丢猎物垂头丧气的时候，看着脚下的野麦子，想到了另一种活下去的方式。于是人类开始驯化五谷。人类因为学会了使用“火”，才能煮烂五谷，谷物淀粉含量高，且干燥适合长期储存，因此五谷也逐渐成为人类的主食。种植五谷需要稳定的水源，所以人类逐水而居，刀耕火种，这就是大河文明的起源。中国历史上的三皇之一“神农氏”就是教会人们学会种植五谷，制作陶器的部落。</p><p><strong>人类的第一次技术革命——“农业革命”</strong>，谷物的驯化让人类可以从植物的光合作用中获取能量，第一次实现了生产力的跃迁，告别了和猩猩那样吃了上顿没下顿的日子。这次技术革命中，陶器的发明是材料革命，火和五谷的驯化是能源革命，语言的出现是信息革命。</p><p>这个时候的人类靠农业生产勉强可以养活整个氏族。把此时的生产力定为1，也就是氏族的劳动力人口干活刚刚好够养活氏族的人口(考虑到有尚无劳动能力的幼儿)。这个时候的社会能实现所谓的民主，应该还不能叫做社会，氏族群体人口还比较少，信息沟通成本比较低。只有能让整个氏族利益最大化的人才会被推举为氏族领袖。与此同时，人类还驯化了家禽、家畜、家蚕等生物，拓宽了食物的来源和能量的利用效率。</p><p>随着冶炼技术的发展，从青铜器到铁器技术的演进，铁犁等各种工具的出现以及牛马等畜力的驯化使得生产力快速提高。人类也从刀耕火种的粗旷式生产转变为精耕细作。人口也会因为生产力的提高而增多。青铜时代和铁器时代分别代表着材料革命的两个跨时代的技术。</p><h2>家庭、私有制与国家的起源</h2><p>原始氏族公社施行公有制，是因为饮血茹毛刀耕火种的原始人通过个人无法单独生产，个人必须加入集体生产才可能存活，生产方式和狼群类似，集体狩猎、采集果实，此时的公有制是生产力水平极其低下而导致的原始公有制，但实际上这种大家族公社是以家族血缘为纽带的，公社间并不实现生产资料的共享。</p><p>此时由于认知水平和生产力的低下，公社还处在迁徙状态，内部实行着群婚制。其次由于人类两性知识的匮乏，导致新出生的人类只知其母不知其父，这也就是所谓的“母系氏族公社”，这一点上有点类似于狮群、狼群的社会组织模式。</p><p>随着认知水平的提升，人们逐渐对两性关系有所认识，同时由于近亲繁殖会导致遗传病概率的加大，人类开始实行族外群婚制。</p><p>进入农业社会后，生产力水平得到发展。在定居的农业社会，由于男性天然的体力优势，更适合繁重的农业耕作，女性开始依附于男性生存，母系氏族公社逐渐演进为男女婚娶的父系氏族公社。</p><p>正因对偶制婚制的形成，以家庭为单位的生产关系出现；同时由于农业社会生产力的发展使得劳动形成了劳动剩余。过去靠打猎、采集野果为生，食物不容易储存，饥一顿饱一顿，也就没有所谓的劳动剩余；农业时代，谷物容易储存，劳动剩余随之产生。此时<strong>劳动剩余的权属和继承问题成为新的社会矛盾，以家庭为单位的私有制也因此出现</strong>。</p><p>与此同时，<strong>公权力与劳动者分离，形成国家</strong>。公权力为维护大众利益无法从事农业生产，如国防安全(炎黄战蚩尤，大禹逐共工征三苗)、兴修水利(大禹治水)。国家为了维持运转需要财税支持，此时存在一些非农业人口，也就出现了一群人供养另一群人的现象，农业税因此出现，《尚书•禹贡》中就记载了大禹治水后定九州并制定税赋的历史，这也是中国第一部税法，此时税赋还比较原始，直到春秋时期鲁国“初税亩”的出现，才初具雏形。而中国的农业税直到2006年才被废除，农业税一直伴随着中华文明上下五千年。</p><p>当国家统治者的家庭脱离社会生产时间长了，便不再愿意继续从事劳动生产，这是由俭入奢易、由奢入俭难的人性使然。大禹治水成功后威望空前，于涂山之会铸九鼎定九州。从此一个阶级统治另一个阶级的阶级社会出现，夏启袭位使得国家从公天下开始演变为家天下。商汤伐桀、武王伐纣，周朝吸取前朝教训，为了维护家天下的统治，将国家土地分封给各个兄弟一起建设，也就是所谓的封建社会。周朝的农业税以井田制的形式出现，公田的产出归国家，私田的产出归私人家庭所有，孟子说夏后氏五十而贡、殷人七十而助、周人百亩而彻，其实都是十分之一的税率。</p><p>此时的农业社会以父权至上，中国上古时期出现的姓氏，“姓”指代母系（“女”人所“生”），氏指代父系，先秦时期姬,姚,妫,姒,姜,嬴,姞,妘等上古姓以女字旁为主，而氏以地名、国名、官名等为主，通常只有贵族才有氏。这也就是所谓的“男子称氏，女子称姓；姓别婚姻，氏分贵贱”。比如春秋五霸中齐桓公姜姓吕氏名小白（姜子牙吕尚后代），晋文公姬姓晋氏名重耳，秦穆公嬴姓赵氏名任好，吴王阖闾姬姓吴氏名光，越王勾践姒姓名鸠浅。这种姓氏并存的现象正是由母系氏族公社演变到父系氏族的遗留产物。</p><p>封建社会发展到一定时间，统治者血缘关系开始逐渐疏远，同时由于人口的不断增长和土地资源的有限，人口和土地的矛盾开始出现，分封的诸侯国之间开始通过战争进行兼并。由于频繁的战争，土地权属经常发生变化，井田制随之瓦解，国家征税不再有公田私田之分。</p><p>秦始皇为了国家不再出现战乱分裂，废除分封施行郡县制，加强中央集权，从此进入帝制王朝时代。</p><p>秦国之所以胜出，在于秦国施行的商鞅变法认为农民是农业社会最重要的生产者，想要富国强兵必须扩大农业人口比重，保持非农业人口比重不超过10%，把人口不断增长而不从事生产的贵族打压到底层从事劳动生产或参军，国家允许私田买卖和开垦荒地以提高积极性，同时提供军功授爵的阶级快速上升通道，国家机器得到高效率的运转。此时的生产力可定为1.1。</p><p>秦国以此兴，也以此亡。当秦国统一六国后，能耕种的优质土地已基本开垦完，战争也结束，阶级出现固化，此时高压的行政手段（修长城、修驰道、重徭役、覆压三百余里的阿房宫）必然激化阶级矛盾，一声“王侯将相宁有种乎”如星火燎原，瞬间激发，这也是历史记载的第一个农民起义。</p><h2>农业时代的生产力瓶颈与王朝的周期兴替</h2><p>农业是以土地为基础，中国历史上自秦朝后的<strong>历史周期律本质上都是土地生产力有瓶颈导致的</strong>。秦朝以前没有出现这种现象(准确的来说是战国以前)，是因为土地还没有被完全开拓，西周时期南方还是蛮荒地区，人口稀少，楚国还被称为“荆蛮”。到了战国人口增多土地资源紧张，国家兼并出现。秦帝国奋六世之余烈，扫六合，平八荒，南取百越，北击匈奴，将大陆所有肥沃的土地收入囊中，自此便进入了土地和人口的周期循环：</p><ul><li><p>王朝初期，人口凋敝，百废待兴。人均土地充足，老百姓丰衣足食，人口的迅速恢复，两三代人后便会迎来王朝的盛世。</p></li><li><p>王朝中期，人口攀升到顶峰，进入王朝最鼎盛的时候。经历几代人的发展，由于个体能力的差异，贫富分化也开始出现。</p></li><li><p>王朝末期，人口的继续上涨，导致土地产出不足以养活这么多人，人们在吃饱和吃不饱的临界点徘徊。只要一旦出现洪涝、干旱、蝗灾等自然灾害，就会出现饿死人的现象，大饥荒人相食曾多次出现在史书中，春秋《左传》中就有易子而食的描写。朝廷如果未能及时救灾安抚，农民起义就可能会在这个时期频繁出现。</p></li></ul><p><img src="https://xqimg.imedao.com/17414afabf9a54e3fe1daf93.jpeg!800.jpg" alt="人口波动"></p><p>历史上多次引进玉米等高产农作物提高了生产力。如张骞出塞引进了葡萄、石榴、胡萝卜、胡椒、胡瓜(黄瓜)、胡蒜(大蒜)、胡麻(芝麻)、胡豆(蚕豆)、胡桃(核桃)、胡菜(香菜)。张骞作为第一个睁眼看世界的汉人为中国开辟了陆上丝绸之路，后人引进了很多其他农作物，如西瓜(西域)、菠菜(波斯)、茄子、棉花等。另外，由于造船技术和指南针的发明，中国又开辟了海上丝绸之路引进了玉米、番瓜(南瓜)、番薯、番茄(西红柿)、番椒(辣椒)、洋番薯(马铃薯)、洋白菜、洋葱等。</p><blockquote><p>“胡”字辈大多为两汉两晋时期由西北陆路引入; “番”字辈大多为明朝时期由“番舶”(外国船只)带入; “洋”字辈则大多由清代乃至近代由环球航海的西洋人引入。</p></blockquote><p>也正因为农业生产力的不断提高，中国古代王朝鼎盛时期能容纳的人口也在不断攀升：两汉巅峰期人口6千多万人，唐朝8千万，宋朝鼎盛时期(宋徽宗赵佶时期，靖康之乱前夕)人口突破1亿，元朝只有9千万(还是蒙古人觉得汉人杀不完的情况下)，明朝鼎盛时期(万历年间)人口1.5亿，清朝鼎盛时期(乾隆盛世)人口超过3亿。现在能养活14亿人口，得感谢袁隆平等科学家的育种技术以及化肥技术的推广。</p><p>除了土地生产力的因素外，制约王朝寿命的另一个因素是以税收为代表的分配制度：</p><ul><li><p>王朝初期，均田制度实现了相对公平，王朝重新焕发活力，纳税人口占总人口的比例较大，国家税基也相对充盈。</p></li><li><p>王朝中期，由于个人天赋与能力的差异，出现贫富分化：弱者由于天灾或者人祸，为了活下去被迫卖田，强者使用积累的劳动剩余，购置了更多的田地。这其中特别是士绅贵族以及官僚阶级有免税的特权，使得他们能拥有更多的田地，更甚者他们使用手中的特权进行<strong>土地兼并</strong>——巧取豪夺百姓的田地。此时国家税基开始萎缩，国家的税负压在了普通百姓的身上。</p></li><li><p>王朝末期，土地兼并无以复加，失地的农民被迫沦为地主的佃农依附于地主，以官僚阶级为代表的地主占有大量土地，不事生产的食利阶级越来越多，此时富者田连阡陌，贫者无立锥之地。国家税收已无力维持国防军事、民生赈济等开支。此时王朝极度脆弱，任何外敌入侵、水灾旱灾等问题都会成为压死骆驼的最后一根稻草。不加税直接崩溃，加税则官逼民反，届时农民起义四起，王朝崩溃，新的轮回重新开始。</p></li></ul><p><img src="https://pic3.zhimg.com/80/v2-2bf4c293f9057caeaeea6db4a392c9d2_1440w.webp"></p><p>朝廷如果有足够的税收救灾安抚受灾群众或者及时扑灭农民起义的火苗，王朝还能续命，但是明君也只能通过打击士绅豪强，合理分配财富、增加税基延缓这个进程，并不能逆转这个进程，因为人口增长和自私都是刻在人基因里的天性，老子在《道德经》中有云：天之道，损有余而补不足；人之道，损不足以奉有余。这种人类系统熵增的马太效应是社会规律，不以人的意志为转移。</p><p>农业时期商品经济十分简单，同时中国士农工商的历史传统导致商业发展受限。但是我们从农业社会发展的本质中发现两个点：</p><p>1、土地是生产资料，是农业社会财富的来源。所以历史上的明君都是通过土地改革解放农业生产力的，如清朝雍正的摊丁入亩、官绅一体当差纳粮，使得之后乾隆盛世人口能达到3亿以上。</p><p>2、人多地少是农业社会永恒的矛盾。这是古代王朝周期循环，不超过300年的根本原因。这是客观规律不以人的意志为转移，明君昏君只能延缓或加速这个进程，却无法逆转，如荀子所说“天行有常，不为尧存，不为桀亡”。</p><p>农业社会的两个核心生产要素是人口和土地，人口越多，生产力越高，但人口达到土地生产力承载的极限后，过多的人口并不会带来生产力的提升，这个规律被西方总结为“马尔萨斯陷阱”。</p><p>除此之外，税收负担的不平等是导致中国的每个王朝都无法超过300年的根本原因。但西方国家并没有300年的桎梏，这是为何？这在于中国自秦以后大部分时间是大一统帝国，中国周边又都是不适合农耕的土地，西边是青藏高原和西域大沙漠，北边是西伯利亚高寒带，东边是汪洋大海，这导致王朝末期，土地集中于大地主后，底层人又无法对外扩张开拓新的适合耕作的土地，只能内部消耗，推翻地主阶级的统治，重新分配土地。改朝换代不仅调整了产权结构，而且大规模的战争使得人口减少，马尔萨斯陷阱和生产资料分配的极端不平等问题都得到了解决。而西方更像中国的春秋战国时期，小国林立，即使凯撒和他的养子屋大维统一了整个地中海地区建立了<a href="https://baike.baidu.com/item/%E5%8F%A4%E7%BD%97%E9%A9%AC/888289">罗马帝国</a>，但罗马帝国并不像中国的家天下，<a href="https://baike.baidu.com/item/%E7%BD%97%E9%A9%AC%E7%9A%87%E5%B8%9D/416182">罗马皇帝</a>不断有篡位和外戚继任等现象，内部频繁发生内乱，中央集权极不稳定，同时北欧的日耳曼等民族侵扰，欧洲战争的频繁程度远比长期统一的中原大帝国高，这使得欧洲人口不像中国王朝更替一样出现周期性的波动。</p><table><thead><tr><th>东方</th><th>西方</th></tr></thead><tbody><tr><td>春秋(前770年～前476年)</td><td>罗马王政时代(前753～前509年)古希腊(前800年左右~前146年)</td></tr><tr><td>战国(前476年～前221年)</td><td>罗马共和国(前509～前27年)</td></tr><tr><td>秦(前221年～前207年)汉(前202年～220年)</td><td>罗马帝国(前27年~1453年)</td></tr><tr><td>魏晋南北朝(220年~280年,265年－420年,420年—589年)</td><td>东西罗马分裂(395年~476年/1453年)</td></tr></tbody></table><p>那为什么中国能实现长期中央集权的大一统国家，而欧洲不行呢？这得益于秦始皇的统一文字，中国的汉字是表意文字，即使有方言上的读音区别，但不影响汉字的理解，换句话说<strong>中国的语言和表意文字是相对分离的体系</strong>。<strong>文字是人类历史上继语言出现后的“第二次信息革命”，也让信息有了载体</strong>，文字的出现提高了信息传播的时间和空间的广度，使得信息从口口相传变为基于甲骨、竹简、锦帛、纸张等载体的传播。时间上，文字可以记录历史上发生过的事件，使人类可以回溯过去的历史，提升认知；空间上，文字可以像政令一样进行大范围的传播，提高了信息的传播的效率和准确性。中国的方言众多，各自有各自的体系，大的如普通话、粤语、客家话等，小的像赣语、吴语等甚至出现“十里不同音”的现象，而秦始皇统一的汉字使得这些不同体系的方言产生了语义的关联。也正是占据人口大多数的汉族人通用汉字，使得中国经历了数次外族入侵，外族统治者都选择了汉化，因为只有使用汉字才能让统治者的政令传递到基层。而西方则不同，<strong>欧洲的拉丁文字是表音文字，语言和文字耦合度过高</strong>。罗马国家建立之后，拉丁语成为官方语言，但随着罗马帝国的逐渐分裂，拉丁语也随着各地方言的差异不断分裂，这使得在中国出现的“分久必合”无法在欧洲出现。另外作为中国四大发明的“纸”使得文字信息的传播效率大大提高。东汉初期的蔡伦改进了造纸技术，让纸能用于书写，纸的出现不仅代替了竹简和锦帛等信息载体，也造就了中国璀璨的书法艺术：东汉草书鼻祖张芝改章草为小草，笔画连绵，字间连缀；汉末行书鼻祖刘德升，行云流水，效率和辨识度兼备；三国楷书鼻祖钟繇，初具棱角，章法分明；东晋书圣王羲之、王献之、王珣；后世欧颜柳赵，苏黄米蔡更是书写了一个个书法艺术的明珠。这种书法艺术造就的文化认同，也增加了国家的凝聚力。而在西方造纸术和活字印刷使得书籍广泛传播，为文艺复兴、科学革命奠定了基础。可以说<strong>造纸术和印刷术是人类第三次信息革命，革新了信息的载体，提高了信息传播效率</strong>，纸的成本极低，书写方便，远远超过以前的甲骨、竹简、锦帛。</p><h2>法律、道德和宗教的目的是维护社会秩序</h2><p>伦理道德最早是人类从群婚制演变为对偶婚制过程中产生的，最早追溯到人文始祖伏羲制定婚姻制度，目的是避免近亲繁殖出现遗传疾病，同时通过道德约束合理分配劳动所得使男性能承担起养育后代的责任。可以看到，中原文明对未能遵守这项道德的部落或国家称为未开化的蛮夷，最开始是楚国荆蛮，接着是西戎蛮夷，匈奴蛮夷……</p><p>对偶婚制催生以家庭为单位的生产关系，正是家庭的出现，使得私有制产权关系的伦理道德出现。私有制成为了人类奋斗的动力，也是人类历史周期循环的驱动力。马克思设想的公有制只有在这种伦理道德消灭后才可能出现，而彼时父子、母子、夫妻等社会关系也将不复存在，此时的人类或许以另一种方式繁衍或者得到永生。</p><p>道德规范的是人的主观意识，只能约束有道德的人；法律规范的是人的客观行为，可以惩罚不遵守规则秩序的人。先秦儒家就是主张以道德治国的主要流派，法家就是主张以法律治国的流派。道德没有强约束力，每个人每个时代的道德观念差别也很大，没有统一的标准，用道德可以约束自己达到自律，但模糊的道德无法约束所有人。因为儒家的理想主义没有考虑人性的幽暗，最终战国主张儒家的国家都灭亡了。法律约束力强，白纸黑字明文规定。特别是税法是是社会财富分配的工具，统治者通过鼓励耕战等社会利益的分配手段，能打造出秦国这样军国主义的战争机器，但严刑峻法也剥夺了个体的人性，使人成为社会机器。而且人客观造成的犯罪，有时并非主观意愿，法律过于严苛死板，法不容情，容易造成冤假错案。另外执法人员也是芸芸众生的一员，也有人的局限性，法家没有考虑执法者内心的幽暗，执法者可能成为破坏社会秩序的力量。中国古代有能力的统治者结合两者，慢慢发展出外儒内法的制度。而现代法律也结合了法治与德治的思想：定罪以客观行为为准，论迹不论心；量刑以主观意识为依据，结合犯罪主体实际情况酌情处理，如犯罪行为分故意犯罪和过失犯罪，刑事责任年龄等成为量刑依据。</p><p>法律和道德的目的都是维护秩序，在不同历史时期也会随之发展。随着牛马等畜力的驯化，农业生产力得到发展，法律也因此改变，牛马作为农业时代最重要的生产力，古代王朝通常都会规定私自宰杀牛马会获罪。中国古代重农主义，统治者认为农业为本，工商为末，因此宋明两代会有禁止商人穿绸缎的禁令。</p><p>在漫长的农业发展过程中，东西方都发展出了宗教。宗教原本产生于人类对自然现象的神秘感和对自然力量的恐惧与崇拜，人类想象出各种神话寓言来解释自然现象，后来逐渐被统治阶级作为控制社会意识形态的工具，它限制了人们的思想。在东西方，人类都长期受<strong>宗教陷阱</strong>的桎梏。</p><p>中国的儒释道三教在漫长的历史中实现了三教合一。道教发源于春秋时期的老子，老子的《道德经》本是他在春秋诸国纷争时对人类社会和宇宙本源的哲学思考，后世逐渐演变成宇宙阴阳、修仙问道的宗教思想；儒家由孔子创立，后由汉武帝罢黜百家独尊儒术成为主流思想，后世统治者逐渐将儒学改造成“君为臣纲 父为子纲 夫为妻纲”三纲五常的道德秩序；佛教发源于古印度，由老子同一时代的释迦摩尼创建，东汉明帝时期传入中国被称为“浮屠教”，南北朝时期，战争不断，人们面对人世变幻无常，佛教开始在各地盛行。西方罗马帝国时期，巴勒斯坦地区的耶稣创建基督教，现在通用的公元纪年就是以耶稣的诞辰作为起始日，后来逐渐分化为天主教(罗马公教)、东正教(东罗马正统大公教)、新教三大流派，基督教是欧美诸国流行，甚至至今仍是梵蒂冈(罗马教廷)的国教；伊斯兰教与基督教、佛教同为世界三大宗教，由穆罕默德于公元7世纪初在阿拉伯半岛创立，在中东诸国流行。</p><p>在中国，宗教通常是统治者用于统治底层民众的工具，但国家权力始终在宗教之上。而西方，政权和神权之间多有纷争，甚至大多数时候神权凌驾于王权之上，这也是为什么西方国王需要教皇加冕，这本质上和东方的“君权神授”有异曲同工之处。也正因此，西方在漫长的中世纪民众的思想都受到了宗教的禁锢。</p><p>十四世纪中叶黑死病导致了宗教信仰的崩塌，信上帝买赎罪券并不能保佑你免遭瘟疫，而后文艺复兴思想解放运动在西欧一直延续到16世纪，期间涌现了众多注重人本思想的人文艺术家，如文学三杰(但丁、彼特拉克、乔万尼·薄伽丘)、美术三杰(达·芬奇、拉斐尔·桑西、米开朗基罗)、莎士比亚；16世纪马丁路德等人提出宗教改革，新教由此诞生，它动摇了天主教的神权统治，也改变了政教合一的局面；与此同时，以哥白尼为代表的科学革命使得理性的科学思维方式开始萌芽，17-18世纪启蒙运动使得封建主义解体，自由、民主、平等的理性主义思想盛行，哲学、自然科学、社会科学开始百花齐放。</p><p>科学革命引领技术变革，技术变革使得生产力进步，带动生产关系变革和社会制度的变迁。西方重商主义促成了欧洲资本的原始积累。15世纪末由于大航海的地理大发现扩大了世界市场，西欧出现了专制的中央集权国家，圈地运动使得农民与土地分离，失去生产资料的农民沦为无产者不得不出卖自己的劳动力；荷兰(荷兰东印度公司、荷兰西印度公司)、英国(英国东印度公司)先后在全球殖民主义掠夺中成为世界头号强国，殖民者往返于欧非美三大洲进行黑奴贸易；农奴制榨取着劳动人民的剩余价值，萃取成资本，成就了不列颠的日不落帝国称号。</p><p><img src="https://ts1.cn.mm.bing.net/th/id/R-C.8dc1d76fd2d4131474a8fea9c3850a11?rik=i7usqT9KFQlYSQ&riu=http://n.sinaimg.cn/sinakd20210325ac/597/w1406h791/20210325/dbb7-kmvwsvx7967518.jpg&ehk=fDzPWjFSXSPA1tFP9aDEPqulSPZ0HhBqjoGcDSs7soY=&risl=&pid=ImgRaw&r=0" alt="黑人奴隶为农场主摘棉花"></p><p>历史中帝国的辉煌与王朝的盛世背后，是无数劳动人民血和泪铸就的。统治者使用宗教、道德约束劳动人民的思想和行为，正如鲁迅所说历史写满了仁义道德，字缝里却只见“吃人”二字。</p><p>古代的宗教文化与道德观念都是当时生产力的产物，因为人多地少是当时的主要矛盾。经济基础决定了政治、法律、文化等上层建筑。</p><p>道德化的看问题，容易掩盖历史真相，真正推动人类历史进步的是生产力的发展，只有通过这个视角才能看透历史上所谓的“野蛮征服文明”的假象。</p><h2>工业时代的生产力发展</h2><p><strong>科学革命推动了技术的进步，引发了欧洲的工业革命</strong>。欧洲工业革命的发展，让欧洲的生产力飞速提升。而明清两代西方大量的丝绸、瓷器、茶叶等需求导致世界大量的白银流入中国，为了平衡贸易逆差打开闭关锁国的中国市场，西方将鸦片输入中国并发动了鸦片战争，自此后中国历经多次战败，也进行了洋务运动被迫工业化。建国后，我们又以举国之力进行工业化————中国开始一步步顺应世界潮流进入工业化时代。</p><p>为什么工业革命发生在欧洲而不是中国？因为欧洲有科学。首先明确一点，常说的科技包含科学和技术，这两者要区分开。<strong>科学是认识世界，技术是改造世界</strong>。中国古代有技术而无科学，中国的齐民要术、梦溪笔谈、农政全书、天工开物等传统丛书都是技术经验的积累，而没有科学的深层解释，中国的哲学思辨还停留在阴阳五行的层次，这使得技术发展只能是无规律的试错，进展缓慢。欧洲文艺复兴后，传统希腊科学的理性思维得到进一步发展，伽利略、牛顿、拉瓦锡、法拉第等科学家通过定量实验和数学计算让自然规律有了哲学思辨，有了科学指导，技术会爆炸式地发展。这就像中医和西医的区别，中医是经验点的积累，复杂但不系统，底层哲学原理是阴阳五行；西医是基于化学、生物学、有机化学、遗传学、分子生物学等科学体系的积累，比如遗传学使得生物学扩大了认知，分子遗传学再次扩大了人类对生物体的认知，这种基于自然哲学的科学认知是成体系的。因此现在的中医不敢说比500年前李时珍时期的中医牛逼，但西医肯定敢说比500年前的西医更牛逼。</p><p>当然，西方科学昌明除了启蒙运动带来的理性思考，还有一个客观原因，那就是西方玻璃工业更加先进。西方容器以玻璃为主，东方容器以陶瓷为主。而玻璃透明的性质让西方工匠能制造出凸透镜，使得人类能探索宏观的宇宙、微观的细胞。比如伽利略制作了世界上第一台天文望远镜，促成了他在观测天文学上的成就，也正是天文望远镜的出现使得东西方天文学拉开巨大差距，当伽利略发现木星的卫星时，我们还在用金木水火土阴阳五行命名天上的星星；牛顿在伽利略的基础上制造了更先进的望远镜和棱镜，造就了他在天文学和光学领域的辉煌成绩；罗伯特胡克制作了第一台显微镜成为第一个观察到细胞的人，同一时期的列文虎克改进显微镜使显微镜能放大两百多倍，人类对微观世界的认知更加开阔。西方发展出玻璃为代表的现代科学，东方发展出陶瓷为代表的大陆文化，这也是各自的地理位置所导致。西方文化发源于地中海，最不缺的是沙子，而沙子是制作玻璃的重要原料；中国发源于大陆，最不缺的是黏土，特别是景德镇瓷器为代表的高岭土，中国的高岭土资源居世界前列，这是陶瓷技术诞生的基础。中国的《墨经》中有使用冰制作凸透镜的记载，可惜冰的熔点较低，使其缺乏玻璃透镜的天然优势。春秋战国各路思想的百花齐放，说明中国从来不缺充满好奇心和探索欲的人，缺的是探索宏观和微观世界的工具。</p><p>正是科学的进步使得西方技术和工业不断革命，人类对物质和能量的利用率极大的提高。</p><p>1760年代开始，<strong>第一次工业革命以牛顿力学为科学基础</strong>，以煤炭能源为辅助使得蒸汽机、纺纱机、火车等技术得到发展，人类进入蒸汽时代。这次技术革命主要革新的是能源技术：蒸汽机和火车等机器对煤炭的利用，将煤炭中化学能以燃烧出热能的形式转化为机器的动能。而蒸汽机和火车的制造得益于各种新式炼钢法的发展，这是材料技术的突破。</p><p>1860年代开始，<strong>第二次工业革命以拉瓦锡开创的化学、法拉第开创的电磁学为理论基础</strong>，以化石能源为辅助，使得内燃机、发电机等技术得到发展，人类进入电气时代。这次技术革命包括<strong>能源革命</strong>：第一、内燃机对化石燃料的利用，将汽油中的化学能以燃烧出热能的形式转化为机器的动能，内燃机将热能封锁在燃机内部，相比瓦特改良的蒸汽机烧开水的形式更加高效，这期间最具时代意义的便是卡尔本茨发明的第一台汽车、亨利·福特通过流水线生产的福特汽车；第二、发电机将动能转化为电能，使得能量可以通过导线传递，这期间具有划时代意义的是托马斯·爱迪生发明了电灯，维尔纳·冯·西门子发明的电车，尼古拉·特斯拉发明的交流电输电技术。<strong>信息革命</strong>：<strong>塞缪尔·莫尔斯发明的电报、亚历山大·贝尔发明的电话等技术是人类的第四次信息革命</strong>，信息以电信号、电磁波等形式进行传递，信息传播的速度远远超过了以往通过纸质媒介传递的速度。<strong>材料革命</strong>：得益于化学的发展，炼钢工艺逐渐发展为现在熟知的现代炼钢技术：转炉炼钢法，平炉炼钢法，电弧炉炼钢法。值得一提的是，谍战剧中常见的莫尔斯电码就是最早的二进制信息编码方式，亚历山大·贝尔建立了美国电话电报公司(AT&amp;T)并成立了贝尔实验室，后来的晶体管、发光二极管、交换机、通信卫星、C语言、UNIX操作系统等跨时代的技术都是出自贝尔实验室，1925年以来，贝尔实验室共获得两万五千多项专利，8项（13人）诺贝尔奖，因此也被誉为“诺奖摇篮”，可以说，人类迈向信息革命的每一步都与贝尔实验室息息相关。</p><p>1940年代，<strong>第三次工业革命以爱因斯坦的相对论、普朗克薛定谔等人开创的量子力学、艾伦图灵与冯诺依曼开创的计算机科学以及香农的信息论、沃森和克里克开创的分子遗传学为理论基础</strong>，以核裂变、核聚变等原子能为辅助，使得核电、半导体集成电路、航天航空、卫星通信、基因工程等技术得到发展。其中原子能技术属于能源革命范畴；单晶硅等半导体材料，橡胶、合成纤维、塑料等高分子材料属于材料革命范畴，而<strong>计算机、互联网等技术属于信息革命</strong>范畴。在贝尔实验室工作的香农提出信息论，从理论上描述了信息的编码存储、压缩传输，图灵和冯诺依曼分别设计了计算机的初始模型，为计算机的发展奠定了基础。可以看到，国内90年代还在用的基于电子显像管的黑白电视没过多少年就换成了大彩电，大彩电还没用多少年，基于发光半导体的液晶电视就占领了主要市场；90年代农村家里很难有一台电话，2000年后诺基亚、摩托罗拉手机也开始在中国流行，各种山寨机也风靡全国，翻盖的、滑盖的、触屏的各式各样，10年后智能手机开始出现，2011年小米发布了第一台小米1手机，随后移动互联网的旋风刮倒了中华大地的每一个角落。科技正在以肉眼可见的速度极速发展着，能源的利用效率在不断的提高，人造材料的物理性能满足了越来越多样化的需求，信息的传播效率也越来越高。</p><p><strong>从人类技术的发展脉络看，主要分为材料革命、能源革命、信息革命三条主线，三条线相互交织，相互影响</strong>。人类的石器时代、青铜时代、铁器时代分别代表了材料技术的三个阶段，其中石器时代分为三个阶段，旧石器时代的打制石器，中石器时代的琢制石器，新时期时代的磨制石器和烧制陶器，烧制陶器（陶器的烧结温度在800～1000摄氏度）的出现表示人类已经学会利用火，青铜技术（铜的熔点1083℃）、铁器技术（铁的熔点1538°C）以及后面的瓷器技术（瓷器的烧结温度在1300～1400摄氏度）对温度的要求越来越高，说明了人类对能量的利用效率在逐渐提高，工业革命后随着化学的发展，新兴材料不断涌现满足了人类的各种需求。能源革命方面，从钻木取火开始，到工业革命后煤炭的异军突起，到后来全面爆发的石油工业，以及现在发展的各种新能源，核能、太阳能、风能、水能、潮汐能、地热能…获取能源的途径越来越多，其中风能、水能是太阳辐射造成大气运动产能的能量，本质上也是来源于太阳能，而太阳能是氢核聚变产生，因此要想真正拥有用之不尽的能源必须掌握可控核聚变的原子能技术。信息革命方面，人类从语言、文字的出现，到纸媒、电报、电话、电视、互联网、大数据、人工智能，人类对信息的传播速度和对信息的利用效率也在不断的提高。</p><p><img src="https://pic4.zhimg.com/80/v2-c5de5a6c613a64cbc68d27832738a17f_1440w.webp" alt="前苏联科学分类学家凯达洛夫院士的科学三角形"></p><p>科学革命引领了技术进步。要想加速技术进步的步伐，还要加强基础科学理论研究，发现更多的自然规律，开拓人类的世界观。现代科学起源于哲学，古希腊的亚里士多德最早创立逻辑学，是公元前希腊哲学的集大成者。而后各大科学门类逐渐从哲学分化，伽利略对亚里士多德的批判初步奠定了惯性体系，直到牛顿的《自然哲学的数学原理》标志着经典物理学大厦的初步建成。20世纪爱因斯坦的《相对论》颠覆了牛顿经典物理学的绝对时空观，并提出统一场论企图统一4种基本相互作用，由于相对论不适用与微观量子，爱因斯坦与普朗克、波尔等人创立量子力学。物理学是化学的基础，化学是生物学的基础，生物学是心理学的基础，心理学是社会学的基础。目前，物理学家们在致力于大统一理论以统一相对论与量子力学隔阂。</p><p><a href="https://space.mit.edu/home/tegmark/toe.html"><img src="https://pic3.zhimg.com/v2-91f248bb16673a84510b6bdb381261a2_r.jpg" alt="大一统理论"></a></p><p>我国近几年在基础理论研究方面加大了投资，各种用于理论研究的基础设施也拔地而起，四川稻城的高海拔宇宙线观测站拉索、圆环阵列射电望远镜千眼天珠，还有落地在四川雅砻江水电站的地下2400米锦屏地下实验室…这些科学设施为我们发现更广阔的自然世界提供了基础。</p><p><img src="https://pic4.zhimg.com/80/v2-06a438f2b1454c04efe7bc7acc26edc3_1440w.webp" alt="新科学三角"></p><p>技术进步，还需要充分利用现有的科学理论进行技术创新，改造世界。我国的裂变堆已经有两套技术体系了，一套是引进美国技术的“国和一号”，一套是引进法国技术的“华龙一号”。在充分吸收这些技术后，我们还自主研发的模块化核裂变小型堆“玲龙一号”，该技术目前已经在海南建设了，东方超环EAST和环流三号等核聚变技术也在进行不断的突破，有望在2050年前实现可控核聚变能源的利用。这些技术的发展正是对前人科学理论的充分利用。</p><p>技术的进步促进了资本积累和产业升级。正是技术要素使得生产力突破了传统农业的“马尔萨斯陷阱”。杂交育种技术和化肥农药技术让现代农业能产出更多粮食，世界人口也从1800年的10亿增长至如今的80亿。</p><p>社会科学是用科学的思维研究社会发展规律，19世纪的马克思和恩格斯是社会科学研究的集大成者，马克思主义中的历史唯物主义是研究人类历史发展规律最科学的方法论。马克思的《资本论》阐释了工业社会下资本的运行逻辑。</p><p>工业时代的生产力发展需要资本和技术的两大要素的支撑。有资本(积累的劳动剩余)才能建厂房扩大再生产、才能供养暂时没有产出的研发人员开发更先进的技术。</p><p>而资本的积累本质是劳动剩余的积累，假设一个工厂把赚取的利润都分给员工了，它将无法扩大再生产，这个企业必然在更新的技术浪潮中覆灭。</p><p>对于国家而言也是如此，经济要发展，当前劳动者就必须要让渡一部分劳动剩余。</p><p>新中国刚建立时，中国的资本来自于苏联。中苏交恶导致苏联撤资，同时遇上美苏冷战，中国必须在美苏的夹缝中寻找发展机会。而资本的稀缺导致我国不得不通过工农业剪刀差将农业的劳动剩余补贴给工业。</p><p>国家通过统购统销收取农民的粮食，以此压低粮食价格保证城市生活资料的供应；城市压低工人工资、并通过粮票布票等制度全面管控生活必需品的发放。而人为的扭曲导致城市的岗位稀缺，种田的农民都想进城怎么办，城乡隔绝的户口制度诞生。也正因此我们才有资本去供养两弹一星的科学家们研发国防科技。有了国防实力，我们才有资格上美苏博弈的牌桌，中美建交也证实了这一点。此时的工业以军用重工业为主，虽然原子弹爆炸了、卫星上天了，但人民的生活迟迟得不到改善，建国之初的人们为国家发展做出了极大的付出。</p><p>农业时代的财富来源是土地，而工业时代的财富来源有人口、技术和市场：<strong>人</strong>通过<strong>技术设备</strong>对生产资料进行加工制造商品到<strong>市场</strong>上卖出去。中西方不同时期对这三个要素的侧重点也不同。</p><p>1、人口。农业时代人口达到生产力瓶颈后，人口是社会的负担。1982年人口普查时，中国的人口已突破10亿大关，这也是改革开放后计划生育被定为国策的原因。但工业时代人口就是劳动力。在资本主义早期，英国圈地运动的“羊吃人”现象实现了农民与土地的分离，农民们流入城市为城市提供了劳动力。随着工业革命的发展，欧洲国家通过殖民掠夺在世界各地制造了大量的奴隶为其工作，历史上的美国蓄奴制直到南北战争之后才被废除，目的也是为了让南方的大量农奴能进工厂打工。</p><p>而中国改革开放通过市场换技术，外资进入中国，带来了资本和技术，关系老百姓衣食住行的轻工业也得到了发展，老百姓的生活得到了极大的改善。而城市劳动力资源不足，于是开放户籍人口流通，农民进城务工蔚然成风。改革开放后的这段时间，沿海的私营企业通过农民工们做衬衫毛衣创造的劳动剩余换取美元，国家通过外汇管制，让私企们将美元换成人民币在国内消费，国家得到美元后再到国际市场进口农产品解决吃饭问题，同时换取飞机、芯片、航母等更先进的技术。此时的中国能迅速发展依靠的是庞大的人口带来的劳动力资源和市场红利。</p><p>2、技术。技术是生产力发展的推动力。随着技术的发展，技术的进步带来的效用比单纯叠加人力更有效。西方这一时期的法律也渐渐转变——不再强迫人们去当工人，而是注重知识产权的保护。专利法促进了技术创新，使得发明人可以通过专利许可积累资本，也让发明者的时间和精力可以集中在技术创新上，如上个世纪的奔驰、福特创始人都是汽车工程师出身。</p><p>中国改革开放后，很早就有了专利法，但是真正开始注重技术专利、著作权等知识产权也才近十年，要知道10年前盗版光碟、山寨手机市场横行，那时候的中国制造是“盗版山寨高仿”的代名词。因为改革开放的前三十年我们要的是市场，技术大都是从发达国家引进的，等到技术引进得差不多了，我们必须要自主研发了，就需要保护知识产权了。研发是个巨耗成本的工作，因为技术研发成功前的这段时间是没有产出的，研发成功了就是一本万利，研发失败了就是钱打水漂了。</p><p>3、市场。市场决定着商品能卖给多少人。工业化带来了规模化生产：技术和设备投入主要在前期，一旦研发的产品打开了市场，后期只需对生产资料进行加工即可源源不断的生产出商品。只要市场越大，平均下来前期投入的成本就越小。</p><p>财富积累度过了原始阶段，形成资本，资本通过技术在一个又一个市场中攻城拔寨逐渐形成垄断地位。市场饱和后，资本为了增值会寻求新的市场。当年的鸦片战争正是西方资本寻求市场扩张发起的。当前国内互联网市场进入存量阶段后，各个互联网大厂也纷纷瞄准海外市场。字节跳动的tiktok、拼多多的temu、南京悄然崛起的Shein…都纷纷在海外布局。</p><p>工业社会生产力的发展速度会加速历史周期律的运转——财富兼并的速度被加快。古代是富者田连阡陌，贫者无立锥之地；现代就变成了富者挣一个亿都是小目标，贫者996加班还房贷。</p><h2>人类如何摆脱周期律</h2><p>马克思曾在共产党宣言中预言，物质极大丰富的共产主义必然取代资本主义。我觉得这个问题值得思考，资源和人口矛盾的马尔萨斯陷阱虽然已经突破，但社会的分配制度并不平等。资本主义的私有制必然导致掌握土地、技术、资本等生产资料的有产者财富不断积累，不掌握生产资料的无产者只能依附于有产者出卖自己的劳动力。有产者财富呈指数增长，无产者财富呈线性增长，且现代货币的通货膨胀会让有产者的资产价值提升，无产者持有的货币价值下降，在逆周期时期无产者失去工作会一贫如洗。解决产权不平等的问题，要么向外扩张开拓新的资源，比如发动战争对外扩张、大航海发现新大陆、飞往太空开发火星…。要么进行劫富济贫式的产权重新调整，这必然导致人类内部的自我消耗，暴力革命是我们都不愿看到的，代价很高，而且生产力也会倒退，特别是核武器的出现导致战争的烈度会比以往任何时候都要高，通过税收进行二次分配是一种和平的制度革命，但改革的阻力必然会非常大。<strong>人类的历史本质就是相对公平与极度不公平之间不断的轮回</strong>。外开拓新资源，需要人类走出舒适区探索未知的领域，比如当地球资源或空间有限时，人类应当走出地球这个摇篮，飞往更加广袤的宇宙。人性有其自身的诸多弱点，如懒惰、享乐主义、耽于安逸、不患寡而患不均…，但人性中也有其光辉的一面，求知欲、好奇心、探索欲…人类社会想要摆脱周期律，必须要尽力避免人类自身的弱点，发挥自身光辉的一面。总之，<strong>走出资本主义的陷阱，必然要突破现有的伦理道德</strong>。</p>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;blockquote&gt;
&lt;p&gt;人猿相揖别。只几个石头磨过，小儿时节。铜铁炉中翻火焰，为问何时猜得？不过几千寒热。人世难逢开口笑，上疆场彼此弯弓月。流遍了，郊原血。&lt;br&gt;一篇读罢头飞雪，但记得斑斑点点，几行陈迹。五帝三皇神圣事，骗了无涯过客。有多少风流人物？盗跖庄屩流誉后，更陈王奋起挥黄钺。歌未竟，东方白。&lt;br&gt;贺新郎·读史————毛泽东&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;农业时代的生产力发展&lt;/h2&gt;</summary>
    
    
    
    <category term="经济与金融" scheme="https://blog.hufeifei.cn/categories/%E7%BB%8F%E6%B5%8E%E4%B8%8E%E9%87%91%E8%9E%8D/"/>
    
    
    <category term="经济" scheme="https://blog.hufeifei.cn/tags/%E7%BB%8F%E6%B5%8E/"/>
    
    <category term="历史" scheme="https://blog.hufeifei.cn/tags/%E5%8E%86%E5%8F%B2/"/>
    
  </entry>
  
  <entry>
    <title>SpringBoot3的新特性-RFC7807-ProblemDetail</title>
    <link href="https://blog.hufeifei.cn/2023/05/J2EE/Spring-RFC7807-ProblemDetail/"/>
    <id>https://blog.hufeifei.cn/2023/05/J2EE/Spring-RFC7807-ProblemDetail/</id>
    <published>2023-05-27T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.691Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>默认情况下，SpringBoot提供了<a href="https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/web/servlet/error/DefaultErrorAttributes.html">DefaultErrorAttributes</a>类，该类实现了<a href="https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/web/servlet/error/ErrorAttributes.html">ErrorAttributes</a>接口，以在发生未处理的错误时生成错误响应。在默认错误的情况下，系统会生成一个 JSON 响应结构，我们可以更仔细地检查它：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;timestamp&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2023-04-01T00:00:00.000+00:00&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;status&quot;</span><span class="punctuation">:</span> <span class="number">500</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;error&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Internal Server Error&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;path&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/api/example&quot;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>虽然此错误响应包含一些关键属性，但它可能无助于查问题。幸运的是，我们可以通过在 Spring WebFlux 应用程序中创建ErrorAttributes接口的自定义实现来修改此默认行为。</p><p>从 Spring Framework 6 开始提供了<a href="https://docs.spring.io/spring-framework/docs/6.0.7/reference/html/web.html#mvc-ann-rest-exceptions">ProblemDetail</a>来支持<a href="https://www.rfc-editor.org/rfc/rfc7807.html">RFC7807规范</a>的表示。ProblemDetail包括一些定义错误详细信息的标准属性，还有一个扩展详细信息以进行自定义的选项。下面列出了支持的属性：</p><ul><li>type (string) – 标识问题类型的 URI 引用</li><li>title (string) – 问题类型的简短摘要</li><li>status (number) – HTTP 状态码</li><li>detail (string) – 应该包含异常的详细信息。</li><li>instance (string) – 一个 URI 引用，用于识别问题的具体原因。例如，它可以指导致问题的属性。</li></ul><p>除了上面提到的标准属性外，ProblemDetail还包含一个Map&lt;String, Object&gt; 以添加自定义参数以提供有关问题的更多详细信息。示例错误响应结构如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https://example.com/probs/email-invalid&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;title&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Invalid email address&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;detail&quot;</span><span class="punctuation">:</span> <span class="string">&quot;The email address &#x27;john.doe&#x27; is invalid.&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;status&quot;</span><span class="punctuation">:</span> <span class="number">400</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;timestamp&quot;</span><span class="punctuation">:</span> <span class="string">&quot;2023-04-07T12:34:56.789Z&quot;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;errors&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;code&quot;</span><span class="punctuation">:</span> <span class="string">&quot;123&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;message&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Error message&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;reference&quot;</span><span class="punctuation">:</span> <span class="string">&quot;https//error/details#123&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>Spring Framework 还提供了一个名为<a href="https://docs.spring.io/spring-framework/docs/current/javadoc-api//org/springframework/web/ErrorResponseException.html">ErrorResponseException</a>的基本实现。此异常封装了一个ProblemDetail对象，该对象生成有关发生的错误的附加信息。我们可以扩展这个异常来自定义和添加属性。</p><h2>在SpringBoot中启用ProblemDetail</h2><p>SpringBoot默认并没有开启ProblemDetail功能，需要通过以下方式任意一种方式开启：</p><p>1、yaml配置文件</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># webmvc</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">mvc:</span></span><br><span class="line">    <span class="attr">problemdetails:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line"><span class="comment"># webflux</span></span><br><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">webflux:</span></span><br><span class="line">    <span class="attr">problemdetails:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p>2、添加ResponseEntityExceptionHandler</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@RestControllerAdvice</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">GlobalExceptionHandler</span> <span class="keyword">extends</span> <span class="title class_">ResponseEntityExceptionHandler</span> &#123;</span><br><span class="line">    <span class="comment">//...</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;默认情况下，SpringBoot提供了&lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/web/servlet/error/DefaultErrorAttributes.html&quot;&gt;DefaultErrorAttributes&lt;/a&gt;类，该类实现了&lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current/api/org/springframework/boot/web/servlet/error/ErrorAttributes.html&quot;&gt;ErrorAttributes&lt;/a&gt;接口，以在发生未处理的错误时生成错误响应。在默认错误的情况下，系统会生成一个 JSON 响应结构，我们可以更仔细地检查它：&lt;/p&gt;
&lt;figure class=&quot;highlight json&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;punctuation&quot;&gt;&amp;#123;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attr&quot;&gt;&amp;quot;timestamp&amp;quot;&lt;/span&gt;&lt;span class=&quot;punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&amp;quot;2023-04-01T00:00:00.000+00:00&amp;quot;&lt;/span&gt;&lt;span class=&quot;punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attr&quot;&gt;&amp;quot;status&amp;quot;&lt;/span&gt;&lt;span class=&quot;punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;number&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attr&quot;&gt;&amp;quot;error&amp;quot;&lt;/span&gt;&lt;span class=&quot;punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&amp;quot;Internal Server Error&amp;quot;&lt;/span&gt;&lt;span class=&quot;punctuation&quot;&gt;,&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;    &lt;span class=&quot;attr&quot;&gt;&amp;quot;path&amp;quot;&lt;/span&gt;&lt;span class=&quot;punctuation&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&amp;quot;/api/example&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;punctuation&quot;&gt;&amp;#125;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;</summary>
    
    
    
    <category term="J2EE" scheme="https://blog.hufeifei.cn/categories/J2EE/"/>
    
    
    <category term="SpringBoot" scheme="https://blog.hufeifei.cn/tags/SpringBoot/"/>
    
    <category term="WebFlux" scheme="https://blog.hufeifei.cn/tags/WebFlux/"/>
    
  </entry>
  
  <entry>
    <title>DEPTA</title>
    <link href="https://blog.hufeifei.cn/2023/01/paper/DEPTA/"/>
    <id>https://blog.hufeifei.cn/2023/01/paper/DEPTA/</id>
    <published>2023-01-25T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.703Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>Web Data Extraction Based on Partial Tree Alignment ———— 论文翻译</p><h2>摘要</h2><p>本文研究了从包含多个结构化数据记录的网页中提取数据的问题。目标是将这些数据记录进行分割，从中提取数据项/字段，并将数据放入数据库表中。这个问题已经被多位研究人员研究过。然而，现有的方法仍然存在一些严重的限制。第一类方法基于机器学习，需要对感兴趣的每个网站进行大量示例的人工标注。由于Web上存在大量的站点和页面，这个过程非常耗时。第二类算法基于自动模式发现。这些方法要么不准确，要么做出很多假设。本文提出了一种新的自动执行任务的方法。它包括两个步骤：（1）识别页面中的单个数据记录，（2）对识别出的数据记录进行对齐和提取数据项。对于第一步，我们提出了一种基于视觉信息的方法来分割数据记录，这比现有方法更准确。对于第二步，我们提出了一种基于树匹配的新颖部分对齐技术。部分对齐意味着我们仅对一对数据记录中可以确凿对齐（或匹配）的数据字段进行对齐，并不对其余的数据字段做出承诺。这种方法能够非常准确地对齐多个数据记录。使用来自不同领域的大量Web页面的实验结果表明，所提出的两步技术能够非常准确地分割数据记录，并从中对齐和提取数据。</p><h2>1、介绍</h2><p><img src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/fd2803c3-a00a-4c7b-a76b-e9a813c28ac8" alt="image"></p><p>结构化数据对象是Web上非常重要的一种信息类型。这些数据对象通常是来自底层数据库的记录，并以一些固定的模板显示在Web页面中。在本文中，我们也称它们为数据记录。在Web页面中挖掘数据记录是有用的，因为它们通常呈现它们所在页面的基本信息，例如产品和服务列表。提取这些结构化数据对象使得我们能够整合来自多个Web页面的数据/信息，提供增值服务，例如比较购物、元查询和搜索。图1展示了Web上一些示例数据记录。图1（A）显示了一个包含两本产品（图书）列表的Web页面段落。每本书的描述是一个数据记录。图1（B）显示了一个包含数据表的页面段落，其中每个数据记录是一个表行。我们的目标有两个：（1）自动识别页面中的这些数据记录，（2）自动对齐和提取数据记录中的数据项。</p><p>文献中报道了多种从Web页面中挖掘数据记录的方法。第一种方法是手动方法。通过观察Web页面及其源代码，程序员从页面中找出一些模式，然后编写程序来识别和提取所有的数据项/字段。这种方法在处理大量页面时不具有可扩展性。其他方法都具有一定程度的自动化。主要有两种算法，即包装器归纳和自动提取。在包装器归纳中[11, 19, 23, 25, 33]，从一组手动标注的页面或数据记录中学习一组提取规则。然后利用这些规则从类似页面中提取数据项。这种方法仍然需要大量的手动工作。在自动方法中，[12] [1]从包含类似数据记录的多个页面中找出模式或语法。然而，这种方法的一个主要限制是需要找到一组包含类似数据记录的初始页面，而这些页面必须通过手动或其他系统来找到。[20]提出了一种尝试探索当前页面背后的详细信息页面以提取数据记录的方法。然而，需要详细信息页面的需求也是一个严重的限制，因为许多数据记录并没有这样的背后页面（例如，图1（B））。此外，该方法假设详细页面已经存在，这在实践中是不现实的。由于典型Web页面中存在大量链接，自动识别指向详细信息页面的链接是一个非常棘手的任务。[8]提出了一种字符串匹配方法，但其结果不够强大，如[21]所示。大多数当前系统做出的另一个假设是，数据记录的相关信息包含在HTML代码的连续段中。然而，在一些Web页面中，一个对象的描述可能与其他对象的描述交织在一起。例如，HTML源代码中两个对象的描述可能按照以下顺序排列：对象1的部分1，对象2的部分1，对象1的部分2，对象2的部分2。因此，对象1和对象2的描述不是连续的。然而，当它们在浏览器上显示时，它们对于人类观看者来说是连续的。在第2节中，我们详细讨论了这些方法，并与我们提出的方法进行了比较。</p><p>本文提出了一个两步策略来解决这个问题。</p><p>1、首先，该方法通过对页面进行分割来识别每个数据记录，而无需提取其数据项。我们改进了先前用于此目的的技术MDR [21]。具体而言，新方法也利用视觉线索来寻找数据记录。视觉信息以两种方式帮助系统：</p><p>（i）它使系统能够识别分隔数据记录的间隙，这有助于正确分割数据记录，因为数据记录内的间隙（如果有）通常较小于数据记录之间的间隙。</p><p>（ii）所提出的系统通过分析HTML标签树或DOM树 [7] 来识别数据记录。构建标签树的一种简单方法是按照HTML代码中的嵌套标签结构进行处理。</p><p>然而，必须加入复杂的分析来处理HTML代码中的错误（例如，缺失或格式不正确的标签）。而视觉或显示信息可以在HTML代码被Web浏览器渲染后获得，它还包含有关标签的层次结构的信息。在这项工作中，我们不是分析HTML代码，而是利用视觉信息（即标签在屏幕上的位置）来推断标签之间的结构关系并构建标签树。由于Web浏览器的渲染引擎（例如Internet Explorer）具有较高的容错性，因此这种方法可以实现更强健的树结构构建。只要浏览器能够正确地渲染页面，就可以正确构建其标签树。</p><p>2、提出了一种新颖的部分树对齐方法，用于对齐并提取发现的数据记录中的相应数据项，并将数据项放入数据库表中。由于HTML代码的嵌套（或树状）组织方式，使用树对齐是自然而然的选择。根据我们的实验证明，这种新方法非常准确。<br>具体来说，在确定了所有的数据记录之后，每个数据记录的子树被重新排列成单一的树，因为每个数据记录可能包含在页面的原始标签树中的多个子树中，并且每个数据记录可能不是连续的。然后，使用我们的部分对齐方法对所有数据记录的标签树进行对齐。在部分对齐中，我们指的是对于每对树（或数据记录），我们仅对齐那些可以确定对齐的数据字段，并忽略那些无法对齐的部分，即不确定未对齐数据项的位置。过早地做出不确定的对齐决策可能会对后续涉及其他数据记录的对齐产生不良影响。这种方法在多个树的对齐中非常有效。</p><p>由此产生的对齐结果使我们能够从页面中提取所有数据记录的数据项。它还可以作为一个提取模式，用于从使用相同模板生成的其他带有数据记录的页面中提取数据项。</p><p>我们的两步方法被称为DEPTA（基于部分树对齐的数据提取），与所有现有方法非常不同，它不会做出现有方法所做的那些假设。只要一个页面包含至少两个数据记录，我们的系统就会自动找到它们（有关更多讨论，请参见第3.5节）。我们使用大量页面的实验结果表明，所提出的技术非常有效。</p><h2>2、相关工作</h2><p>与我们的相关工作在包装生成领域。包装是从网站或页面中提取数据并将其放入数据库的程序[1, 11, 12, 16, 18, 19, 22, 23, 25]。有两种主要的包装生成方法。</p><p>第一种方法是包装归纳，它使用有监督学习从一组手动标记的正负样本中学习数据提取规则。然而，手动标记数据是费力且耗时的工作。此外，对于不同的网站或甚至同一网站的不同页面，手动标记过程需要重复进行，因为它们遵循不同的模板/模式。示例包装归纳系统包括WIEN [19]，Softmealy [18]，Stalker [23]，WL2 [11]，[25]等。我们的技术不需要人工标记。它可以自动在页面中挖掘数据记录并从记录中提取数据。</p><p>第二种方法是自动提取。在[14]中，研究了自动识别数据记录边界的方法。该方法基于一组启发式规则，例如最高计数标签、重复标签和本体匹配。[5]提出了一些更多的启发式规则来执行任务，而不使用领域本体。然而，[21]表明这些方法产生了较差的结果。此外，这些方法不会从数据记录中提取数据。[8]提出了一种从页面的HTML标签字符串中找到模式的方法，然后使用这些模式提取数据项。该方法使用了Patricia树和序列对齐来找到非精确匹配。然而，[21]表明其性能也较弱。我们的新方法不使用标签字符串进行对齐，而是使用树，利用嵌套的树结构来进行更准确的数据提取。[13]还提供了一组启发式规则来找到单个产品信息，例如价格和其他信息。</p><p>在[1, 12, 34]中，提出了另外两种技术。然而，它们需要使用包含相似数据记录的同一网站的多个页面（假定这些页面已给出）来从页面中找到模式或语法来提取数据记录。假设可用的包含相似数据记录的多个页面是一个严重的限制。我们的方法适用于每个单独的页面。</p><p>[20]提出了另一种数据提取方法。其主要思想是利用当前页面后面的详细数据来识别数据记录。通常，包含多个数据记录的页面并不包含每个数据记录的完整信息。相反，通常使用链接指向包含产品详细描述的页面。因此，该技术适用于图1（A）中的示例，但不适用于图1（B）中的示例，因为图1（B）中的每个数据记录都没有指向详细页面的链接。此外，[20]中的方法假设详细页面已经存在（在他们的实验中，这些页面是手动确定的），这是不现实的。由于典型网页中存在大量链接，自动识别指向详细页面的正确链接并不是一项简单的任务。我们的技术适用于图1中的两种页面类型，因为它不需要任何详细页面。</p><p>大多数现有方法的另一个问题是它们假设数据记录的相关信息包含在HTML代码的连续段中。这并不总是正确的。这个问题在介绍部分已经讨论过。我们提出的方法能够处理这种情况，因为我们的记录分割方法能够识别出这样的数据记录。在[21]中，我们提出了MDR算法，它只识别数据记录，但不对数据记录进行对齐或提取数据项。因此，它只完成了我们任务的第一步。即使对于第一步，它也有两个主要缺点。(1)该算法利用Web页面的HTML标签树从页面中提取数据记录。然而，某些页面的HTML源代码中的错误标签使得构建正确的树变得困难，从而无法在这些页面中找到正确的数据记录。使用视觉（渲染）信息来构建我们的新系统中的树解决了这个问题。(2)单个数据记录可能由多个子树组成。由于噪声信息，MDR可能会找到错误的子树组合。在我们的新系统中，数据记录之间的视觉间隙有助于解决这个问题。请注意，视觉线索已在其他Web任务中使用，例如找到不同的语义块[29, 28]。</p><p>最后，在[27]中，树匹配被用于在新闻页面中找到主要内容。然而，他们的任务与我们的不同。</p><h2>3、数据记录抽取</h2><p>现在我们开始介绍我们提出的技术。本节重点介绍第一步：将Web页面分割为单个数据记录以识别它们。本节不涉及对数据记录进行对齐或提取数据项的工作，这将是下一节的主题。由于这一步是对我们先前的技术MDR [21]的改进，因此我们在下面简要概述MDR算法，并介绍在本工作中对MDR进行的改进。我们也将增强的算法称为MDR-2（MDR的第二个版本）。</p><h3>3.1、MDR的基本思想</h3><p>MDR算法基于对Web页面中数据记录的两个观察以及一个编辑距离字符串匹配算法[2]来查找数据记录。这两个观察是：</p><p>1、 一组包含一组类似对象描述的数据记录通常以连续的区域形式呈现在页面上，并使用相似的HTML标签进行格式化。这样的区域被称为数据记录区域（或简称为数据区域）。例如，在图1（A）中，两本书在一个连续的区域中呈现。它们还使用几乎相同的HTML标签序列进行格式化。如果我们将页面的HTML标签视为一个长字符串，我们可以使用字符串匹配（例如，编辑距离[2]）来比较不同的子字符串，以找到表示相似数据记录的子字符串。这种方法的问题是计算量很大，因为数据记录可以从任何标签开始，也可以在任何标签结束。一组数据记录通常在其标签字符串方面长度不同，因为它们可能不包含完全相同的信息片段（参见图1（A））。下一个观察有助于解决这个问题。<br><img src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/24f9b5fa-7512-4190-aef2-3fc57bfa4967" alt="image"><br>2、 Web页面中HTML标签的嵌套结构自然形成一个标签树。例如，图2显示了一个示例标签树。在这个树中，每个数据记录被包裹在3个TR节点中，并且它们的子树位于相同的父节点TBODY下。两个数据记录位于两个虚线框中。我们的第二个观察是，一组相似的数据记录由相同父节点的一些子树组成。一个数据记录不太可能从一个子树的中间开始，在另一个子树的中间结束。相反，它从一个子树的开头开始，并在相同或后续的子树的结尾结束。例如，一个数据记录不太可能从<code>TD*</code>开始，并在<code>TD＃</code>结束（图2）。这个观察使得基于编辑距离字符串比较的高效算法能够识别数据记录，因为它限制了在标签树中可能起始和结束数据记录的标签范围。</p><p>实验结果表明，这些观察非常有效。我们绝不假设一个Web页面只有一个包含数据记录的数据区域。事实上，一个Web页面可能包含几个数据区域，不同的区域可能具有不同的数据记录。给定一个Web页面，算法分为三个步骤（我们还讨论了在我们当前工作中对MDR进行的改进）：</p><ol><li>第一步：构建页面的HTML标签树。在新系统中，使用视觉（渲染）信息构建标签树。</li><li>第二步：使用标签树在页面中挖掘数据区域。数据区域是页面中包含一系列相似数据记录的区域。MDR首先挖掘数据区域，然后在这些区域内找到数据记录，而不是直接挖掘数据记录（这是困难的）。例如，在图2中，我们首先找到TBODY节点下方的单个数据区域。在我们的新系统中，再次使用视觉信息可以产生更好的结果。</li><li>第三步：从每个数据区域中识别数据记录。例如，在图2中，这一步在TBODY节点下方的数据区域中找到数据记录1和数据记录2。</li></ol><p>对MDR算法的主要改进是利用视觉信息来帮助构建更健壮的树，并找到更准确的数据区域。我们下面对它们进行描述。</p><h3>3.2、构建HTML标签树</h3><p>在Web浏览器中，每个HTML元素（由起始标签、可选属性、可选嵌入的HTML内容和可能被省略的结束标签组成）都会被渲染为一个矩形。可以根据嵌套的矩形（由嵌套标签产生）构建标签树。具体细节如下：</p><ol><li>通过调用浏览器的嵌入式解析和渲染引擎（如Internet Explorer），找到每个HTML元素的矩形的四个边界。</li><li>检测矩形之间的包含关系，即一个矩形是否被包含在另一个矩形内。可以根据包含关系构建树结构。</li></ol><img width="543" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/fa185c1d-b78b-4a17-914b-53102f512ab7"><p>让我们用一个示例来说明这个过程。假设我们有图3左侧的HTML代码，其中是一个包含两行（tr）和每行两个单元格（td）的表格。浏览器的渲染引擎在图3右侧为每个HTML元素生成了边界坐标（以像素为单位）。</p><img width="486" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/8ab407b3-62bb-433c-8c2f-ccdc1afabbb4"><p>通过视觉信息，我们可以按照打开标签的顺序，并通过包含关系检查，构建出图4中的树结构。树构建算法非常直观，我们在这里不再详细讨论。</p><h3>3.3、挖掘数据区域</h3><p>该步骤会挖掘包含相似数据记录的页面中的每个数据区域。为了避免直接挖掘数据记录（这很困难），我们首先挖掘数据区域。通过比较单个节点（包括其子节点）的标签字符串和相邻多个节点的组合，我们可以找到每个数据区域。</p><img width="591" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/6b5e46c5-7b3d-4359-9156-c040e179abf9"><p>我们使用图5中的人工标签树来解释。我们发现节点5和6相似（基于编辑距离）并形成标记为1的数据区域，节点8、9和10相似并形成标记为2的数据区域，节点对（14, 15）、（16, 17）和（18, 19）相似并形成标记为3的数据区域。为了避免同时使用单个节点和节点组合，我们使用广义节点的概念来表示每个相似的单个（标签）节点和每个（标签）节点组合。因此，一系列相邻的广义节点形成一个数据区域。图5中的每个阴影单个节点或节点组合都是一个广义节点。广义节点的概念捕捉了这样的情况：数据记录可能包含在几个兄弟标签节点中，而不是一个标签节点，并且数据记录在标签树中可能不是连续的，但广义节点是连续的（见下文）。</p><p>由于第3.1节的观察，为了识别数据区域中的广义节点并进行字符串比较，所需的比较次数并不多。我们只需要在父节点的子节点之间进行比较。识别数据区域的过程比较复杂，请参阅[21]了解更多细节。</p><p>在我们的新系统中，利用数据记录之间的间隙来消除虚假的节点组合。我们利用以下关于数据记录的视觉观察：</p><p>• 数据区域中两个数据记录之间的间隙应不小于数据记录内的任何间隙。例如，在图1（A）中，两个数据记录之间存在较大的间隙。</p><h3>3.4、识别数据记录</h3><p>在确定了所有的数据区域之后，我们从广义节点中识别数据记录。需要注意的是，每个广义节点（标签树中的单个节点或节点组合）可能不代表一个单独的数据记录。情况可能非常复杂。下面，我们只强调两种有趣的情况，其中数据记录不包含在HTML代码的连续段中，以展示我们系统的一些高级功能（详细信息请参阅[21]，以及其他更简单的情况）。</p><h4>3.4.1、非连续的数据记录：情况1</h4><p>在某些网页中，对象（数据记录）的描述不在HTML代码的连续段中。有两种主要情况。图6展示了第一种情况的示例。</p><p>在这个示例中，数据区域包含两个广义节点，每个广义节点包含两个标签节点（两行），这意味着这两个标签节点（行）彼此不相似。但是，每个标签节点具有相同数量的子节点，并且子节点彼此相似。一行列出了两个对象的名称，下一行列出了对象的其他信息，也是两个单元格。这导致HTML代码如下：name 1, name 2, description 1, description 2, name 3, name 4, description 3, description 4。</p><p>对于这种情况，广义节点中每个标签节点的相应子节点形成一个非连续的数据记录。这由图6底部的标签树进行说明，其中r表示行，n表示名称，d表示描述。G1和G2是广义节点。 (n1, d1), (n2, d2), (n3, d3)和(n4, d4)形成了四个数据记录。</p><img width="538" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/178afaa6-9d99-40e3-b4ea-7c4ff7e141c7"><h4>3.4.2、非连续的数据记录：情况2</h4><p>图7展示了第二种情况的示例，其中两个或更多数据区域形成多个数据记录。在这个示例中，第一行和第二行彼此不相似，但第一行形成一个数据区域，第二行形成另一个数据区域。每个数据区域包含两个（小）广义节点。</p><p>从图7的标签树中可以看出，这种情况与图6中的情况具有相同的结构。因此，可以应用类似的策略，即将每个数据区域的相应广义节点合并在一起形成非连续的数据记录。这个过程由图7中的标签树进行说明（G1、G2、g1和g2是广义节点）。</p><img width="545" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/4284a3bc-85a6-4c32-a464-ec0994e73844"><h3>3.5、关于数据记录的重要说明</h3><p>最后，需要强调的是，MDR或MDR-2并不知道哪些常规数据记录对用户有用。它仅仅找到了所有的数据记录。然而，在特定的应用中，用户通常只对特定类型的数据记录感兴趣，例如产品列表或数据表。可以设计简单的启发式方法来仅输出所需类型的数据记录。例如，在MDR（或MDR-2）中，可以选择仅基于一些指标（如图像、价格等）输出产品数据记录。</p><h2>4、数据抽取</h2><p>我们现在介绍数据提取的部分树对齐技术。关键任务是如何匹配所有数据记录中对应的数据项或字段。这包括两个子步骤：</p><ol><li>为每个数据记录生成一个根标签树：在确定了所有数据记录后，每个数据记录的子树将重新排列为一棵单独的树。正如上文所示，每个数据记录可能包含在页面原始标签树的多个子树中，并且每个数据记录可能不是连续的。因此，这个子步骤是为了为每个数据记录组合成一棵单独的树（可能需要添加一个人工根节点）。由于这个过程相当简单，我们不再进一步讨论。</li><li>部分树对齐：每个数据区域中所有数据记录的标签树都使用我们的部分对齐方法进行对齐，该方法基于树匹配。需要注意的是，在匹配过程中，我们仅使用标签，不涉及数据项。接下来，我们首先简要介绍树编辑距离或树匹配，然后介绍本工作中使用的受限树匹配方法。之后，我们将讨论多重对齐，并介绍基于标签树对多个数据记录进行部分树对齐的方法。</li></ol><p>在这里需要指出的是，字符串编辑距离在这一步骤中并不适用，因为字符串没有考虑树结构，而树结构对于确定数据项的正确对齐非常重要。由于两个字符串的多个对齐可能导致相同的编辑距离，字符串对齐可能会产生许多错误。而且，由于大多数用于形成数据记录的标签是tr和td，通过字符串匹配很难确定正确的对齐方式，因为有许多可能的对齐方式。然而，树匹配由于树结构约束，显著减少了可能的对齐方式数量。在我们的算法中，我们只使用一个简单的规则来解决存在多个可能的树对齐时的冲突。我们简单地选择最早出现在树中的可能子树对齐。这种方法在我们的实验中表现得非常好。因此，我们没有设计更复杂的冲突解决策略。</p><h3>4.1、树编辑距离</h3><p>类似于字符串编辑距离，两个树A和B之间的树编辑距离[31, 30]（我们只关注带标签的有序根树）是将A转换为B所需的最小操作集的相关成本。在经典的定义中，用于定义树编辑距离的操作集包括三种操作：节点删除、节点插入和节点替换。通常为每个操作分配一个成本。解决树编辑距离问题通常通过找到两个树之间的最小成本映射来辅助完成[30]。映射[30]的概念在正式定义上如下：</p><p>假设X是一棵树，X[i]是树X的第i个节点，根据树的前序遍历。树A的大小为n1，树B的大小为n2，映射M是一组有序对(i, j)，每个来自树的一个节点，对于所有的(i1, j1), (i2, j2) ∈ M，满足以下条件：</p><p>（1）i1 = i2当且仅当j1 = j2；<br>（2）如果A[i1]在A[i2]的左侧，那么B[j1]在B[j2]的左侧；<br>（3）如果A[i1]是A[i2]的祖先，那么B[j1]是B[j2]的祖先。</p><p>直观地说，该定义要求每个节点在映射中最多出现一次，并且保留了兄弟节点之间的顺序和节点之间的层次关系。图8展示了一个映射的示例。</p><img width="597" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/d63374ff-4c96-4662-ac59-9a84ff360054"><p>已经提出了几种算法来解决找到将一棵树转换为另一棵树所需的最小操作集（即成本最小）的问题。所有的表述都具有二次以上的复杂性[10]。还证明了如果树没有顺序，问题是NP-complete的[36]。在[30]中，提出了一种基于动态规划的解决方案。该算法的复杂度为O(n1n2h1h2)，其中n1和n2是树的大小，h1和h2是树的高度。在[32][10]中，还提出了另外两个具有类似复杂度的算法。</p><h3>4.2、简单树匹配</h3><p>在上述一般设置中，映射可以跨越层级，例如树A中的节点a和树B中的节点a。还存在替换，例如A中的节点b和B中的节点h。在本工作中，我们使用了一种受限制的匹配算法[35]，该算法最初用于比较软件工程中的两个计算机程序，被称为简单树匹配（STM）。STM通过动态规划生成最大匹配来评估两个树的相似性，其复杂度为O(n1n2)，其中n1和n2分别为树A和B的大小。不允许进行节点替换和层级交叉。</p><p>设A和B为两棵树，i ∈ A，j ∈ B为A和B中的两个节点。树之间的匹配被定义为一个映射M，对于M中的每对(i, j)其中i和j为非根节点，有(parent(i), parent(j)) ∈ M。最大匹配是具有最大配对数的匹配。</p><p>设A = &lt;RA, A1, A2,…, Am&gt;和B = &lt;RB, B1, B2,…, Bn&gt;为两棵树，其中RA和RB为A和B的根节点，Ai和Bj分别为A和B的第i个和第j个一级子树。当RA和RB包含相同的符号时，A和B之间的最大匹配是MA,B+1，其中MA,B是&lt;A1, A2,…, Am&gt;和&lt;B1, B2,…, Bn&gt;之间的最大匹配。MA,B可以通过以下动态规划方案获得：</p><ol><li>如果Am和Bn之间的最大匹配大于Am和Bi（1≤i&lt;n）之间的任何最大匹配，则MA,B是&lt;A1, A2,…, Am-1&gt;和&lt;B1, B2,…, Bn-1&gt;之间的最大匹配加上Am和Bn之间的最大匹配。</li><li>否则，MA,B与&lt;A1, A2,…, Am&gt;和&lt;B1, B2,…, Bn-1&gt;之间的最大匹配相同，或者与&lt;A1, A2,…, Am-1&gt;和&lt;B1, B2,…, Bn&gt;之间的最大匹配相同。</li></ol><p>在图9中的Simple_Tree_Matching算法中，首先比较A和B的根节点（第1行）。如果根节点包含不同的符号，则两棵树完全不匹配。如果根节点包含相同的符号，则递归地找到A和B的一级子树之间的最大匹配，并将其保存在W矩阵中（第8行）。基于W矩阵，应用动态规划方案来找到两棵树A和B之间最大匹配中的配对数。</p><p>算法伪代码: Simple_Tree_Matching(A, B) </p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">if the roots of the two trees A and B contain distinct symbols </span><br><span class="line">  then return (0); </span><br><span class="line">else m:= the number of first-level sub-trees of A; </span><br><span class="line">  n:= the number of first-level sub-trees of B; </span><br><span class="line">  Initialization: M[i, 0]:= 0 for i = 0, …, m; </span><br><span class="line">                  M[0, j] := 0 for j = 0, …, n; </span><br><span class="line">  for i = 1 to m do </span><br><span class="line">    for j = 1 to n do </span><br><span class="line">      M[i,j]:=max(M[i,j-1], M[i-1, j], M[i-1, j-1]+W[i, j]); </span><br><span class="line">        where W[i,j] = Simple_Tree_Matching(Ai, Bj) </span><br><span class="line">    endfor; </span><br><span class="line">  endfor; </span><br><span class="line">  return (M[m, n]+1) </span><br><span class="line">endif</span><br></pre></td></tr></table></figure><img width="433" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/bf55295c-e723-46c3-90dd-c2b7864dfa20"><p>我们使用[35]中的一个例子来解释算法（图10）。为了找到树A和B之间的最大匹配，首先比较它们的根节点N1和N15。由于N1和N15包含相同的符号，返回M1-15[4,2]+1作为树A和B之间的最大匹配值（第11行）。M1-15矩阵是基于W1-15矩阵计算的，而W1-15矩阵中的每个条目，例如W1-15[i, j]，是树A和B的第i个和第j个一级子树之间的最大匹配，它是基于其M矩阵递归计算的。例如，通过构建矩阵(E)-(H)，递归计算出W1-15[4, 2]。所有相关的单元格都被阴影标记。M矩阵中的零列和零行是初始化。请注意，我们在M和W矩阵中都使用下标来指示它们所操作的节点。</p><p>在匹配过程（或匹配之后），我们可以回溯到M矩阵中，找到两个树中匹配/对齐的节点。当一个节点有多个匹配结果时，我们选择在树中出现最早的匹配。例如，在图11中，树A中的节点c可以匹配树B中的第一个节点c或最后一个节点c。我们选择树B中的第一个节点c。这种启发式方法是因为在Web页面中为了视觉效果，如果树A中的较早节点x与树B中的较晚节点y匹配，通常会有一些指示（标签）出现在x之前。根据我们的实验，这种启发式方法效果很好。</p><h3>4.3、多对齐</h3><p>由于页面中的每个数据区域都包含多个数据记录，我们需要对多个标签树进行对齐，以便在表的同一列中生成一个包含所有相应数据项/字段的单个数据库表。在这个数据表中，每一行代表一棵树（数据记录），每一列代表每个数据记录中的一个数据字段。存在几种现有算法可以执行多个序列/树的赋值。在[6]中，提出了一种使用多维动态规划的多重对齐方法。该方法是最优的，但其时间复杂度呈指数级增长，因此不适合实际使用。还提出了许多启发式方法[24, 17, 3]。在[8]中使用的居中字符串方法是一种特殊的启发式方法，用于多个序列的对齐，也可以用于树的对齐。在这种方法中，选择一个序列xc，使得（D(xi, xc)代表两个字符串的距离）的值最小。</p><p>$$<br>\sum_{k}^{i=0}D(x_i,x_c)<br>$$</p><p>然后，针对每对(xi, xc)，其中i ≠ c，执行一对一的对齐操作。假设有k个序列，且所有序列的长度为n，寻找中心序列的时间复杂度为O(k^2n^2)，而每一步的迭代一对一对齐操作的时间复杂度为O(n^2)。因此，总体的时间复杂度为O(k^2n^2)。类似地，我们可以找到一个中心树Tc，并将所有其他树与Tc对齐。这种技术存在两个主要缺点：首先，尽管该算法具有多项式时间复杂度，但对于包含许多数据记录或包含许多属性的数据记录的页面，其运行速度较慢。其次，如果中心树没有特定的数据项，那些包含相同数据项的其他数据记录将无法对齐。我们实施了这种方法，但结果很差。其他流行的多重对齐方法包括渐进对齐[17]和迭代对齐[3]。它们的工作原理类似于分级聚类，并且都需要提前进行O(k^2)的一对一匹配。对于我们的任务，我们可以做得更好，因为我们知道数据记录遵循某些预定义的模板。</p><h3>4.4、部分树对齐</h3><p>我们提出的方法通过逐步扩展种子（标签）树来对齐多个标签树。种子树记为Ts，最初选择具有最多数据字段的树作为种子树。需要注意的是，种子树类似于中心树，但不需要进行O(k^2)的一对一树匹配来选择。选择这棵种子树的原因很明确，因为这棵树更有可能与其他数据记录中的数据字段良好对齐。然后，对于每个Ti（i ≠ s），算法试图为Ti中的每个节点找到与Ts中的匹配节点。当找到节点ni的匹配时，在ni和ns之间创建一个链接，表示在种子树中的匹配。如果找不到节点ni的匹配，则算法尝试通过将ni插入到Ts中来扩展种子树。扩展后的种子树Ts随后用于后续匹配。需要注意的是，在匹配或对齐过程中不使用标签树节点中的数据项。</p><h4>4.4.1、两棵树的部分树对齐</h4><p>在介绍完对齐多个树的完整算法之前，让我们先讨论一下两个树的部分对齐的概念。如上所述，在Ts和Ti匹配之后，Ti中的一些节点可以与Ts中对应的节点对齐，因为它们互相匹配。对于那些未匹配的Ti中的节点，我们希望将它们插入到Ts中，因为它们可能包含可选的数据项。当从Ti中插入一个新节点ni到种子树Ts时，可能存在两种情况，取决于能否确定在Ts中唯一的位置来插入ni。事实上，我们不仅考虑单个节点ni，还可以一起考虑Ti中一组未匹配的连续兄弟节点nj…nm。不失一般性，我们假设nj…nm的父节点在Ts中有一个匹配，并且我们希望将nj…nm插入到Ts中的相同父节点下。只有当可以在Ts中唯一确定插入nj…nm的位置时，我们才会将它们插入到Ts中。否则，它们将不会被插入到Ts中，保持未对齐状态。因此，这种对齐是部分的。插入nj…nm的位置可以唯一确定在以下情况下：</p><ol><li>如果nj…nm在Ti中有两个相邻的兄弟节点，一个在右侧，一个在左侧，它们与Ts中的两个连续兄弟节点匹配。图12(A)展示了这样的情况，其中给出了Ts的一部分和Ti的一部分。我们可以看到Ti中的节点c和节点d（连续的兄弟节点）可以插入到Ts的节点b和节点e之间，因为Ts和Ti中的节点b和节点e是匹配的。新的（扩展的）Ts也在图12(A)中显示。需要注意的是，节点a、b、c、d和e也可能有它们自己的子节点，但我们没有绘制它们以节省空间。以下所有情况都适用于此。</li><li>如果nj…nm在Ti中只有一个左侧相邻节点x，并且x与Ts中最右侧的节点x匹配，那么nj…nm可以插入到Ts中的节点x之后。图12(B)说明了这种情况。</li><li>如果nj…nm在Ti中只有一个右侧相邻节点x，并且它与Ts中最左侧的节点x匹配，那么nj…nm可以插入到Ts中的节点x之前。这种情况与上述情况类似。</li></ol><p>否则，我们无法唯一确定Ti中未匹配节点插入Ts的位置。这在图12(C)中有所说明。在这种情况下，Ti中未匹配的节点x可以插入到Ts的两个位置之间，即节点a和节点b之间，或者节点b和节点e之间。在这种情况下，我们将不会将其插入到Ts中。</p><img width="374" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/a1b45d24-cf79-40c3-9645-074c2787798f"><h4>4.4.2、完整算法</h4><p>图13给出了基于两个标签树部分对齐的多树对齐的完整算法。</p><img width="423" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/d9799e77-c705-4eb6-ae54-2208695f8b64"><p>我们在图14中使用一个简单的示例来解释算法。我们有三个示例树，它们都只有两个层级。</p><p>第1行和第2行（图13）基本上是找到具有最多数据项的树，这就是种子树。在图14中，种子树是第一棵树（我们省略了T1左侧的许多节点）。第3行进行一些初始化操作。第4行开始while循环，对每个未对齐的树与Ts进行对齐。第5行选择下一个未对齐的树，第6行进行树的匹配。第7行通过追踪第6行的矩阵结果找到所有匹配的节点对。这个过程类似于使用编辑距离对齐两个字符串。我们不会进一步讨论这个问题。注意，第5行和第6行可以集成在一起。为了简单起见，我们将它们分开展示。在图14中，Ts和T2产生一个匹配，即节点b。节点n、c、k和g未与Ts匹配。第8行进行检查。第9行尝试将它们插入Ts，这就是上面讨论的部分树对齐。在图14中，T2中的节点n、c、k和g都无法插入Ts，因为找不到唯一的位置。第14行将T2插入R，R是可能需要进一步处理的树的列表。在图14中，当将T3与Ts进行匹配时，所有未匹配的节点c、h和k都可以插入Ts。因此，T3将不会被插入R。第14-16行设置“flag = true”以指示找到了一些新的对齐/匹配，或者插入了一些未匹配的节点到Ts中。</p><p>第17-21行检查停止条件。“S = ∅ and flag = true”表示我们已经处理了S中的所有树，并且找到了一些新的对齐或插入操作。然后应该再次处理R中的树。在图14中，R中只有T2，它将与下一轮中的新Ts进行匹配。现在T2中的每个节点都可以匹配或插入。过程完成。第23行根据生成的对齐结果输出每个树的数据项。请注意，如果算法完成后仍然存在未匹配的节点和数据，那么每个未匹配的数据将占据单独的一列。表1显示了图14中树的数据表。我们使用“1”表示一个数据项。</p><img width="403" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/be05592a-8b21-4da4-a023-69c3d8e08d44"><img width="417" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/70c17fa2-c8fc-4e01-ab78-d46a4c1bb497"><p>该算法的复杂度在不考虑树匹配的情况下为O(k^2)，其中k是树的数量。然而，在实践中，我们几乎总是只需要遍历S一次（即R = ∅）。</p><p>应注意，生成的对齐结果Ts还可以用作从使用相同模板生成的其他页面中提取数据项的提取模式。</p><h2>5、实验评估</h2><p>本节评估了我们的系统DEPTA（基于部分树对齐的数据提取），该系统实现了提出的技术。评估分为两个部分：</p><ol><li><p>数据记录提取（步骤1）：我们将DEPTA的第一步（也称为MDR-2）与我们现有的系统MDR进行比较，以确定数据记录。在这里，我们不将其与[5]和[8]中的方法进行比较，因为[21]表明MDR已经比它们更有效。</p></li><li><p>数据项/字段对齐和提取（步骤2）：这是DEPTA的第二步。[8]能够执行相同的任务。然而，正如[21]所示，它在找到正确的数据记录方面表现不佳，因此无法很好地提取数据项。我们不与[1][12]中的系统进行比较，因为它们需要多个页面，并且所有页面都包含类似的数据记录以从页面中提取模式。[20]中的技术需要页面背后的详细信息页面（待提取页面），在他们的实验中，这些详细信息页面是手动识别和下载的，这在实践中是不现实的。DEPTA更加通用。给定单个页面，它能够从中提取数据记录和数据项。</p></li></ol><p>我们的实验结果如表2所示。</p><p>第1列：列出了每个站点的URL。在某些站点上尝试了多个页面（具有不同的数据记录格式）。我们在实验中使用的站点数量为49。使用的页面总数为72。我们的实验Web页面是随机收集的。由于大多数页面的URL较长，我们无法在此列出它们。我们将在我们的网站上发布所有测试页面的URL。</p><p>第2列和第4列：它们分别给出了MDR和MDR-2（DEPTA的步骤1）从每个站点的页面中提取的正确（Cor.）记录数。这些数据记录是页面中明显的记录（例如产品列表）。它们不包括导航区域，这些区域也可能具有规律的模式。请注意，尽管MDR-2框架能够处理嵌套的数据记录（记录中的记录），但在这项工作中我们没有明确处理此类数据记录，因为在记录列表中它们相对较少。我们将在未来添加这一点。提出的部分树对齐方法能够对齐嵌套记录中的数据项。</p><p>第3列和第5列：它们分别给出了MDR和MDR-2（DEPTA的步骤1）从每个站点的页面中错误提取的数据记录数。x/y表示提取结果中有x个是不正确的，y个是未提取的。</p><p>第6列和第7列：它们分别给出了DEPTA的第2步从每个站点的数据记录中提取的正确数据项和错误数据项的数量。具有错误对齐的提取的数据项也被视为错误。</p><p>表2的最后三行给出了每列的总计，以及每个系统的召回率和精确度。对于MDR和MDR-2（DEPTA的第1步），召回率和精确度是基于在所有页面中找到的正确数据记录总数和这些页面中实际数据记录的数量计算的。对于DEPTA的数据项提取，精确度和召回率的计算考虑了因DEPTA的第1步导致的20个丢失的数据记录。</p><p>我们可以看到，数据提取非常有效。几乎所有的错误都是由于数据记录提取引起的。我们还观察到，MDR-2的性能明显优于MDR。</p><img width="255" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/56c9cd7a-a243-4acd-8cc3-19affc2b64fe"><h2>6、结论和未来工作</h2><p>在本文中，我们提出了一种从网页中提取结构化数据的新方法。尽管这个问题已经被几位研究人员研究过，但现有的技术要么不准确，要么做出了许多强假设。我们的方法不做这些假设，只需要页面包含多个数据记录，而对于包含数据记录的页面来说，这几乎总是成立的。我们的技术包括两个步骤：（1）在不提取数据记录中的每个数据字段的情况下识别数据记录，以及（2）对多个数据记录中的相应数据字段进行对齐，以从中提取数据并放入数据库表中。我们针对步骤（1）提出了一种基于视觉信息的增强方法，显著提高了我们之前算法的准确性。对于步骤（2），我们提出了一种新颖的部分树对齐技术，用于对齐多个数据记录的相应数据字段。使用大量网页的实证结果表明，这种新的两步技术能够非常准确地分割数据记录并从中提取数据。</p><h2>7、致谢</h2><p>这项工作得到了美国国家科学基金会(NSF)的支持（项目编号：IIS-0307239）。</p><h2>8、参考文献</h2><ul><li>[1]. Arasu, A. and Garcia-Molina, H. <a href="https://dl.acm.org/doi/10.1145/872757.872770">Extracting Structured Data from Web Pages</a>. SIGMOD-03, 2003.</li><li>[2]. Baeza-Yates, R. <a href="https://dl.acm.org/doi/10.1145/27656.27657">Algorithms for string matching: A survey</a>. ACM SIGIR Forum, 23(3-4):34-58, 1989.</li><li>[3]. Barton, G., Sternberg, M. <a href="https://www.sciencedirect.com/science/article/pii/0022283687901828">A strategy for the rapid multiple alignment of protein sequences: confidence levels from tertiary structure comparisons</a>. J. Mol. Biol. 1987, 327-337.</li><li>[4]. Bar-Yossef, Z. and Rajagopalan, S. <a href="https://doi.org/10.1145/564376.564421">Template Detection via Data Mining and its Applications</a>. WWW 2002, 2002.</li><li>[5]. Buttler, D., Liu, L., Pu, C. <a href="https://doi.org/10.1109/ICDCS.2001.918855">A fully automated extraction system for the World Wide Web</a>. IEEE ICDCS-21, 2001.</li><li>[6]. Carrillo, H., Lipman, D. <a href="https://doi.org/10.1137/0148037">The multiple sequence alignment problem in biology</a>. SIAM J. Applied Math., 1988;48(5).</li><li>[7]. Chakrabarti, S. <a href="https://dl.acm.org/doi/book/10.5555/579551">Mining the Web: Discovering Knowledge from Hypertext Data</a>. Morgan Kaufmann Publishers, 2002.</li><li>[8]. Chang, C. and Lui, S-L. <a href="https://dl.acm.org/doi/10.1145/371920.372174">IEPAD: Information extraction based on pattern discovery</a>. WWW-10, 2001.</li><li>[9]. Chen, H.-H., Tsai, S.-C., and Tsai, J.-H. <a href="https://www.aclweb.org/anthology/C00-1060/">Mining tables from large scale html texts</a>. COLING-00, 2000.</li><li>[10]. Chen, W. <a href="https://doi.org/10.1006/jagm.2001.1188">New algorithm for ordered tree-to-tree correction problem</a>. Journal of Algorithms, 40:135–158, 2001.</li><li>[11]. Cohen, W., Hurst, M., and Jensen, L. <a href="https://doi.org/10.1145/511446.511491">A flexible learning system for wrapping tables and lists in HTML documents</a>. WWW-2002, 2002.</li><li>[12]. Crescenzi, V., Mecca, G. and Merialdo, P. <a href="https://dl.acm.org/doi/10.5555/588291.588305">Roadrunner: Towards automatic data extraction from large web sites</a>. VLDB-01, 2001.</li><li>[13]. Doorenbos, R., Etzioni, O., Weld, D. <a href="https://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.5.8055">A scalable comparison shopping agent for the World Wide Web</a>. Agents-97, 1997.</li><li>[14]. Embley, D., Jiang, Y and Ng, Y. <a href="https://doi.org/10.1145/304181.304196">Record-boundary discovery in Web documents</a>. SIGMOD-99, 1999.</li><li>[15]. Gusfield, D. <a href="https://books.google.com/books/about/Algorithms_on_Strings_Trees_and_Sequence.html?id=D_0dAwAAQBAJ">Algorithms on strings, trees, and sequences</a>. Cambridge, 1997.</li><li>[16]. Hammer, J., Garcia-Molina, H., Cho, J., Aranha, R., and Crespo, A. <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.35.8254">Extracting semi-structured information from the Web</a>. Workshop on Manag. of Semi-structured Data, 1997.</li><li>[17]. Hogeweg, P., Hesper, B. <a href="https://doi.org/10.1007/BF02193497">The alignment of sets of sequences and the construction of phylogenetic trees: An integrated method</a>. J. Mol. Evol., 20, 175-186 (1984).</li><li>[18]. Hsu, C.-N. and Dung, M.-T. <a href="https://doi.org/10.1016/S0306-4379(98)80014-8">Generating finite-state transducers for semi-structured data extraction from the Web</a>. Information Systems. 23(8): 521-538, 1998.</li><li>[19]. Kushmerick, N. <a href="https://doi.org/10.1016/S0004-3702(99)00062-3">Wrapper induction: efficiency and expressiveness</a>. Artificial Intelligence, 118:15-68, 2000.</li><li>[20]. Lerman, K., Getoor L., Minton, S. and Knoblock, C. <a href="https://dl.acm.org/doi/10.1145/1007568.1007650">Using the Structure of Web Sites for Automatic Segmentation of Tables</a>. SIGMOD-04, 2004.</li><li>[21]. Liu, B., Grossman, R. and Zhai, Y. <a href="https://doi.org/10.1145/956863.956944">Mining data records from Web pages</a>. KDD-03, 2003.</li><li>[22]. Meng, X., Lu, H., Wang, H., and Gu, M. <a href="https://doi.org/10.1109/ICDE.2002.994735">Schema-Guided Wrapper Generator</a>. ICDE-02, 2002.</li><li>[23]. Muslea, I., Minton, S. and Knoblock, C. <a href="https://www.aaai.org/Library/Agents/1999/agents99-019.php">A hierarchical approach to wrapper induction</a>. Agents-99, 1999.</li><li>[24]. Notredame, C. <a href="https://doi.org/10.2172/768377">Recent progresses in multiple sequence alignment: a survey</a>. Technical Report, 2002.</li><li>[25]. Pinto, D., McCallum, A., Wei, X. and Bruce, W. <a href="https://dl.acm.org/doi/10.1145/860435.860480">Table Extraction Using Conditional Random Fields</a>. SIGIR-03.</li><li>[26]. Ramaswamy, L., Ivengar, A., Liu, L., and Douglis, F. <a href="https://doi.org/10.1145/1013367.1013401">Automatic detection of fragments in dynamically generated Web pages</a>. WWW-04, 2004.</li><li>[27]. Reis, D. Golgher, P., Silva, A., Laender, A. <a href="https://doi.org/10.1145/988672.988735">Automatic Web news extraction using tree edit distance</a>, WWW-04, 2004.</li><li>[28]. Rosenfeld, B., Feldman, R., Aumann, Y. <a href="https://doi.org/10.1145/584792.584886">Structural extraction from visual layout of documents</a>. CIKM-02, 2002.</li><li>[29]. Song, R., Liu, H., Wen, J.-R., Ma, W.-Y. <a href="https://doi.org/10.1145/988672.988760">Learning block importance models for Web pages</a>. WWW-04, 2004.</li><li>[30]. Tai, K. <a href="https://doi.org/10.1145/322062.322067">The tree-to-tree correction problem</a>. J. ACM, 26(3):422–433, 1979.</li><li>[31]. Valiente, G. <a href="https://www.lsi.upc.edu/~valiente/docs/Valiente04.pdf">Tree edit distance and common subtrees</a>. Research Report LSI-02-20-R, Universitat Politecnica de Catalunya, Barcelona, Spain, 2002.</li><li>[32]. Wang, J., Shapiro, J., Shasha, D., Zhang, K., Currey, K. <a href="https://doi.org/10.1109/TPAMI.1998.712560">An algorithm for finding the largest approximately common substructures of two trees</a>. IEEE PAMI, 20(8), 1998.</li><li>[33]. Wang, Y., Hu, J. <a href="https://doi.org/10.1145/511446.511503">A machine learning based approach for table detection on the Web</a>. WWW-2002.</li><li>[34]. Wang, J.-Y., and Lochovsky, F. <a href="https://doi.org/10.1145/775047.775058">Data extraction and label assignment for Web databases</a>. WWW-03, 2003.</li><li>[35]. Yang, W. <a href="https://doi.org/10.1002/spe.4380210702">Identifying syntactic differences between two programs</a>. Softw. Pract. Exper., 21(7):739–755, 1991.</li><li>[36]. Zhang, K., Statman, R., Shasha, D. <a href="https://doi.org/10.1016/0020-0190(92)90130-T">On the editing distance between unordered labeled trees</a>. Information Processing Letters, 42(3):133–139, 1992.</li></ul>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;Web Data Extraction Based on Partial Tree Alignment ———— 论文翻译&lt;/p&gt;
&lt;h2&gt;摘要&lt;/h2&gt;</summary>
    
    
    
    <category term="算法" scheme="https://blog.hufeifei.cn/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="算法" scheme="https://blog.hufeifei.cn/tags/%E7%AE%97%E6%B3%95/"/>
    
    <category term="Web挖掘" scheme="https://blog.hufeifei.cn/tags/Web%E6%8C%96%E6%8E%98/"/>
    
  </entry>
  
  <entry>
    <title>时序数据库和传统关系型数据库</title>
    <link href="https://blog.hufeifei.cn/2022/08/DB/time-series&amp;rdbms/"/>
    <id>https://blog.hufeifei.cn/2022/08/DB/time-series&amp;rdbms/</id>
    <published>2022-08-03T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.691Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>时序数据特点：</p><p>1、写多读少：持续高并发的写入，由于定期采样的特点，写入量平稳，几乎不会有更新操作。</p><p>2、冷热明显：查询一般查近期产生的数据，很少查过期数据。</p><p>3、数据关联性小：数据之间几乎不存在关系，不需要Join。</p><p>4、查询场景不同，索引特殊：数据都包含设备信息(服务器、传感器)和时间戳，大部分都是聚合查询。</p><p>应用场景：IOT传感器数据、服务器监控数据、金融交易数据</p><p>绝大多数关系型数据库的特点：</p><p>1、读多写少：大部分RDBMS都是基于B+树实现的，B+树主要通过增加节点大小降低树的层级从而减小IO，索引更多数据，从而优化读取性能。</p><p>2、随机读写：B+树读写会直达叶子节点，读写性能稳定，少部分热数据直接通过LRU进行缓存。</p><p>3、表间关系紧密：关系型数据库的特点就是关联关系，通过范式来避免数据冗余，查询数据库时通过Nested Loop Join，Hash Join，Sort Merge Join等算法进行关联。</p><p>4、按查询场景建立二级索引：为了提升查询性能，会对查询字段额外创建另一个B+树索引，也就是所谓的“二级索引”，这也导致写操作需要同时更新这些索引。</p><p>应用场景：一致性较强的应用数据</p><h2>B+树的优缺点</h2><img width="725" alt="image" src="https://github.com/holmofy/blog.hufeifei.cn/assets/19494806/ac8a8c9d-c49c-4629-973f-38d666513bec"><p><strong>优点</strong>：</p><p>1、随机读写：根据B+树索引查询，能对磁盘中的数据实现快速读写。按照InnoDB的16KB块大小计算，对8字节的ID值进行索引，包括物理指针在内，一个节点可以存储1000左右的数据。这样算内两层数据只有1M左右，可以缓存在内存中，第三层可以索引1G左右的数据，所以三层B+树基本只要一次I/O操作。</p><p>2、范围查询：B+树叶子节点通过双向链表连起来了，可以直接顺着叶子节点的链表进行范围扫描，避免了B树回溯节点的问题。</p><p>3、查询稳定：数据都存在叶子节点，内部节点只存key，一方面可以让内部节点索引更多的数据，降低树的层级，另一方面能让查询都沉到叶子节点，性能相对稳定，不会像B树那样，有的查询读到第二层，有的查询读到第三层。</p><p>4、WAL保证写操作的持久性：将修改先写入预写日志(Write-Ahead Log)，如果修改的脏页因为宕机等原因没有落盘，可以通过WAL进行恢复。</p><p><strong>缺点</strong>：</p><p>1、页分裂，写性能不稳定：写操作可能导致页面数据已满，触发页分裂，页分裂会产生多次磁盘I/O，导致写放大。</p><p>2、大数据量I/O性能下降：数据量过大，会导致层级过深，I/O次数上升，性能下降。通常的策略是分库分表，但是分库分表需要根据系统业务选择列进行路由，通用性不强。</p><h2>LSM存储结构</h2><p><img src="https://pic3.zhimg.com/80/v2-73601ec793dc41efe55574da2ea73d2a_720w.jpg"></p><p><strong>L</strong>og-<strong>S</strong>tructure <strong>M</strong>ergeTree将写操作写入内存树，当达到一定阈值再Flush进磁盘，磁盘中的小树会逐级合并大树。</p><p><strong>优点</strong>：</p><p>1、写性能吞吐量极高：随机写合并成大批量的顺序写。支持高吞吐的写，写入性能能得到大幅度提升。</p><p>2、没有B+树的页分裂，修改操作会直接追加到<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex" xmlns="http://www.w3.org/2000/svg" width="2.605ex" height="1.97ex" role="img" focusable="false" viewBox="0 -705 1151.6 870.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mn" transform="translate(748,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container>树中，查询会从<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex" xmlns="http://www.w3.org/2000/svg" width="2.605ex" height="1.97ex" role="img" focusable="false" viewBox="0 -705 1151.6 870.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mn" transform="translate(748,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container>树到…<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="2.765ex" height="1.952ex" role="img" focusable="false" viewBox="0 -705 1222.3 862.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mi" transform="translate(748,-150) scale(0.707)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>树；删除操作，会以墓碑标记的方式追加到<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex" xmlns="http://www.w3.org/2000/svg" width="2.605ex" height="1.97ex" role="img" focusable="false" viewBox="0 -705 1151.6 870.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mn" transform="translate(748,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container>树。</p><p><strong>缺点</strong>：</p><p>1、读放大：读取操作需要，从<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.375ex" xmlns="http://www.w3.org/2000/svg" width="2.605ex" height="1.97ex" role="img" focusable="false" viewBox="0 -705 1151.6 870.6"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mn" transform="translate(748,-150) scale(0.707)"><path data-c="30" d="M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z"></path></g></g></g></g></svg></mjx-container>依次检查读到<mjx-container class="MathJax" jax="SVG"><svg style="vertical-align: -0.357ex" xmlns="http://www.w3.org/2000/svg" width="2.765ex" height="1.952ex" role="img" focusable="false" viewBox="0 -705 1222.3 862.8"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="msub"><g data-mml-node="mi"><path data-c="1D436" d="M50 252Q50 367 117 473T286 641T490 704Q580 704 633 653Q642 643 648 636T656 626L657 623Q660 623 684 649Q691 655 699 663T715 679T725 690L740 705H746Q760 705 760 698Q760 694 728 561Q692 422 692 421Q690 416 687 415T669 413H653Q647 419 647 422Q647 423 648 429T650 449T651 481Q651 552 619 605T510 659Q484 659 454 652T382 628T299 572T226 479Q194 422 175 346T156 222Q156 108 232 58Q280 24 350 24Q441 24 512 92T606 240Q610 253 612 255T628 257Q648 257 648 248Q648 243 647 239Q618 132 523 55T319 -22Q206 -22 128 53T50 252Z"></path></g><g data-mml-node="mi" transform="translate(748,-150) scale(0.707)"><path data-c="1D45B" d="M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z"></path></g></g></g></g></svg></mjx-container>，特别是当数据不存在的时候，需要扫描所有的树，I/O读取操作增多，性能也不稳定。</p><p>2、写放大：对数据的修改和删除，需要延迟到Compact阶段进行后台合并，写操作次数实际上增多了。</p><p>3、空间放大：LSM-Tree的深层树中可能存在未合并的垃圾数据，会占用更多空间。</p><p><strong>优化</strong>：</p><p>1、读优化：可以在内存中使用BloomFilter对树中的数据进行预判，如果不存在就不需要进行读操作了。</p><p>2、写优化和空间优化：优化Compact算法，尽量减少写操作。</p><h2>使用LSM-Tree实现时序数据库</h2><p>LSM-Tree非常适合存储时序数据。</p><p>1、首先LSM-Tree的写性能满足了时序数据持续性高并发的写入和读多写少的场景。</p><p>2、时序数据基本不会修改和删除，所以避免了不必要的Compact操作，也就没有空间放大的问题，写放大也能避免。</p><p>3、老数据会随着层级的层架，进入更深层，契合了是冷热数据查询的场景。</p>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;时序数据特点：&lt;/p&gt;
&lt;p&gt;1、写多读少：持续高并发的写入，由于定期采样的特点，写入量平稳，几乎不会有更新操作。&lt;/p&gt;</summary>
    
    
    
    <category term="数据库" scheme="https://blog.hufeifei.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="DB" scheme="https://blog.hufeifei.cn/tags/DB/"/>
    
    <category term="B-Tree" scheme="https://blog.hufeifei.cn/tags/B-Tree/"/>
    
    <category term="LSM-Tree" scheme="https://blog.hufeifei.cn/tags/LSM-Tree/"/>
    
    <category term="DataStructure" scheme="https://blog.hufeifei.cn/tags/DataStructure/"/>
    
  </entry>
  
  <entry>
    <title>解决Docker镜像爆满的问题</title>
    <link href="https://blog.hufeifei.cn/2022/02/Linux/docker-images/"/>
    <id>https://blog.hufeifei.cn/2022/02/Linux/docker-images/</id>
    <published>2022-02-12T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.699Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2>现象</h2><p>使用过docker的人都知道，在正常情况下。我们使用multi-stage构建利用docker镜像缓存机制，可以加快构建速度。</p><p>但是缓存的镜像一多，没有及时释放磁盘空间，磁盘就容易爆满。</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@report ~]# df -h</span><br><span class="line">文件系统        容量  已用  可用 已用% 挂载点</span><br><span class="line">devtmpfs        909M     0  909M    0% /dev</span><br><span class="line">tmpfs           919M   24K  919M    1% /dev/shm</span><br><span class="line">tmpfs           919M  752K  919M    1% /run</span><br><span class="line">tmpfs           919M     0  919M    0% /sys/fs/cgroup</span><br><span class="line">/dev/vda1        50G  9.6G   38G   21% /</span><br><span class="line">tmpfs           184M     0  184M    0% /run/user/0</span><br><span class="line"><span class="addition">+overlay          50G  9.6G   38G   21% /var/lib/docker/overlay2/eefc0488163e0d222c384c54041549023a998e3fefeea1c672f0cb9b0f1e78a1/merged</span></span><br><span class="line">shm              64M     0   64M    0% /var/lib/docker/containers/ceb6efe9a7cd0563af63ee0b37fb7d7d4f387a46691e7d1d6109876a22fc8b6d/mounts/shm</span><br><span class="line"><span class="addition">+overlay          50G  9.6G   38G   21% /var/lib/docker/overlay2/038df81678b0660a7f3e9eaade223fdd541beff0799bed64437eabe525c4088d/merged</span></span><br><span class="line"><span class="addition">+overlay          50G  9.6G   38G   21% /var/lib/docker/overlay2/1bd852511b0179c8cc31b9e5a3b6ccf66da6d990a98a1b5ca7874e556f1e384e/merged</span></span><br><span class="line">shm              64M     0   64M    0% /var/lib/docker/containers/83e5b18fe998f7ed3ceb4b6328ee427748cd8fd8f1de313222286e3bc125bb15/mounts/shm</span><br><span class="line">[root@report ~]# docker system df</span><br><span class="line">TYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLE</span><br><span class="line">Images          12        8         3.453GB   903.7MB (26%)</span><br><span class="line">Containers      9         3         120.3MB   13.79MB (11%)</span><br><span class="line">Local Volumes   1         1         292.6MB   0B (0%)</span><br><span class="line">Build Cache     0         0         0B        0B</span><br></pre></td></tr></table></figure><p>如果每次构建完手动<code>docker rmi</code>又达不到加快构建速度的效果。</p><p>尤其是在持续集成环境中，大家公用一个build machine的时候。大家各自打扫门前雪，更加不会有人care磁盘会不会被占满。 </p><h2>方法</h2><p>为了一劳永逸的解决这个问题，最好的办法莫过于通过定时任务来清理旧的image。 这个方法听起来高大上，用起来简单的很。 运行crontab -e命令编辑定时任务。 </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">crontab -e</span><br></pre></td></tr></table></figure><p>在打开的文本编辑器最后添加如下一行，然后保存退出。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0 1 * * * docker image prune -a --force --filter <span class="string">&quot;until=48h&quot;</span></span><br></pre></td></tr></table></figure><p>然后执行下面的命令使定时任务生效。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart crond.service</span><br></pre></td></tr></table></figure><p>其实，到这里，整个配置就结束了。接下来我们简单解释一下。<br>上面的定时任务是每天夜里1点钟删除2天（48h）之前的image。<br>具体的操作时间，具体的image保留时间，可以根据自己的情况修改。</p>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2&gt;现象&lt;/h2&gt;&lt;p&gt;使用过docker的人都知道，在正常情况下。我们使用multi-stage构建利用docker镜像缓存机制，可以加快构建速度。&lt;/p&gt;</summary>
    
    
    
    <category term="Linux运维" scheme="https://blog.hufeifei.cn/categories/Linux%E8%BF%90%E7%BB%B4/"/>
    
    
    <category term="Linux" scheme="https://blog.hufeifei.cn/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>在nginx中安装并调试OpenResty</title>
    <link href="https://blog.hufeifei.cn/2021/10/C-C++/nginx-open-resty/"/>
    <id>https://blog.hufeifei.cn/2021/10/C-C++/nginx-open-resty/</id>
    <published>2021-10-31T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.687Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2>安装OpenResty相关模块</h2><p>OpenResty是基于Lua即时编译器(<a href="https://github.com/LuaJIT/LuaJIT">LuaJIT</a>)对Nginx进行扩展的模块——最核心的就是<a href="https://github.com/openresty/lua-nginx-module"><code>lua-nginx-module</code></a>这个模块。其他的都是<a href="https://github.com/bungle/awesome-resty">OpenResty基于lua开发的相关模块</a>，当然也可以基于lua开发自己的第三方模块。</p><p>所以要想使用OpenResty首先必须安装<code>lua-nginx-module</code>。</p><ol><li><p>下载并安装LuaJIT。可以使用源码方式安装，这个可以参考<a href="https://luajit.org/install.html">官方文档</a>非常详细。这里为了方便直接用apt安装了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install luajit libluajit-5.1-dev</span><br></pre></td></tr></table></figure></li><li><p>下载<code>ngx_devel_kit</code>模块</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在nginx目录下创建一个modules目录</span></span><br><span class="line"><span class="built_in">mkdir</span> modules</span><br><span class="line"><span class="comment"># 从github克隆模块代码</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/vision5/ngx_devel_kit/ modules/ngx_devel_kit</span><br><span class="line"><span class="comment"># 切换到v0.3.1版本</span></span><br><span class="line">git checkout tags/v0.3.1 -b v0.3.1</span><br></pre></td></tr></table></figure></li><li><p>下载<code>lua-nginx-module</code>模块</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/openresty/lua-nginx-module modules/ngx_http_lua_module</span><br><span class="line">git checkout tags/v0.10.20 -b v0.10.20</span><br></pre></td></tr></table></figure><p>如果是使用alibaba/tengine，这个模块已经被包含在tengine的<code>modules/ngx_http_lua_module</code>目录下了。</p><blockquote><p>另外注意<a href="https://github.com/openresty/lua-nginx-module#nginx-compatibility">lua-nginx-module与nginx的兼容性</a>，nginx1.6.0之前的版本是不支持的。</p></blockquote></li></ol><h2>编译nginx源码</h2><ol start="0"><li><p>如果需要对nginx进行debug的话，需要修改 /auto/cc/conf 文件，将<code>ngx_compile_opt=&quot;-c&quot;</code>修改为 <code>ngx_compile_opt=&quot;-c -g&quot;</code></p><blockquote><p><code>-g</code>用来生成调试信息：详见<a href="https://gcc.gnu.org/onlinedocs/gcc/Debugging-Options.html">gcc文档</a></p></blockquote></li><li><p>设置luajit的头文件和静态库的路径，ubuntu下可以用dpkg看看libluajit被安装到哪个目录了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">$ dpkg -L libluajit-5.1-dev</span><br><span class="line">/.</span><br><span class="line">/usr</span><br><span class="line">/usr/include</span><br><span class="line">/usr/include/luajit-2.1</span><br><span class="line">/usr/include/luajit-2.1/lauxlib.h</span><br><span class="line">/usr/include/luajit-2.1/lua.h</span><br><span class="line">/usr/include/luajit-2.1/lua.hpp</span><br><span class="line">/usr/include/luajit-2.1/luaconf.h</span><br><span class="line">/usr/include/luajit-2.1/luajit.h</span><br><span class="line">/usr/include/luajit-2.1/lualib.h</span><br><span class="line">/usr/lib</span><br><span class="line">/usr/lib/x86_64-linux-gnu</span><br><span class="line">/usr/lib/x86_64-linux-gnu/libluajit-5.1.a</span><br><span class="line">/usr/lib/x86_64-linux-gnu/pkgconfig</span><br><span class="line">/usr/lib/x86_64-linux-gnu/pkgconfig/luajit.pc</span><br><span class="line">/usr/share</span><br><span class="line">/usr/share/doc</span><br><span class="line">/usr/share/doc/libluajit-5.1-dev</span><br><span class="line">/usr/share/doc/libluajit-5.1-dev/copyright</span><br><span class="line">/usr/lib/x86_64-linux-gnu/libluajit-5.1.so</span><br><span class="line">/usr/share/doc/libluajit-5.1-dev/changelog.Debian.gz</span><br></pre></td></tr></table></figure><p>然后设置两个环境变量</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> LUAJIT_LIB=/usr/lib/x86_64-linux-gnu/</span><br><span class="line"><span class="built_in">export</span> LUAJIT_INC=/usr/include/luajit-2.1/</span><br></pre></td></tr></table></figure></li><li><p>执行<code>auto/configure</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">auto/configure --prefix=nginx \</span><br><span class="line">         --with-ld-opt=<span class="string">&quot;-Wl,-rpath,/usr/lib/x86_64-linux-gnu/&quot;</span> \</span><br><span class="line">         --add-module=./modules/ngx_devel_kit \</span><br><span class="line">         --add-module=./modules/ngx_http_lua_module</span><br></pre></td></tr></table></figure></li><li><p>执行<code>make install</code></p><blockquote><p>编译过程可能会比较慢，可以执行<code>make -j2 &amp;&amp; make install</code>调大编译任务的个数</p></blockquote></li></ol><h2>调试OpenResty中的lua代码</h2><p>这里以一个第三方的lua模板引擎为例——<a href="https://github.com/bungle/lua-resty-template">lua-resty-template</a></p><h3>安装lua模块</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 在nginx下创建一个放lua脚本的目录</span></span><br><span class="line"><span class="built_in">mkdir</span> lua-lib</span><br><span class="line"><span class="comment"># 下载lua-resty-template模块</span></span><br><span class="line">git <span class="built_in">clone</span> https://github.com/bungle/lua-resty-template lua-lib/lua-resty-template</span><br></pre></td></tr></table></figure><p>在<code>nginx.conf</code>中对lua模块进行配置</p><figure class="highlight nginx"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="section">http</span> &#123;</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    <span class="comment"># 设置lua模块的路径</span></span><br><span class="line">    <span class="attribute">lua_package_path</span> <span class="string">&quot;lua-lib/lua-resty-template/lib/?.lua;;&quot;</span>;</span><br><span class="line">    </span><br><span class="line">    <span class="section">server</span> &#123;</span><br><span class="line">        <span class="attribute">listen</span>       <span class="number">80</span>;</span><br><span class="line">        <span class="attribute">server_name</span>  localhost;</span><br><span class="line">        </span><br><span class="line">        <span class="attribute">set</span> <span class="variable">$template_root</span> html/templates;</span><br><span class="line">        <span class="section">location</span> /templates/ &#123;</span><br><span class="line">          <span class="attribute">root</span> html;</span><br><span class="line">          <span class="attribute">content_by_lua</span> <span class="string">&#x27;</span></span><br><span class="line"><span class="string">            local template = require &quot;resty.template&quot;</span></span><br><span class="line"><span class="string">            template.render(&quot;view.html&quot;, &#123; message = &quot;Hello, World!&quot; &#125;)</span></span><br><span class="line"><span class="string">          &#x27;</span>;      </span><br><span class="line">    &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在<code>html/templates</code>目录下添加模板文件</p><figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&lt;!DOCTYPE <span class="keyword">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">h1</span>&gt;</span>&#123;&#123;message&#125;&#125;<span class="tag">&lt;/<span class="name">h1</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure><p>访问<code>localhost/templates/view.html</code>，能看到下面的结果</p><p><img src="https://s.pc.qq.com/tousu/img/20211101/1341156_1635761461.jpg" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="lua template"></p><blockquote><p>Read More:</p><p><a href="https://github.com/lua/lua">https://github.com/lua/lua</a></p><p><a href="https://www.lua.org/pil/23.html">https://www.lua.org/pil/23.html</a></p><p><a href="http://lua-users.org/wiki/DebuggingLuaCode">http://lua-users.org/wiki/DebuggingLuaCode</a></p><p><a href="http://notebook.kulchenko.com/zerobrane/debugging-openresty-nginx-lua-scripts-with-zerobrane-studio">http://notebook.kulchenko.com/zerobrane/debugging-openresty-nginx-lua-scripts-with-zerobrane-studio</a></p><p><a href="https://github.com/LewisJEllis/awesome-lua">https://github.com/LewisJEllis/awesome-lua</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2&gt;安装OpenResty相关模块&lt;/h2&gt;&lt;p&gt;OpenResty是基于Lua即时编译器(&lt;a href=&quot;https://github.com/LuaJIT/LuaJIT&quot;&gt;LuaJIT&lt;/a&gt;)对Nginx进行扩展的模块——最核心的就是&lt;a href=&quot;https://github.com/openresty/lua-nginx-module&quot;&gt;&lt;code&gt;lua-nginx-module&lt;/code&gt;&lt;/a&gt;这个模块。其他的都是&lt;a href=&quot;https://github.com/bungle/awesome-resty&quot;&gt;OpenResty基于lua开发的相关模块&lt;/a&gt;，当然也可以基于lua开发自己的第三方模块。&lt;/p&gt;</summary>
    
    
    
    <category term="C&amp;C++" scheme="https://blog.hufeifei.cn/categories/C-C/"/>
    
    
    <category term="C" scheme="https://blog.hufeifei.cn/tags/C/"/>
    
    <category term="Nginx" scheme="https://blog.hufeifei.cn/tags/Nginx/"/>
    
    <category term="VSCode" scheme="https://blog.hufeifei.cn/tags/VSCode/"/>
    
    <category term="OpenResty" scheme="https://blog.hufeifei.cn/tags/OpenResty/"/>
    
  </entry>
  
  <entry>
    <title>在vscode中调试nginx源码</title>
    <link href="https://blog.hufeifei.cn/2021/10/C-C++/vscode-debug-nginx/"/>
    <id>https://blog.hufeifei.cn/2021/10/C-C++/vscode-debug-nginx/</id>
    <published>2021-10-31T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.687Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p><img src="http://www.aosabook.org/images/nginx/architecture.png" alt="NGINX architecture"></p><p>vscode调试nginx源码</p><h2>clone源码</h2><figure class="codeblock codeblock--tabbed"><figcaption><ul class="tabs"><li class="tab active">bash</li></ul></figcaption><div class="tabs-content"><figure class="highlight bash" style="display: block;"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/nginx/nginx</span><br></pre></td></tr></tbody></table></figure></div></figure><p>除了官方的nginx，也可以考虑用阿里的<a href="https://github.com/alibaba/tengine">Tengine</a>或<a href="https://github.com/openresty/ngx_openresty">OpenResty</a>。</p><p>这两个发行版添加了各自的<a href="https://github.com/agile6v/awesome-nginx#third-party-modules">三方module</a>。</p><h2>编译运行</h2><ol><li><p>修改 /auto/cc/conf 文件，将ngx_compile_opt=”-c” 修改为 ngx_compile_opt=”-c -g”</p><blockquote><p><code>-g</code>用来生成调试信息：详见<a href="https://gcc.gnu.org/onlinedocs/gcc/Debugging-Options.html">gcc文档</a></p></blockquote></li><li><p>执行 sudo ./auto/configure –prefix=nginx工程目录 ，如果遇到错误 “the HTTP rewrite module requires the PCRE library”，说明少了用来匹配正则表达式的<code>pcre</code>依赖包，可以自行根据平台进行安装</p><figure class="codeblock codeblock--tabbed"><figcaption><ul class="tabs"><li class="tab active">Debein</li><li class="tab">MacOS</li><li class="tab">CentOS</li></ul></figcaption><div class="tabs-content"><figure class="highlight bash Debein" style="display: block;"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt install pcre2-utils</span><br></pre></td></tr></tbody></table></figure><figure class="highlight bash MacOS" style="display: none;"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">brew install pcre</span><br></pre></td></tr></tbody></table></figure><figure class="highlight bash CentOS" style="display: none;"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">yum install pcre</span><br></pre></td></tr></tbody></table></figure></div></figure></li><li><p>执行 sudo make</p></li><li><p>执行 ./objs/nginx，打开浏览器访问下 127.0.0.1，没问题的话就可以看到Nginx的欢迎界面了。</p><p><img src="https://s.pc.qq.com/tousu/img/20211101/7899594_1635743831.jpg" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="nginx"></p></li></ol><blockquote><p>具体源码编译内容可以参考<a href="https://docs.nginx.com/nginx/admin-guide/installing-nginx/installing-nginx-open-source/#compiling-and-installing-from-source">nginx文档</a></p></blockquote><h2>Nginx的多进程架构</h2><p>nginx是多进程架构：一个Master进程，若干个Worker进程。</p><p>Master进程负责管理 Worker 进程，处理nginx命令行指令</p><p>Worker进程负责接收处理客户端请求</p><p><img src="https://p1-jj.byteimg.com/tos-cn-i-t2oaga2asx/gold-user-assets/2020/2/19/1705d5bae51f9935~tplv-t2oaga2asx-watermark.awebp"></p><p>Worker进程数通常设置成CPU核数，<a href="https://nginx.org/en/docs/ngx_core_module.html#worker_processes"><code>worker_processes: auto;</code></a>可以自动检查CPU设置成核心数。</p><p>Worker进程和redis类似使用单线程+IO多路复用实现高并发处理IO请求。</p><p><img src="http://www.aosabook.org/images/nginx/architecture.png" alt="NGINX architecture"></p><h2>Master进程调试</h2><ol><li><p>修改<code>/conf/nginx.conf</code></p><figure class="codeblock codeblock--tabbed"><figcaption><ul class="tabs"><li class="tab active">nginx</li></ul></figcaption><div class="tabs-content"><figure class="highlight nginx" style="display: block;"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭Master守护进程的功能</span></span><br><span class="line"><span class="attribute">daemon</span> <span class="literal">off</span>;</span><br><span class="line"><span class="comment"># 便于调试只启动一个Worker进程</span></span><br><span class="line"><span class="attribute">worker_processes</span>  <span class="number">1</span>;</span><br></pre></td></tr></tbody></table></figure></div></figure><p>daemon默认都是<code>on</code>，<a href="http://nginx.org/en/docs/ngx_core_module.html#daemon">开发阶段关闭</a></p></li><li><p>添加VSCODE调试配置</p><figure class="codeblock codeblock--tabbed"><figcaption><ul class="tabs"><li class="tab active">JSON</li></ul></figcaption><div class="tabs-content"><figure class="highlight json JSON" style="display: block;"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"version"</span><span class="punctuation">:</span> <span class="string">"0.2.0"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"configurations"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">{</span></span><br><span class="line">      <span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"(gdb) Launch"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"type"</span><span class="punctuation">:</span> <span class="string">"cppdbg"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"request"</span><span class="punctuation">:</span> <span class="string">"launch"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"program"</span><span class="punctuation">:</span> <span class="string">"${workspaceFolder}/objs/nginx"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"args"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">"-c"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">"${workspaceFolder}/conf/nginx.conf"</span></span><br><span class="line">      <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"stopAtEntry"</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"cwd"</span><span class="punctuation">:</span> <span class="string">"${workspaceFolder}"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"environment"</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"MIMode"</span><span class="punctuation">:</span> <span class="string">"gdb"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"miDebuggerPath"</span><span class="punctuation">:</span> <span class="string">"/usr/bin/gdb"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"setupCommands"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">{</span></span><br><span class="line">          <span class="attr">"description"</span><span class="punctuation">:</span> <span class="string">"Enable pretty-printing for gdb"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"text"</span><span class="punctuation">:</span> <span class="string">"-enable-pretty-printing"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"ignoreFailures"</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">        <span class="punctuation">}</span></span><br><span class="line">      <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">}</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></tbody></table></figure></div></figure><p>如果是MacOS，不愿意装<code>gdb</code>，也可以用llvm的<code>lldb</code>进行调试。具体配置可以参考<a href="https://code.visualstudio.com/docs/cpp/launch-json-reference#_customizing-gdb-or-lldb">vscode文档</a></p></li><li><p>打断点，Debug起来</p><p><img src="https://s.pc.qq.com/tousu/img/20211101/1323853_1635750161.jpg" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="nginx debug"></p></li></ol><h2>调试Worker进程</h2><ol><li><p>查看 Worker 进程pid</p><figure class="codeblock codeblock--tabbed"><figcaption><ul class="tabs"><li class="tab active">bash</li></ul></figcaption><div class="tabs-content"><figure class="highlight bash" style="display: block;"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ps aux | grep nginx</span><br></pre></td></tr></tbody></table></figure></div></figure><p><img src="https://s.pc.qq.com/tousu/img/20211101/5578379_1635750721.jpg" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="nginx worker process"></p></li><li><p>编辑<code>launch.json</code>，Attach到worker进程</p><figure class="codeblock codeblock--tabbed"><figcaption><ul class="tabs"><li class="tab active">json</li></ul></figcaption><div class="tabs-content"><figure class="highlight json" style="display: block;"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"version"</span><span class="punctuation">:</span> <span class="string">"0.2.0"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"configurations"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line"><span class="comment">/* ... */</span></span><br><span class="line">    <span class="punctuation">{</span></span><br><span class="line">      <span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"(gdb) Attach Worker"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"type"</span><span class="punctuation">:</span> <span class="string">"cppdbg"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"request"</span><span class="punctuation">:</span> <span class="string">"attach"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"program"</span><span class="punctuation">:</span> <span class="string">"${workspaceFolder}/objs/nginx"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"MIMode"</span><span class="punctuation">:</span> <span class="string">"gdb"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"miDebuggerPath"</span><span class="punctuation">:</span> <span class="string">"/usr/bin/gdb"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"processId"</span><span class="punctuation">:</span> <span class="string">"9133"</span></span><br><span class="line">    <span class="punctuation">}</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></tbody></table></figure></div></figure><p>这里的进程id填进去就行了</p></li><li><p>切换到<code>Attach Worker</code></p><p><img src="https://s.pc.qq.com/tousu/img/20211101/1899231_1635751242.jpg" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="Attach Worker"></p></li><li><p>接受请求的地方打个断点，浏览器重新刷新一下，请求就进来了</p><p><img src="https://s.pc.qq.com/tousu/img/20211101/5407806_1635751394.jpg" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="Debug Worker Process"></p></li><li><p>从函数堆栈中，可以看到请求的处理过程</p><p><img src="https://s.pc.qq.com/tousu/img/20211101/6907176_1635751804.jpg" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="process request"></p></li></ol><h2>关闭Nginx多进程模式</h2><p>启动两个进程的方式debug确实挺麻烦的，nginx提供了<a href="http://nginx.org/en/docs/ngx_core_module.html#master_process">配置关闭多进程架构</a>，这样就可以在一个进程里对nginx的整个流程进行debug了，避免上面繁琐的配置。</p><p>只需要在<code>nginx.conf</code>文件中把<code>daemon</code>和<code>master_process</code>设成<code>off</code>即可。</p><figure class="codeblock codeblock--tabbed"><figcaption><ul class="tabs"><li class="tab active">nginx</li></ul></figcaption><div class="tabs-content"><figure class="highlight nginx" style="display: block;"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 关闭Master守护进程的功能</span></span><br><span class="line"><span class="attribute">daemon</span> <span class="literal">off</span>;</span><br><span class="line"><span class="comment"># 关闭多进程架构，如果为off，不会启动worker_process进程</span></span><br><span class="line"><span class="attribute">master_process</span> <span class="literal">off</span>;</span><br></pre></td></tr></tbody></table></figure></div></figure><blockquote><p>ReadMore: <a href="https://github.com/agile6v/awesome-nginx">https://github.com/agile6v/awesome-nginx</a></p></blockquote>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;&lt;img src=&quot;http://www.aosabook.org/images/nginx/architecture.png&quot; alt=&quot;NGINX architecture&quot;&gt;&lt;/p&gt;
&lt;p&gt;vscode调试nginx源码&lt;/p&gt;</summary>
    
    
    
    <category term="C&amp;C++" scheme="https://blog.hufeifei.cn/categories/C-C/"/>
    
    
    <category term="C" scheme="https://blog.hufeifei.cn/tags/C/"/>
    
    <category term="Nginx" scheme="https://blog.hufeifei.cn/tags/Nginx/"/>
    
    <category term="VSCode" scheme="https://blog.hufeifei.cn/tags/VSCode/"/>
    
  </entry>
  
  <entry>
    <title>ElasticSearch中_source、store_fields、doc_values性能比较</title>
    <link href="https://blog.hufeifei.cn/2021/10/DB/source-stored-docvalues/"/>
    <id>https://blog.hufeifei.cn/2021/10/DB/source-stored-docvalues/</id>
    <published>2021-10-21T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.691Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>在这篇文章中，我想<strong>从性能的角度探讨ElasticSearch 为我们存储了哪些字段，以及在查询检索时这些字段如何工作</strong>。实际上，ElasticSearch和Solr的底层库Lucene提供了两种存储和检索字段的方式：<code>store_fields</code>和<code>doc_values</code>。此外，ElasticSearch默认提供了 <code>_source</code> 字段，这是在索引时由文档的所有字段构造的一个大json。</p><p>为什么 ElasticSearch使用 <code>_source</code> 字段作为默认值，所有这些可用的字段从性能的角度来看有什么区别？让我们一探究竟！</p><h2>Lucene中的store_fields和doc_values</h2><p>当我们在 Lucene 中索引一个文档时，已经被索引的原始字段的信息丢失了。字段根据schema配置进行分词、转换然后索引形成倒排索引。没有任何额外的数据结构，当我们搜索一个文档时，我们得到的是这个文档的 docId 而不是原始字段。为了获得这些原始信息，我们需要额外的数据结构。Lucene为此提供了两种可用的方式：<code>store_fields</code>和<code>doc_values</code>。</p><h3>store_fields</h3><p><code>store_fields</code>的目的是存储字段的原始值（没被分词），以便在查询时检索它们。正如前面所说Lucene的倒排索引查询出来的是一个个docId，为了得到原始值就得把原始值存储起来。</p><h3>doc_values</h3><p>引入了<code>doc_values</code>是为了对排序、聚合、分组等操作进行加速。<code>doc_values</code>也可用于在查询时返回字段值。唯一的限制是我们不能在text字段上使用<code>doc_values</code>。</p><p><code>store_fields</code>和<code>doc_values</code>是在 Lucene 库中实现的，在 Solr 和 ElasticSearch 中都可以使用。</p><p>这里有一篇文章，比较了 Solr 中<code>store_fields</code>和<code>doc_values</code>检索性能：</p><p><a href="https://sease.io/2020/03/docvalues-vs-stored-fields-apache-solr-features-and-performance-smackdown.html">DocValues VS Stored Fields : Apache Solr Features and Performance SmackDown</a>.</p><p>可以找到关于<code>store_fields</code>和<code>doc_values</code>的更详细的使用方法以及各自局限性。</p><h2>ElasticSearch中的字段检索</h2><p>如果我们在映射中明确定义<code>store_fields</code>和<code>doc_values</code>，则可以在 elasticsearch 中使用它们：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;properties&quot;</span> <span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;field&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;keyword&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;store&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">        <span class="string">&quot;doc_values&quot;</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><blockquote><p>默认情况下，<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-store.html">每个字段的<code>store</code>都设置为 false</a>。相反，<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/doc-values.html">所有支持<code>doc_values</code>的字段都会默认开启<code>doc_values</code></a>。</p></blockquote><p>根据<code>store_fields</code>和<code>doc_values</code>的默认配置，在查询时仍然会返回查询命中的文档中的每个字段值。发生这种情况是因为 ElasticSearch 使用另一种工具进行字段检索：Elasticsearch 提供的<code>_source</code>字段。</p><h3>ElasticSearch _source字段</h3><p><code>_source</code> 字段是在索引时传递给 ElasticSearch 的 json。此字段在 ElasticSearch 中默认设置为 true，可以通过以下方式使用<code>mappings</code>禁用<code>_source</code>：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;mappings&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;_source&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;enabled&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>有两种方式检索<code>_source</code>字段的内容：</p><p>1、查询时用<code>field</code>选项可以提取在<code>mappings</code>中已经定义的字段</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST my-index-000001/_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;match&quot;: &#123;</span><br><span class="line">      &quot;user.id&quot;: &quot;kimchy&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;fields&quot;: [</span><br><span class="line">    &quot;user.id&quot;,</span><br><span class="line">    &quot;http.response.*&quot;,         </span><br><span class="line">    &#123;</span><br><span class="line">      &quot;field&quot;: &quot;@timestamp&quot;,</span><br><span class="line">      &quot;format&quot;: &quot;epoch_millis&quot; </span><br><span class="line">    &#125;</span><br><span class="line">  ],</span><br><span class="line">  &quot;_source&quot;: false</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>还可以用<code>format</code>选项对一些特殊的字段进行格式化处理，比如可以将时间戳转成字符串。</p><p>这种方式命中的结果也会在的<code>hits</code>对象下有对应的<code>fields</code>字段作为响应。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;hits&quot;</span> <span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;total&quot;</span> <span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;value&quot;</span> <span class="punctuation">:</span> <span class="number">1</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;relation&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;eq&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;max_score&quot;</span> <span class="punctuation">:</span> <span class="number">1.0</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;hits&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;_index&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;my-index-000001&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;_id&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;0&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;_score&quot;</span> <span class="punctuation">:</span> <span class="number">1.0</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;_type&quot;</span> <span class="punctuation">:</span> <span class="string">&quot;_doc&quot;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;fields&quot;</span> <span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;user.id&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;kimchy&quot;</span></span><br><span class="line">          <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;@timestamp&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;4098435132000&quot;</span></span><br><span class="line">          <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;http.response.bytes&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">1070000</span></span><br><span class="line">          <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;http.response.status_code&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="number">200</span></span><br><span class="line">          <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>2、通过<code>_source</code>选项提取原始的文档内容。前面的例子中，查询时<code>_source</code>都置成了false。</p><p>默认情况下<code>_source</code>为true，也就是默认返回<code>_source</code>原始内容的所有字段。</p><p>也可以<a href="https://www.elastic.co/guide/en/elasticsearch/reference/7.15/search-fields.html#source-filtering">指定要在响应中返回的<code>_source</code>中的一部分字段</a>，这应该是为了提高网络传输的响应速度。</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">GET /_search</span><br><span class="line">&#123;</span><br><span class="line">  &quot;_source&quot;: &#123;</span><br><span class="line">    &quot;includes&quot;: [ &quot;obj1.*&quot;, &quot;obj2.*&quot; ],</span><br><span class="line">    &quot;excludes&quot;: [ &quot;*.description&quot; ]</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;query&quot;: &#123;</span><br><span class="line">    &quot;term&quot;: &#123;</span><br><span class="line">      &quot;user.id&quot;: &quot;kimchy&quot;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-source-field.html#include-exclude">通过适当的配置将<code>_source</code>的某些字段在索引的时候就排除掉</a>：</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">PUT logs</span><br><span class="line">&#123;</span><br><span class="line">  &quot;mappings&quot;: &#123;</span><br><span class="line">    &quot;_source&quot;: &#123;</span><br><span class="line">      &quot;excludes&quot;: [</span><br><span class="line">        &quot;meta.description&quot;,</span><br><span class="line">        &quot;meta.other.*&quot;</span><br><span class="line">      ]</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>索引时，从<code>_source</code>中排除字段将减少磁盘空间使用，但被排除的字段将永远不会在响应中返回。</p><p>如果禁用 elasticsearch <code>_source</code> 字段，更新文档时需要从头开始重新索引。实际上，为了更新文档，我们需要从旧文档中获取字段的值。从逻辑上讲，使用store_fields和doc_values从旧文档中获取字段的值应该是可行的（这就是 Solr 中原子更新的工作方式）。但是，由于设计决定，这在 ElasticSearch 中是不允许的，如果您需要更新文档，则必须在 elasticsearch 索引配置中启用<code>_source</code>字段。</p><h3>检索字段</h3><p>在 elasticsearch 中，您可以启用或禁用<code>_source</code>字段并使Stored Field或<code>doc_values</code>。但是如何在查询时检索字段？</p><p>默认情况下，如果启用了<code>_source</code>，则返回包含整个文档的<code>_source</code>。您可以避免它并仅返回源的一个子集，如下所示：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">POST my-index<span class="number">-000001</span>/_search</span><br><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;query&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;match&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;user.id&quot;</span><span class="punctuation">:</span> <span class="string">&quot;kimchy&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;user.id&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;http.response.*&quot;</span><span class="punctuation">,</span>         </span><br><span class="line">    <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;field&quot;</span><span class="punctuation">:</span> <span class="string">&quot;@timestamp&quot;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;format&quot;</span><span class="punctuation">:</span> <span class="string">&quot;epoch_millis&quot;</span> </span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;_source&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>但是，如果您没有启用<code>_source</code>字段，并且想要从Stored Field和<code>doc_values</code>返回字段，则必须以另一种方式告诉它给 ElasticSearch。对于您使用的每个源，您必须以不同的方式指定字段列表：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">...</span><br><span class="line"> <span class="attr">&quot;fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;sv1&quot;</span><span class="punctuation">,</span> <span class="string">&quot;sv2&quot;</span><span class="punctuation">,</span>...<span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;docvalue_fields&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;dv1&quot;</span><span class="punctuation">,</span> <span class="string">&quot;dv2&quot;</span><span class="punctuation">,</span>...<span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line"> <span class="attr">&quot;stored_fields&quot;</span> <span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;s1&quot;</span><span class="punctuation">,</span> <span class="string">&quot;s2&quot;</span><span class="punctuation">,</span>...<span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure><p>例如，如果您有一个字段既存储了<code>store_fields</code>也存储了<code>doc_values</code>，您可以选择是从<code>store_fields</code>还是<code>doc_values</code>中检索它。从功能的角度来看，这完全相同，但您的选择可能会影响查询的执行时间。</p><h2>store_fields字段, doc_values和ElasticSearch _source内部结构</h2><p>在本节中，我只想简要概述<code>store_fields</code>、<code>_source</code> 字段和 <code>doc_values</code> 的内部结构，以便来了解使用这些方法进行字段检索时对性能的期望。</p><h3>store_fields内部结构</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-store.html">store_fields</a>以行方式放置在磁盘中：对于每个文档，都有一行连续包含所有需要存储的字段。</p><p><img src="https://i0.wp.com/sease.io/wp-content/uploads/2020/11/storedfields.png?resize=716,160&ssl=1" alt="img"></p><p>以上图为例。为了访问文档 x 的 field3，我们必须先访问文档 x 的行起始位置，并跳过存储在 field3 之前的所有字段。跳过字段需要获取其长度。跳过字段虽然不像读取那么繁琐，但此操作并非不耗时。</p><h3>doc_values内部结构</h3><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/doc-values.html">doc_values</a>以列方式存储。多个文档的同一个字段的值一起连续存储在一起，因为同一个字段的格式基本是一致的，所以可以“几乎”直接访问某个文档的某个字段。计算一个想要的值的地址不是一个简单的操作，它有一个计算成本，但我们可以想象，如果我们只想要一个字段，使用这种访问会更有效率。但是对于磁盘来说，这种随机访问会非常影响性能，所以一般只有在排序和聚合这种需要大批量提取一个字段的情况下会使用<code>doc_values</code>。</p><h3>ElasticSearch _source内部结构</h3><p><code>_source</code> 呢？好吧，如上所述，<code>_source</code> 是一个包含 json 的大字段，其中包含在索引时提供给 ElasticSearch 的所有输入。但是，这个字段实际上是如何存储的？毫不奇怪，ElasticSearch 利用了一种已经由 Lucene 现成的机制：<code>store_fields</code>。而且，<code>_source</code> 字段是行中第一个存储的字段。</p><p><img src="https://i0.wp.com/sease.io/wp-content/uploads/2020/11/sourcefield.jpg?resize=707,175&ssl=1" alt="img"></p><p>正因为它是包含整个文档内容的json，所以必须读取整个<code>_source</code>才能使用它包含的信息。如果我们要返回一个文档的所有字段，这个过程直观上是最快的。另一方面，如果我们只需要返回它包含的信息的一小部分，读取这个巨大的字段可能会浪费计算能力。</p><h2>性能测试</h2><p>为了对 3 种类型的字段进行基准测试，我在 ElasticSearch 中创建了 3 个不同的索引。我索引了来自维基百科的 100 万个文档，对于每个文档，我用三种不同的方法索引了 100 个包含 15 个字符的字符串字段：在第一个索引中，我将字段设置为<code>store_fields</code>，在第二个索引中设置为<code>doc_values</code>。在这两个索引中，我都禁用了<code>_source</code>字段。相反，在第三个索引中，我只是启用了<code>_source</code>字段。</p><p>文档和查询集合来自 <a href="https://github.com/tantivy-search/search-benchmark-game%E3%80%82">https://github.com/tantivy-search/search-benchmark-game。</a> 我使用真实的集合来模拟真实的场景。 </p><p>执行细节：</p><ul><li>CPU: AMD锐龙3600</li><li>RAM: 32 GB</li></ul><p>对于每个查询，我请求了最好的 200 个文档，并重复测试——将返回的字段数量（在我创建的 100 个随机字符串字段中）从 1 逐步提升到 100。</p><p>这是基准测试的结果：</p><p><img src="https://i0.wp.com/sease.io/wp-content/uploads/2020/11/elastic-benachmarks.png?resize=706,530&ssl=1" alt="img"></p><p>结果正好显示了我们期望看到的结果。</p><p>1、**如果我们需要每个文档的字段很少，建议使用 <code>doc_values</code> **。</p><p>2、<strong>当我们想要返回整个文档<code>_source</code> 字段是最好的</strong></p><p>3、而<code>store_field</code>是其他两者之间的完美折中。</p><p>在我执行的基准测试场景中，<strong>如果我们只需要一个字段，<code>doc_values</code>的速度几乎是 <code>_source </code>字段的两倍</strong> ，而在相反的极端情况下，如果我们想返回所有字段，使用<code>_source</code>字段代替<code>doc_values</code>，图表显示速度几乎提高了 <strong>2倍</strong>。</p><p>总之，性能不是我们必须考虑的唯一参数。正如我们在这篇文章中简要解释的那样，使用一种或另一种方法存在一些限制。由于您的用例的一些限制，您可能被迫使用这三个中的一个。而且即使从表现来看，我们也没有明显的赢家。</p><p>如果磁盘空间不是问题，**甚至可以混合不同的方法并将字段设置为<code>store_field</code>和<code>doc_values</code>，并保持开启<code>_source</code> **。在查询时，elasticsearch 使您可以选择所需的字段列表，以及是否希望从 <code>_source</code>、<code>_store_field</code>或 <code>doc_values</code> 返回它们。</p><p>当然三个都存储，也会导致索引阶段速度很慢，容易出现EsReject异常。所以软件工程没有银弹。根据场景合适选择吧！</p><p>参考：</p><p><a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/search-fields.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/search-fields.html</a></p><p><a href="https://sease.io/2021/02/field-retrieval-performance-in-elasticsearch.html">https://sease.io/2021/02/field-retrieval-performance-in-elasticsearch.html</a></p>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;在这篇文章中，我想&lt;strong&gt;从性能的角度探讨ElasticSearch 为我们存储了哪些字段，以及在查询检索时这些字段如何工作&lt;/strong&gt;。实际上，ElasticSearch和Solr的底层库Lucene提供了两种存储和检索字段的方式：&lt;code&gt;store_fields&lt;/code&gt;和&lt;code&gt;doc_values&lt;/code&gt;。此外，ElasticSearch默认提供了 &lt;code&gt;_source&lt;/code&gt; 字段，这是在索引时由文档的所有字段构造的一个大json。&lt;/p&gt;
&lt;p&gt;为什么 ElasticSearch使用 &lt;code&gt;_source&lt;/code&gt; 字段作为默认值，所有这些可用的字段从性能的角度来看有什么区别？让我们一探究竟！&lt;/p&gt;</summary>
    
    
    
    <category term="数据库" scheme="https://blog.hufeifei.cn/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"/>
    
    
    <category term="DB" scheme="https://blog.hufeifei.cn/tags/DB/"/>
    
    <category term="ElasticSearch" scheme="https://blog.hufeifei.cn/tags/ElasticSearch/"/>
    
    <category term="Lucene" scheme="https://blog.hufeifei.cn/tags/Lucene/"/>
    
  </entry>
  
  <entry>
    <title>菜鸟教程引发的流量与产品的思考</title>
    <link href="https://blog.hufeifei.cn/2021/10/business/think-of-runoob-tutorial/"/>
    <id>https://blog.hufeifei.cn/2021/10/business/think-of-runoob-tutorial/</id>
    <published>2021-10-19T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.703Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>对菜鸟教程网站的思考。菜鸟教程一个看上去很平常的网站，只是提供HTML、CSS、JS等Web相关的基础教程，但是据站长之家统计，这个网站的日流量达到接近300万的PV。</p><p><img src="https://s.pc.qq.com/tousu/img/20211024/2682028_1635059637.jpg" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer"></p><h2>金字塔行业结构：我们都曾是菜鸟</h2><p>大多数行业都是金字塔结构，行业头部的人往往是少数。很多时候我们把目标瞄向行业头部的专家，却忽视了专家也是从菜鸟成长起来的，忽视了普通从业者，忽视了“菜鸟“们的需求。“菜鸟教程”这个网站就是瞄准行业底部占大头的客户。也就是所谓的”下沉市场“。</p><p><img src="https://ae04.alicdn.com/kf/Ub42e3dfeba084b438059673c5781ab0fd.png" alt="金字塔行业结构"></p><p>很多时候，因为自己的孤傲，忽略了这部分下沉市场的需求：当你成为专家的时候，往往会对CSDN上的用户嗤之以鼻；当企业做大了，经常会忽视用户的小众需求；当阿里不断打造”消费升级“的概念，财报年年增长，股票欣欣向荣，商家抽成越来越狠，流量成本越来越高，逐渐背离三四线城市的需求，所以拼多多迅速崛起。</p><h2>好的产品与大的流量：先有鸡还是先有蛋</h2><p>有人说：只要产品做的好，人无我有，人有我优，总会有大量用户来使用我的产品。但是这个依赖于用户对产品的认知，在互联网环境下，酒香也怕巷子深，没有好的流量手段推广，产品再好也无人问津。</p><p>也有人说：我只要把用户基数做大了，流量做大了，不管卖啥，都能赚的盆满钵满。这种做法不能说有错，但是不可持续，没有好的产品支撑，用户无法回购，一锤子买卖做完就没了，流量再大，也是涸泽而渔。</p><p>好的产品需要创业者根据用户痛点用心打磨，针对每个行业，每个需求点做法不一。这篇文章下面重要讲的是流量的获取。</p><h2>流量获取</h2><ol><li><p>传统模式，如发传单、地推、电话营销、展会营销。这种以人力为主，转化率比较高。</p></li><li><p>SEO</p><p>SEO是成本最低的获取流量的方式，只需要懂技术，对搜索引擎关键词进行优化，尽可能让你的网站在搜索结果的前几页，自然就有流量了。</p><p>SEO 网站优化的步骤和技巧有哪些？ 可以参考 - 纵横SEO的回答 - 知乎 <a href="https://www.zhihu.com/question/19808905/answer/1324352720">https://www.zhihu.com/question/19808905/answer/1324352720</a></p><p>SEO流量的优点是质量很高，人家都是冲着关键词找到你的，只要产品做的足够好，转化率是非常高的。</p><p>SEO的缺点是应用必须部署在Web端，得让爬虫能访问到，这对于移动端App不友好。</p><blockquote><p>今天次把我的网站所有的访问量清0了，验证一下SEO的效果</p></blockquote></li><li><p>联盟推广</p><p>可以使用百度、谷歌的广告联盟，投放广告后，用户点击就能跳到landing页了。</p><p>联盟推广要看平台的算法，目前谷歌的质量比百度的质量好很多。</p></li><li><p>移动互联网平台引流</p><p>联盟推广主要针对Web上的用户，对于移动端用户，可以在微信、抖音等社交媒体上推广。这中类型的广告转化率也要看平台的广告算法的准确率，千人千面——能根据用户画像精准的推荐广告，这样转化率才会更高。</p><p><img src="https://ae04.alicdn.com/kf/Ub334c48335db4cfdaea9cc8071fabde3F.png" alt="微信广告"><br>我发现微信广告，每个人看到的内容都是不一样的，这种有针对性的投放，流量转化率就高很多。</p></li></ol><h2>渠道的选择原则</h2><ol><li><p>便宜的渠道优先：这个比较好理解，优先需要考虑到成本问题，当然如果不缺钱，可以忽略这条。缺点吧，便宜的渠道一般转化率可能较差。</p></li><li><p>和目标用户群比较匹配的渠道优先：这个很好理解，渠道匹配，转化率高。如果你产品的目标客户群是女性，你最好去小红书上去获客，比如你要推广的是化妆品，你应该选择美妆类的主播帮忙推广产品。</p></li><li><p>有可追溯性的渠道优先：一般流量的转化率需要数据作为基础。具备可追溯性 ，才可能优化广告投放的效果。</p><p>互联网广告通过大数据进行计算汇总：前面提到的SEO，各个所有引擎都有相关的统计平台，比如google的Google Search Console，Bing的BingWebMaster；联盟推广和其他互联网推广平台也有相应的统计报表。</p></li><li><p>投放灵活性的渠道优先：线下广告和一些合作mcn机构，一般都是一个季度、半年起投，如果你的产品和商业模式还不清晰，这种渠道暂时不要考虑。</p></li><li><p>大体量的渠道优先：大体量的渠道决定你获客的上限，一般中小企业暂时不需要考虑，这个属于爆发期企业需要考虑的问题。</p></li></ol>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;对菜鸟教程网站的思考。菜鸟教程一个看上去很平常的网站，只是提供HTML、CSS、JS等Web相关的基础教程，但是据站长之家统计，这个网站的日流量达到接近300万的PV。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://s.pc.qq.com/tousu/img/20211024/2682028_1635059637.jpg&quot; rel=&quot;external noreferrer nofollow noopener&quot; referrerpolicy=&quot;no-referrer&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="商业" scheme="https://blog.hufeifei.cn/categories/%E5%95%86%E4%B8%9A/"/>
    
    
    <category term="商业" scheme="https://blog.hufeifei.cn/tags/%E5%95%86%E4%B8%9A/"/>
    
    <category term="随笔" scheme="https://blog.hufeifei.cn/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>OpenTelemetry：一统江湖的未来</title>
    <link href="https://blog.hufeifei.cn/2021/10/Distribution/OpenTelemetry/"/>
    <id>https://blog.hufeifei.cn/2021/10/Distribution/OpenTelemetry/</id>
    <published>2021-10-10T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.691Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><blockquote><p>天下大势，分久必合，合久必分——《三国演义》</p></blockquote><h2>乾坤未定，混沌初开</h2><p><img src="https://www.brendangregg.com/Perf/linux_observability_tools.png" alt="Linux性能观测工具"></p><p>分布式未开之际，软件世界里网站后台还是单体模式。有问题可以看日志，查性能有<code>top</code>以及<a href="https://github.com/sysstat/sysstat">sysstat</a>下的一批工具包：<code>mpstat</code>、<code>pidstat</code>、<code>iostat</code>，要对日志做分析统计可以上文本三剑客<code>awk</code>、<code>sed</code>、<code>grep</code>。</p><p>随着互联网的突飞猛进，摩尔定律的失效，单体模式已经承接不了互联网下的滔天流量，应用的日志体量也在飙升，由于分布式集群环境日志也不再单独分布在一台机器上，怎么监控应用的性能、怎么基于日志做指标统计也变得异常复杂。于是衍生了<a href="https://blog.hufeifei.cn/2021/09/Distribution/grafana/">分布式系统的可观测性</a>的三大基石：Logging、Metrics、Tracing。今天的主角就是Tracing。</p><p><img src="https://pic3.zhimg.com/v2-246813d3962794604c4bc409a94693d6_r.jpg" alt="分布式观测性三大基石"></p><h2>Dapper启蒙，百花齐放</h2><p>谷歌作为互联网的巨擘，手握独步天下的搜索引擎——Google。搜索引擎作为互联网的要隘，流量增长异常惊人，这也促使谷歌发展出自己的一套分布式系统。谷歌为了增加公司影响力便于吸引人才，将内部的系统设计以一篇篇论文的形式公布给业界。</p><blockquote><p>谷歌就是这么自信，要知道谷歌的创始人也是基于自己发表的一篇论文创建的谷歌搜索引擎。</p></blockquote><p><img src="http://duanple.com/wp-content/uploads/2019/08/paper.jpg" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="谷歌论文与开源技术"></p><p>这其中每一篇论文都曾掀起过层层巨浪，比如号称三驾马车的GFS、MapReduce、Bigtable开创了大数据时代，Spanner、F1给分布式数据库指明了方向，TensorFlow引领了人工智能机器学习的发展，Borg衍生出基于K8S云原生的大生态。而<a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/36356.pdf">Dapper</a>也只是谷歌浩瀚冰山下的一隅，却引领了分布式系统链路追踪的发展。</p><p><img src="http://ww1.sinaimg.cn/large/bda5cd74ly1gh049xp5d1j20cl0auwf1.jpg" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="Dapper链路追踪"></p><p><a href="https://blog.hufeifei.cn/2020/07/Alibaba/distributed-tracing/">Dapper中描述了谷歌内部系统的链路追踪技术</a>。论文在2010年一经发出，Twitter根据论文研发了<a href="https://github.com/openzipkin/zipkin">Zipkin</a>，Uber根据论文研发了<a href="https://github.com/jaegertracing/jaeger">Jaeper</a>。当然这只是最早开源出来的非常有名气的两个项目，还有像阿里的EagleEye等众多为开源出来的内部项目都是以谷歌的Dapper为原型设计的。</p><p><img src="https://p.pstatp.com/origin/pgc-image/d0f15af19cfe475f897c97a705aa4a2f" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="链路追踪技术"></p><h2>OpenTracing标准，号令天下; OpenCensus不出，谁与争锋</h2><p>但是随着各大厂商对链路追踪系统的实现趋于碎片化，社区开始制定OpenTracing标准来统一链路追踪中涉及的相关概念和规范——这是一套平台无关、厂商无关的Trace协议，使得开发人员能够方便的添加或更换分布式追踪系统的实现。</p><p>在2016年11月的时候CNCF技术委员会投票接受OpenTracing作为Hosted项目，这是CNCF的第三个项目，第一个是Kubernetes，第二个是Prometheus，可见CNCF对OpenTracing背后可观察性的重视。大名鼎鼎的Zipkin、Jaeger也都开始遵循OpenTracing协议。</p><p>既然有了OpenTracing，OpenCensus又来凑什么热闹？</p><p>对不起，你要知道OpenCensus的发起者可是谷歌，也就是最早提出Tracing概念的公司（教练下场指导工作了:smirk:），而OpenCensus也就是Google Dapper的社区版。</p><p>OpenCensus和OpenTracing最大的不同在于除了Tracing外，它还把Metrics也包括进来，这样也可以在OpenCensus上做基础的指标监控；还有一点不同是OpenCensus并不是单纯的规范制定，他还把包括数据采集的Agent、Collector一股脑都实现了。OpenCensus也有众多的追随者，最大的新闻就是微软也宣布加入，OpenCensus可谓是如虎添翼。</p><p>OpenTracing这边有Elastic、Uber、Twitter、DataDog等互联网新秀作为拥趸已发展多年，而OpenCensus有谷歌、微软两大巨头撑腰。一时间也难分高低。</p><h2>横扫六合，一统天下</h2><p>既然没办法分个高低，谁都有优劣势，咱们就别干了，统一吧。于是OpenTelemetry横空出世。</p><p>那么问题来了：统一可以，起一个新的项目从头搞吗？那之前追随我的弟兄们怎么办？不能丢了我的兄弟们啊。<br>放心，这种事情肯定不会发生的。要知道OpenTelemetry的发起者都是OpenTracing和OpenCensus的人，所以项目的第一宗旨就是：兼容OpenTracing和OpenCensus。对于使用OpenTracing或OpenCensus的应用不需要重新改动就可以接入OpenTelemetry。</p><p>OpenTelemetry可谓是一出生就带着无比炫目的光环：OpenTracing支持、OpenCensus支持、直接进入CNCF sanbox项目。但OpenTelemetry也不是为了解决可观察性上的所有问题，他的核心工作主要集中在3个部分：</p><ol><li>规范的制定，包括概念、协议、API，除了自身的协议外，还需要把这些规范和W3C、GRPC这些协议达成一致；</li><li>相关SDK、Tool的实现和集成，包括各类语言的SDK、代码自动注入、其他三方库（Log4j、LogBack等）的集成；</li><li>采集系统的实现，目前还是采用OpenCensus的采集架构，包括Agent和Collector。</li></ol><p>可以看到OpenTelemetry只是做了数据规范、SDK、采集的事情，对于Backend、Visual、Alert等并不涉及，官方目前推荐的是用Prometheus去做Metrics的Backend、用Jaeger去做Tracing的Backend。</p><p><img src="https://pic3.zhimg.com/80/v2-f40112487219807fc5d66ad6cdce5d56_1440w.jpg" alt="img"></p><p>看了上面的图大家可能会有疑问：Metrics、Tracing都有了，那Logging为什么也不加到里面呢？<br>其实Logging之所以没有进去，主要有两个原因：</p><ol><li>工作组目前主要的工作是在把OpenTracing和OpenCensus的概念尽早统一并开发相应的SDK，Logging是P2的优先级。</li><li>他们还没有想好Logging该怎么集成到规范中，因为这里还需要和CNCF里面的Fluentd一起去做，大家都还没有想好。</li></ol><h3>终极目标</h3><p>OpenTelemetry的终态就是实现Metrics、Tracing、Logging的融合，作为CNCF可观察性的终极解决方案。</p><p>Tracing：提供了一个请求从接收到处理完毕整个生命周期的跟踪路径，通常请求都是在分布式的系统中处理，所以也叫做分布式链路追踪。</p><p>Metrics：提供量化的系统内/外部各个维度的指标，一般包括Counter、Gauge、Histogram等。</p><p>Logging：提供系统/进程最精细化的信息，例如某个关键变量、事件、访问记录等。</p><p>这三者在可观测性上缺一不可：基于Metrics的告警发现异常，通过Tracing定位问题（可疑）模块，根据模块具体的日志详情定位到错误根源，最后再基于这次问题调查经验调整Metrics（增加或者调整报警阈值等）以便下次可以更早发现/预防此类问题。</p><h3>Metrics、Tracing、Logging融合的关键</h3><p>实现Metrics、Tracing、Logging融合的关键是能够拿到这三者之间的关联关系.其中我们可以根据最基础的信息来聚焦，例如：时间、Hostname(IP)、APPName。这些最基础的信息只能定位到一个具体的时间和模块，但很难继续Digin，于是我们就把TraceID把打印到Log中，这样可以做到Tracing和Logging的关联。但这还是解决不了很多问题：</p><ol><li>如何把Metrics和其他两者关联起来</li><li>如何提供更多维度的关联，例如请求的方法名、URL、用户类型、设备类型、地理位置等</li><li>关联关系如何一致，且能够在分布式系统下传播</li></ol><p>在OpenTelemetry中试图使用Context为Metrics、Logging、Tracing提供统一的上下文，三者均可以访问到这些信息，由OpenTelemetry本身负责提供Context的存储和传播：</p><ul><li>Context数据在Task/Request的执行周期中都可以被访问到</li><li>提供统一的存储层，用于保存Context信息，并保证在各种语言和处理模型下都可以工作（例如单线程模型、线程池模型、CallBack模型、Go Routine模型等）</li><li>多种维度的关联基于Tag（或者叫meta）信息实现，Tag内容由业务确定，例如：通过TrafficType来区别是生产流量还是压测流量、通过DeviceType来分析各个设备类型的数据…</li><li>提供分布式的Context传播方式，例如通过W3C的traceparent/tracestate头、GRPC协议等</li></ul><h3>当前状态以及后续路线</h3><p>目前OpenTelemetry还处于策划和原型阶段，很多细节的点还在讨论当中，目前官方给的时间节奏是：</p><ul><li>2019年9月，发布主要语言版本的SDK（Pre Release版）</li><li>2019年11月，OpenTracing和OpenCensus正式sunsetted（ReadOnly）</li><li>未来两年内，保证可以兼容OpenTracing和OpenCensus的SDK</li></ul><h3>总结</h3><p>从Prometheus、OpenTracing、Fluentd到OpenTelemetry、Thanos这些项目的陆续进入就可以看出CNCF对于Cloud Native下可观察性的重视，而OpenTelemetry的出现标志着Metrics、Tracing、Logging有望全部统一。</p><p>但OpenTelemetry并不是为了解决客观性上的所有问题，后续还有很多工作需要进行，例如：</p><ul><li>提供统一的后端存储，目前三类数据都是存储在不同系统中</li><li>提供计算、分析的方法和最佳实践，例如动态拓扑分析</li><li>统一的可视化方案</li><li>AIOps相关能力，例如Anomaly Detection、Root Cause Analysis等</li></ul><p>更多参考文章：</p><p><a href="https://www.cncf.io/blog/2019/05/21/a-brief-history-of-opentelemetry-so-far/">A brief history of OpenTelemetry (So Far) | Cloud Native Computing Foundation (cncf.io)</a></p><p><a href="https://www.cncf.io/blog/2016/10/11/opentracing-joins-the-cloud-native-computing-foundation/">OpenTracing joins the Cloud Native Computing Foundation | Cloud Native Computing Foundation (cncf.io)</a></p><p><a href="https://github.com/open-telemetry/opentelemetry-specification">open-telemetry/opentelemetry-specification: Specifications for OpenTelemetry (github.com)</a></p>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;blockquote&gt;
&lt;p&gt;天下大势，分久必合，合久必分——《三国演义》&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;乾坤未定，混沌初开&lt;/h2&gt;</summary>
    
    
    
    <category term="分布式" scheme="https://blog.hufeifei.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="Distributed" scheme="https://blog.hufeifei.cn/tags/Distributed/"/>
    
    <category term="OpenTelemetry" scheme="https://blog.hufeifei.cn/tags/OpenTelemetry/"/>
    
  </entry>
  
  <entry>
    <title>grpc在k8s中的负载均衡问题</title>
    <link href="https://blog.hufeifei.cn/2021/10/Distribution/grpc-in-k8s/"/>
    <id>https://blog.hufeifei.cn/2021/10/Distribution/grpc-in-k8s/</id>
    <published>2021-10-10T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.691Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><p>线上skywalking架构：</p><p><img src="/2021/10/Distribution/grpc-in-k8s/skywalking.svg" alt="skywalking"></p><p>两台skywalking-oap接受并分析由agent采集的trace数据，但是问题是两台oap服务负载不均衡。</p><p><img src="https://p.pstatp.com/origin/pgc-image/3f7d24cab5424fdcb455ed043ad06337" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="grpc-in-k8s"></p><h2>k8s的service四层负载均衡</h2><p>为了排除k8s的service负载均衡的问题，在线下环境还原了请求的过程。</p><p>skywalking提供了grpc(11800端口)和rest(12800端口)两种协议的服务。</p><p>从下图可以看到，skywalking提供了11800和12800的监听端口，以及连接ElasticSearch的9200端口</p><p><img src="https://p.pstatp.com/origin/pgc-image/304a8e74bcab495aba183d0654daf135" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="skywalking"></p><p>第一次请求连上了skywalking-oap1</p><p><img src="https://p.pstatp.com/origin/pgc-image/dd123b9774c2484785a128610b1dd361" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer"></p><p>第二次请求连上了skywalking-oap2</p><p><img src="https://p.pstatp.com/origin/pgc-image/b013fc7590584e3d8102c09fb7e2ab3e" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer"></p><p>多次请求负载均衡是没有问题的。但是请求会断开连接，实际上是两次<strong>连接</strong>连向了两台不同的server。这个概念很重要，请求和连接不是一个事物，多个请求可以复用一个连接。</p><h2>grpc长连接导致负载不均衡</h2><p>观察线上的两台oap发现，两台server都维持了大量的长连接，其中负载高的一台明显连接数更多。</p><p><img src="https://p.pstatp.com/origin/pgc-image/3d9e91705fc844ca97888f5955d079c1" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer"></p><p>由于线上skywalking-agent和skywalking-oap使用的是grpc进行通信的，grpc基于http/2会维持一个长连接。k8s的service无法识别应用层的负载均衡。</p><h2>对比常见的负载均衡实现</h2><p><strong>dubbo与SpringCloudRibbon的客户端负载均衡</strong></p><p>Dubbo因为有自己的注册中心可以直接获取服务ip，负载均衡直接由Dubbo客户端实现，两次调用会路由到不同的service，即使client持有多个service实例的连接，客户端也能根据连接个数进行负载均衡。这本质上和SpringCloud中的Ribbon原理一样。这种情况直接就不需要k8s的service来实现负载均衡。</p><p><img src="https://camo.githubusercontent.com/e11a2ff9575abc290657ba3fdbff5d36f1594e7add67a72e0eda32e449508eef/68747470733a2f2f647562626f2e6170616368652e6f72672f696d67732f6172636869746563747572652e706e67" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="Dubbo Architecture"></p><p><strong>基于反向代理的负载均衡</strong></p><p>Nginx，Apache，HAProxy等反向代理服务器都支持负载均衡的功能。</p><p><img src="https://www.technicalhosts.com/wp-content/uploads/2020/08/Reverse-proxy.gif"></p><p>像Nginx是能识别HTTP消息的，即使是维持了长连接，也能截取出完整的http消息，从而实现应用层的负载均衡。</p><p>Nginx在1.9.0添加了<a href="http://nginx.org/en/docs/stream/ngx_stream_proxy_module.html"><code>ngx_stream_proxy_module</code>模块</a>支持TCP/UDP的反向代理，但是它只能处理TCP连接，但是处理不了应用层的请求负载均衡。</p><p>比如<a href="https://www.nginx.com/blog/mysql-high-availability-with-nginx-plus-and-galera-cluster/">使用nginx为mysql建立高可用的反向代理</a>，它解析不了同一个mysql连接中的两条sql请求。比如想进行读写分离，nginx就实现不了，这些大多是在应用端实现的，或者使用专业的反向代理，比如<a href="https://proxysql.com/blog/configure-read-write-split/">ProxySQL</a>。</p><p>k8s的service就有点类似于nginx的tcp反向代理。当然只是说很像，实际上区别还是很大的。</p><p>下面看一下k8s的service实现原理。</p><h2>k8s的service实现原理</h2><p><a href="https://kubernetes.io/docs/concepts/services-networking/service/#virtual-ips-and-service-proxies">k8s的service是基于虚拟ip实现的</a>：使用iptables实现路由转发。k8s的service代理有三种运行模式：</p><h3>1、userspace代理模式</h3><p>这种模式，kube-proxy 会监控 Kubernetes control plane 对 Service 对象和 Endpoints 对象的添加和移除操作。 对每个 Service，它会在本地 Node 上打开一个端口（随机选择）。 任何连接到“代理端口”的请求，都会被代理到 Service 后端的某个Pod上（如 <code>Endpoints</code> 所报告的一样）。 使用哪个后端 Pod，是 kube-proxy 基于 <code>SessionAffinity</code> 来确定的。</p><p>最后，它配置 iptables 规则，将到达该 Service 的 <code>clusterIP</code>（是虚拟 IP） 和 <code>Port</code> 的请求重定向到代理的后端Pod的端口。</p><p>默认情况下，用户空间模式下的 kube-proxy 通过<strong>轮询</strong>算法选择后端服务。</p><p><img src="https://d33wubrfki0l68.cloudfront.net/e351b830334b8622a700a8da6568cb081c464a9b/13020/images/docs/services-userspace-overview.svg" alt="Services overview diagram for userspace proxy"></p><h3>2、iptables 代理模式</h3><p>这种模式，<code>kube-proxy</code> 会监控 Kubernetes control plane 对 Service 对象和 Endpoints 对象的添加和移除。对每个 Service，它会配置 iptables 规则，从而捕获到达该 Service 的 <code>clusterIP</code> 和端口的请求，进而将请求重定向到 Service 的后端中的某个 Pod 上面。 对于每个 Endpoints 对象，它也会配置 iptables 规则，这个规则会选择一个后端Pod。</p><p>默认情况下，kube-proxy 在 iptables 模式下<strong>随机</strong>选择一个后端。</p><p>使用 iptables 处理流量具有较低的系统开销，因为流量由 Linux netfilter 处理， 而无需在用户空间和内核空间之间切换。 这种方法也可能更可靠。</p><p>如果 kube-proxy 在 iptables 模式下运行，并且所选的第一个 Pod 没有响应， 则连接失败。 这与用户空间模式不同：在这种情况下，kube-proxy 将检测到与第一个 Pod 的连接已失败， 并会自动使用其他后端 Pod 重试。</p><p>你可以使用 Pod <a href="https://kubernetes.io/zh/docs/concepts/workloads/pods/pod-lifecycle/#container-probes">就绪探针</a> 验证后端 Pod 可以正常工作，以便 iptables 模式下的 kube-proxy 仅看到测试正常的Pod。 这样做意味着你避免将流量通过 kube-proxy 发送到已知已失败的 Pod。</p><p><img src="https://d33wubrfki0l68.cloudfront.net/27b2978647a8d7bdc2a96b213f0c0d3242ef9ce0/e8c9b/images/docs/services-iptables-overview.svg" alt="iptables代理模式下Service概览图"></p><h3>3、IPVS模式</h3><p>在 <code>ipvs</code> 模式下，kube-proxy 监控 Kubernetes Services和Endpoints，调用 <code>netlink</code> 接口相应地创建 IPVS 规则， 并定期将 IPVS 规则与 Kubernetes 服务和端点同步。 该控制循环可确保IPVS 状态与所需状态匹配。访问Service时，IPVS 将流量定向到后端Pod之一。</p><p>IPVS代理模式基于类似于 iptables 模式的 netfilter hook函数， 但是使用哈希表作为基础数据结构，并且在内核空间中工作。 这意味着，与 iptables 模式下的 kube-proxy 相比，IPVS 模式下的 kube-proxy 重定向通信的延迟要短，并且在同步代理规则时具有更好的性能。 与其他代理模式相比，IPVS 模式还支持更高的网络流量吞吐量。</p><p>IPVS 提供了更多选项来平衡后端 Pod 的流量。 这些是：</p><ul><li><code>rr</code>：轮替（Round-Robin）</li><li><code>lc</code>：最少链接（Least Connection），即打开链接数量最少者优先</li><li><code>dh</code>：目标地址哈希（Destination Hashing）</li><li><code>sh</code>：源地址哈希（Source Hashing）</li><li><code>sed</code>：最短预期延迟（Shortest Expected Delay）</li><li><code>nq</code>：从不排队（Never Queue）</li></ul><blockquote><p><strong>说明：</strong></p><p>要在 IPVS 模式下运行 kube-proxy，必须在启动 kube-proxy 之前使 IPVS 在节点上可用。</p><p>当 kube-proxy 以 IPVS 代理模式启动时，它将验证 IPVS 内核模块是否可用。 如果未检测到 IPVS 内核模块，则 kube-proxy 将退回到以 iptables 代理模式运行。</p></blockquote><p><img src="https://d33wubrfki0l68.cloudfront.net/2d3d2b521cf7f9ff83238218dac1c019c270b1ed/9ac5c/images/docs/services-ipvs-overview.svg" alt="IPVS代理的 Services 概述图"></p><p>在这些代理模型中，绑定到服务 IP 的流量： 在客户端不了解 Kubernetes 或服务或 Pod 的任何信息的情况下，将 Port 代理到适当的后端。</p><p>如果要确保每次都将来自特定客户端的连接传递到同一 Pod， 则可以通过将 <code>service.spec.sessionAffinity</code> 设置为 “ClientIP” （默认值是 “None”），来基于客户端的 IP 地址选择会话关联。 你还可以通过适当设置 <code>service.spec.sessionAffinityConfig.clientIP.timeoutSeconds</code> 来设置最大会话停留时间。 （默认值为 10800 秒，即 3 小时）。</p><h2>K8s中grpc负载均衡的解决方案</h2><p>前面已经分析了k8s的service是无法实现应用层的负载均衡的。grpc基于http/2，因为http/2是长连接，负载均衡需要发生在每次调用，而非每次连接。K8s识别不了http/2的请求，就无法实现grpc的负载均衡。</p><h3>1、使用Nginx进行反向代理</h3><p>既然grpc基于http/2，那么可以使用Nginx进行grpc的反向代理，因为<a href="http://nginx.org/en/docs/http/ngx_http_v2_module.html">Nginx在1.9.5开始支持Http/2协议</a>。这个方案能完全保证流量的均匀分配。</p><p>但是架构上就比较复杂，为了防止skywalking-oap的pod重启，ip改变后nginx需要重新修改配置。那么需要为每个skywalking-oap创建一个Service。另外为了防止Nginx重启后Pod的ip改变，Nginx也需要创建一个Service。</p><p><img src="/2021/10/Distribution/grpc-in-k8s/skywalking-nginx.svg"></p><p>一个简单的方法是使用K8s的Ingress代替Nginx，<a href="https://kubernetes.github.io/ingress-nginx/">Ingress本身也有nginx的实现</a>。</p><p><img src="/2021/10/Distribution/grpc-in-k8s/skywalking-ingress.svg"></p><h3>2、修改K8s的service运行模式</h3><p>我们退而求其次，无法实现每次grpc调用的负载均衡，保证连接数的均衡，也算进一大步了。</p><p>前面分析K8s的Service运行原理的时候，Service有三种运行模式：</p><ul><li>userspace代理模式：过<strong>轮询</strong>算法选择后端服务</li><li>iptables代理模式：<strong>随机</strong>选择后端服务</li><li>IPVS模式：支持多种模式<ul><li><code>rr</code>：轮替（Round-Robin）</li><li><code>lc</code>：最少链接（Least Connection），即打开链接数量最少者优先</li><li><code>dh</code>：目标地址哈希（Destination Hashing）</li><li><code>sh</code>：源地址哈希（Source Hashing）</li><li><code>sed</code>：最短预期延迟（Shortest Expected Delay）</li><li><code>nq</code>：从不排队（Never Queue）</li></ul></li></ul><p>使用轮询和随机的方式创建连接，问题是连接断了后重连，会出现连接不均衡的问题。</p><p>那么可以使用IPVS的<code>lc</code>模式，让连接优先分配给打开链接数少的server。这样能保证连接数的均衡。</p><h3>3、为grpc添加LoaderBalancer组件</h3><p>原生grpc就没有服务发现这个概念，而是使用<a href="https://github.com/grpc/grpc/blob/master/doc/load-balancing.md">另外的LoaderBalancer组件实现</a>负载均衡。</p><p><img src="https://p.pstatp.com/origin/pgc-image/10fbe36a93e9450ea628dbc3ccaf04f0" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer"></p><p>这种方式类似于Dubbo的方案，让客户端实现负载均衡。但是实现起来就比较复杂了，除了要多部署一个LoadBalancer，还需要在skywalking-agent中配置grpc负载均衡的策略。skywalking-oap注册到LoadBalancer中也是一个大问题。</p>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;p&gt;线上skywalking架构：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;/2021/10/Distribution/grpc-in-k8s/skywalking.svg&quot; alt=&quot;skywalking&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="分布式" scheme="https://blog.hufeifei.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="Distributed" scheme="https://blog.hufeifei.cn/tags/Distributed/"/>
    
    <category term="gRPC" scheme="https://blog.hufeifei.cn/tags/gRPC/"/>
    
    <category term="Kubernetes" scheme="https://blog.hufeifei.cn/tags/Kubernetes/"/>
    
  </entry>
  
  <entry>
    <title>行为经济学与营销</title>
    <link href="https://blog.hufeifei.cn/2021/10/economic/behavioral-economics/"/>
    <id>https://blog.hufeifei.cn/2021/10/economic/behavioral-economics/</id>
    <published>2021-10-01T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.703Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><blockquote><p>之前工作中接触过电商营销平台，对营销略有了解，后面也看了一点文章书籍。这篇文章将我的一些思考做一下整理。</p></blockquote><p>传统经济学理论是基于人是理性的这一前提作为假设，推断人的经济行为，这个假设是为了方便使用数学工具描述经济学理论，但实际上大多数人无法做到完全理性。</p><p>心理学理论则是研究人性一般规律，认识自己，认识他人，推断大众行为的决策方向。</p><p>而行为经济学则是结合心理学与经济学，推断人的经济行为，相比传统经济学和心理学，行为经济学更加实用。它非常切合实际的体现在生活的各个方面，如营销(或者叫消费心理学)，金融，婚恋，甚至人际关系。这篇文章的主要内容也是来自于《怪诞行为学》一书。</p><h2>1、锚定效应：比较心理</h2><p><img src="https://pic4.zhimg.com/v2-7602ffc5a785c864d939ce6eca702543_r.jpg" alt="视觉锚定效应"></p><p>我们大多数人都会觉得右边的小正方形颜色更深，因为人的视觉经常会受到对比参考物的影响。但实际上中间的两个正方形颜色都是<code>#4e4e4e</code>。这是因为人类视觉系统对亮度的更敏感，而对颜色没那么敏感。这种人类视觉的局限性被利用在了JPEG的图片有损压缩算法中。图片有损压缩算法具体可以参看<a href="https://zhuanlan.zhihu.com/p/521617590">这篇文章——令人拍案叫绝的JPEG图像压缩原理</a></p><p><img src="https://pic1.zhimg.com/80/v2-b9b8296a2634abc031876caf3c8cbea4_1440w.webp" alt="图片有损压缩"></p><p>事实上除了人的视觉，人的心理也会受参考物的影响，从而影响人的决策。</p><p>比如有定价125元一年的订阅杂志卖不出去了，此时商家提供一个电子版的杂志56元，电子版加纸质版买一送一125元。这个锚定的56元电子版，让原来卖不出去的125元纸质杂志捆绑销售，用户觉得自己捡了个56块钱的便宜，纸质版杂志相当于69元买到手了，但实际上电子版成本几乎为零，商家为了促销才让你觉得赚到了。</p><p><img src="https://pic3.zhimg.com/v2-b54aae22825ad2eb4c24283d6aa54de2_r.jpg"></p><p>再比如星巴克里咖啡的不同规格：</p><p><img src="https://pic4.zhimg.com/80/v2-f5115feee1247d26ff7f15a915783ff7_1440w.webp"></p><p>星巴克大杯470ml是31元，而小杯240ml就需要25元，算一下发现470ml将近是240ml两杯，这个时候你可能就心甘情愿的花了31块买了个大杯的星巴克，还以为自己赚了。实际上小杯星巴克就是一个参考锚定值，让你觉得31块买470ml的星巴克不贵而且赚了。</p><p><img src="https://pic4.zhimg.com/80/v2-072014036f05a19fa5c49a6a2ed161ab_1440w.webp"></p><p>奶茶第二杯半价的本质也是让你觉得占到了便宜，以一杯的价格作为锚点，让你发现两杯价格反而更便宜。商家不傻，商家卖两杯的收益肯定是比卖一杯的收益大的，所以这也可以间接推算出一杯奶茶的利润率肯定大于50%</p><p><img src="https://pic1.zhimg.com/v2-c21f249842a64e029b36ae2ed7f50d04_r.jpg"></p><p>俗话都说“货比三家不吃亏”，人衡量自己是赚到了还是亏了，是需要有个参照物的，而商家就专门设计这么个参照物，让你觉得自己占了便宜。</p><p><img src="https://pic4.zhimg.com/80/v2-1277d767743e032154a71159b692dc27_1440w.webp"></p><p><strong>攀比心理</strong></p><p>国人有个现象：读书时比成绩，大学时比学历，工作了比收入，结婚了比对象，有娃了比娃的成绩……循环往复，乐此不疲。</p><p>这个普世的价值观实际上也是锚定效应的一种体现，因为你拿来比对的是你周围的亲戚朋友。“隔壁老王的娃这次考试又考了100了，你怎么才考95分”，难道是95分不够优秀吗，只是因为你的视野范围内有更优秀的，这是人性的弱点，所以营销专家们也喜欢钻营这个，专门夸大广告词。</p><p><img src="https://pic2.zhimg.com/80/v2-0568b4f2c8bb7a5ad0429f96245fb33d_1440w.webp"></p><h3>损失厌恶心理</h3><p>人都有一个心理现象：失去的痛苦远大于得到的快乐。</p><p>比如有一个彩票，50%概率能赢得11块，50%概率损失10块。</p><p><img src="https://pic4.zhimg.com/80/v2-f0db847d48b3e7a0d12a15d86cc3142b_1440w.webp"></p><p>按照传统经济学理论，这个游戏的盈利期望是正的，应该会有很多人乐意玩这个游戏。但是实际研究发现大多数人不愿意玩这个游戏，因为损失10块钱带来的痛苦会比赢11块钱带来的价值大。</p><p><img src="https://pic2.zhimg.com/80/v2-e4c4c8a5bd97369b51f5360210502a99_1440w.webp"></p><p>首月1元或首月免减，连续包年的会员，让你先拥有会员资质，等你体验了会员权益后，失去这个权益的痛苦大于你一个月得到十几块钱的价值，此时你就会一直让他扣费。这就是利用了人的损失厌恶心理。</p><p><img src="https://pic1.zhimg.com/80/v2-7b8fbee7803123cbac80e039d2921290_1440w.webp"></p><p>再比如电商常用手段——优惠券，你看着快过期的优惠券，心里痒痒地觉得就要损失5块钱了，于是你开始打开app翻啊翻，找啊找，看看有没有潜在的想买的东西。这也是电商营销平台最喜欢用的激活用户潜在需求的手段。</p><p><img src="https://pic4.zhimg.com/80/v2-96f1ad5cd0ffcd6a40b7f719f18ca483_1440w.webp"></p><h2>2、羊群效应：从众心理</h2><p>为什么一条牧羊犬能驯服一千多只羊的羊群呢？因为牧羊犬只要搞定羊群中的几只领头羊，其他羊都会满怀信任心甘情愿地跟着它走。</p><p><img src="https://pic2.zhimg.com/80/v2-8d8c2fdc11f56fb47263a932f44f8941_1440w.webp"></p><p>人也是一样，在人类早期，单独的个体面对豺狼虎豹是很难生存下来的，所以人类也进化出了羊群效应。</p><p>在信息不对称的时候，羊群效应能有效避免损失。比如，来到一个陌生的城市旅游，要看周围哪家餐馆好吃，上美团看看大众点评；比如上淘宝买零食，会看哪个销量高。也正因此，商家为了销量会刷评论。</p><p>除了刷评论，商家们利用人类的羊群效应做广告营销：裤子口袋里装东西显得土，裤子的皮带扣环上挂钥匙显老气，那是因为商家们要卖他生产的包。</p><p>除了羊群效应，人类还有一个毛病：迷信权威。这也是人类进化的选择，原始社会中人类需要活下来就必须团结，而任何一个团队都需要权威领袖来领导，领袖之所以能成为领袖，是因为他通常能让整个族群利益最大化，族群中的其他人只要追随配合领袖也能吃到肉喝到汤。</p><p>跟随团队、追随权威领袖的人活下来了，那些脱离团队、离群索居的人在自然选择下淘汰了。随着人类进化和社会文化的影响，羊群效应和迷信权威在历史的进程中刻入人们的骨子里。鲁迅曾有言：中国的年轻人大抵都缺乏了独立思考的能力。</p><p>还记得文章前面乔布斯的那句话吗“顾客要的不是占便宜，而是占便宜的感觉”，乔布斯真的说过这句话吗，并没有，这句话完全是杜撰的。鲁迅真的说过前面那句话吗，那句话也是杜撰的。</p><p>但是这些话因为冠以名人口吻，使其更有信服力。这就像你在央视台打广告，请朱广权、撒贝宁宣传代言带来的效果是一样的。</p><p>对于代价小的事儿，羊群效应能省掉很多精力去调查甄别判断。但是对于<strong>高代价的事儿就要避免羊群效应</strong>了。</p><p>像股市，自己没有调查，没有自己合理的投资逻辑，盲目跟风追涨杀跌就只能沦为被割的韭菜。</p><p>比如买房，售楼处会故意营造出一种商品房热销的感觉，仿佛在不买就要错失这次机会了，这促使买家不加思考快速签订购房合同。</p><p><strong>自我羊群效应：墨守成规</strong></p><p>“自我羊群效应”，指的是根据自己以往的经验，不假思索地进行决策。过去的自己能成功，不代表现在能成功，成功的因素可能受当时的环境等各种因素影响。所以面对大的决策，需要审时度势因地制宜结合不同场景不同因素思考再下决策。</p>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;blockquote&gt;
&lt;p&gt;之前工作中接触过电商营销平台，对营销略有了解，后面也看了一点文章书籍。这篇文章将我的一些思考做一下整理。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;传统经济学理论是基于人是理性的这一前提作为假设，推断人的经济行为，这个假设是为了方便使用数学工具描述经济学理论，但实际上大多数人无法做到完全理性。&lt;/p&gt;</summary>
    
    
    
    <category term="经济与金融" scheme="https://blog.hufeifei.cn/categories/%E7%BB%8F%E6%B5%8E%E4%B8%8E%E9%87%91%E8%9E%8D/"/>
    
    
    <category term="随笔" scheme="https://blog.hufeifei.cn/tags/%E9%9A%8F%E7%AC%94/"/>
    
    <category term="经济" scheme="https://blog.hufeifei.cn/tags/%E7%BB%8F%E6%B5%8E/"/>
    
    <category term="营销" scheme="https://blog.hufeifei.cn/tags/%E8%90%A5%E9%94%80/"/>
    
    <category term="心理学" scheme="https://blog.hufeifei.cn/tags/%E5%BF%83%E7%90%86%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>分布式系统的可观测性</title>
    <link href="https://blog.hufeifei.cn/2021/09/Distribution/grafana/"/>
    <id>https://blog.hufeifei.cn/2021/09/Distribution/grafana/</id>
    <published>2021-09-20T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.691Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2>从单体应用到分布式应用的可观测性</h2><p><img src="https://engineering.zenduty.com/assets/images/tracinglogging.png" alt="分布式系统观测性的三大基石"></p><h3>Logging</h3><p><strong>日志记录本质上是一个事件</strong>。大多数语言、应用程序框架或库都支持日志，表现形式可以是字符串这样原始的非结构化数据，也可以是JSON等半结构化数据。开发者可以通过日志来分析应用的执行状况，报错信息，分析性能…… 正因为日志极其灵活，生成非常容易，没有一个统一的结构，所以它的体量也是最大的。</p><p>对于单体应用，查看日志我们可以直接登上服务器，用<code>head</code>、<code>tail</code>、<code>less</code>、<code>more</code>等命令进行查看，也可以结合<code>awk</code>、<code>sed</code>、<code>grep</code>等文本处理工具进行简单的分析。但是分布式应用，面对部署在数十数百台机器的应用，<strong>亟需一个日志收集、处理、存储、查询的系统</strong>。</p><p>开源社区最早流行的是Elastic体系的ELK。Logstash负责收集，ElasticSearch负责索引与存储，Kibana负责查询与展示。ElasticSearch支持全文索引可以进行全文搜索，而且支持DocValue可以用于结构化数据的聚合分析。再加上<a href="https://www.elastic.co/cn/beats/">MetricBeats</a>提供了监控指标的收集，<a href="https://www.elastic.co/cn/apm/">APM</a>提供的链路收集，Elastic俨然已是一个集Logging、Metrics、Trace的大一统技术体系。这主要是因为早期的</p><p>Elastic野心很大，但是这也导致ElasticSearch并不专注在其中的一个领域。</p><p>1、使用全文索引受限于分词器，对于日志查询非常鸡肋(两个单词能搜索到，三个单词就搜索不到的现象也不少)。</p><p>2、而且索引阶段特别耗时，很多用户都无法忍受ElasticSearch索引不过来时抛出的EsReject。</p><p>3、另外，ElasticSearch除了用于全文搜索的倒排索引，还有<code>store</code>按行存储，在<code>_source</code>字段中存储JSON文档，<code>docValue</code>列式存储，对于不熟悉ElasticSearch的开发者来说，意味着存储体量翻了好几倍，ElasticSearch的高性能查询严重依赖于索引缓存，官方建议<a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/tune-for-search-speed.html#_give_memory_to_the_filesystem_cache_2">机器的内存得预留一半给操作系统进行文件缓存</a>，这套吃内存的东西对普通的日志查询简直就是小题大做。</p><p>4、还有ElasticSearch在生产环境至少得部署三个节点，否则由于网络波动容易出现<a href="https://peoplesofttutorial.com/elasticsearch-split-brain-problem">脑裂</a>。</p><p>5、基于JVM的Logstash极其笨重，经常因为<a href="https://discuss.elastic.co/t/logstash-with-long-gc/42159">GC无响应</a>导致日志延时，作为采集日志的agent有点喧宾夺主，为此Elastic专门用Go语言开发了轻量级的FileBeat日志采集工具。由FileBeat负责采集，Logstash负责解析处理。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/1tSJhpzDRzL3Fs0QtzAZaVDTe2Bdx5mrp1gNwmFcnAn7UZuF2hxiaVOPHW4gAIWu66KbkuVsb3nI4akLR7pKgow/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="ELK"></p><p>目前K8s生态下以Fluentd和C语言编写的fluent-bit为主作为日志收集工具，Grafana开发的Loki负责存储。Loki去掉了全文索引，使用最原始的块存储，对时间和特定标签做索引，这和Metrics领域的Prometheus类似。</p><p><img src="http://img.hufeifei.cn/picgoimage-20211118103512775.png" alt="image-20211118103512775"></p><h3>Metrics</h3><p>单体应用中应用的性能可以通过<a href="https://www.brendangregg.com/linuxperf.html">Linux自带的各种工具</a>进行观测。</p><p>比如最常用的top命令可以看到每个进程的CPU、内存等使用情况，<code>mpstat</code>、<code>vmstat</code>、<code>iostat</code>可以看到系统的CPU、内存、磁盘读写等情况。</p><p><img src="https://www.brendangregg.com/Perf/linux_observability_tools.png" alt="Linux Performance"></p><p>对于不同语言编写的应用也有针对应用内部的监控工具，如Java体系有<code>jmap</code>、<code>jconsole</code>、<a href="http://www.eclipse.org/mat/">Eclipse Memory Analyzer</a>等工具，JDK也提供了JMX对应用指标接口进行标准化。</p><p>在分布式系统中，由于应用部署在多台机器上，应用性能的观测面临着巨大的挑战。</p><p>指标数据和日志数据的区别在于它更加结构化，而且这些metrics的结构化数据与传统的OLTP数据库中的数据，区别在于：</p><ul><li>数据不可变，只有插入，没有修改</li><li>按时间依次生成，顺序追加</li><li>数据量远比传统的OLTP数据库大</li><li>主要以时间戳和单独的主键(serverId、deviceId、accountId……)做索引</li><li>数据通常需要聚合。需要看同一秒内应用所有机器的整体性能，就需要把这些机器的数据聚合起来</li></ul><p>这类数据也被称为<a href="https://en.wikipedia.org/wiki/Time_series_database">时序数据</a>，<a href="https://zhuanlan.zhihu.com/p/29367404">时序数据库的发展</a>就是专门用来解决这类数据的存储问题。</p><p>正因为时序数据是按照时间依次生成顺序追加的，所以除了早期的<a href="https://orangematter.solarwinds.com/2014/12/16/in-case-you-missed-it-building-a-time-series-database-in-mysql/">VividCortex（基于MySQL）</a>和<a href="https://blog.timescale.com/blog/building-a-distributed-time-series-database-on-postgresql/">TimeScaleDB（基于PostgreSQL）</a>使用就地更新的B+树来存储，其他大多数时序数据库都是用LSM-Tree(Log-Structured Merge Tree)作为底层的索引结构（在InfluxDB中被叫做Time-Structured Merge Tree）。</p><p><img src="http://img.hufeifei.cn/picgoimage-20211118103722343.png" alt="image-20211118103722343"></p><p>时序数据并不局限于系统与应用的性能指标，还包括了各种业务指标，如互联网应用的流量分析、接口性能、消息发送量……物联网传感器的功率、风速、温度等各种信号……金融领域的股票交易数据……</p><p>目前prometheus+grafana的组合几乎成了分布式系统指标观测的事实标准。</p><p><img src="http://img.hufeifei.cn/picgoimage-20211118104006562.png" alt="image-20211118104006562"></p><h3>Trace</h3><p>单体应用的调用只局限于内存的堆栈，可以通过<strong>stack trace</strong>进行调用链追踪，调用的性能分析可以通过这些堆栈生成相应的火炬图进行可视化。<a href="https://github.com/search?q=Flame+Graph">github</a>上也有大多数语言应用生成火炬图的工具，使用火炬图能方便地分析各个函数的调用深度和调用消耗。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/1tSJhpzDRzL3Fs0QtzAZaVDTe2Bdx5mr4TZtWaHyicKZh4Rhr2Zf4BHoMQjxWcf6kfgfkIo06icxT2ksuESn3b4w/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="FlameGraph"></p><p>但是分布式应用，不再是内存内的堆栈调用了，而是穿透网络的RPC调用。用户一个请求过来，从A服务到B服务再到C服务……这个调用链可能很长。再也不能像单机版应用一样直接看程序堆栈，直接用火炬图就能分析应用的性能了。而且一个应用部署了多台机器，具体调用了集群中哪台机器也是不知道的。</p><p>这就催生了<strong>调用链收集</strong>的工具，将分布式应用的调用链整成一个跟程序堆栈类似的东西，最好还能告诉我每个服务调用过程中的耗时，这就是<strong>Distributed Tracing</strong>。</p><p>最早<a href="https://zhuanlan.zhihu.com/p/163806366">谷歌的Dapper论文</a>就介绍了谷歌是怎么实现这个功能的。然后开源社区便产出了Zipkin、Jaeger等优秀工具，Spring Cloud也有一个Sleuth，这种组件很多，每种实现可能有所差别。</p><p>在谷歌论文里服务之间的调用被称为Span，整个链路被叫做Trace，但是在一些实现里服务间的调用被称为Rpc或者其他的名字，为了规范链路追踪的技术，有了<a href="https://opentracing.io/">OpenTracing</a>标准和<a href="https://opencensus.io/">OpenCensus</a>标准。</p><p>但是，OpenTracing和OpenCensus的出发点不一样。由社区发起的OpenTracing专注于链路追踪相关概念的统一，与具体实现无关，是一套链路追踪的规范。由谷歌主导的OpenCensus包括了Metrics和Trace两者数据收集的规范与对应的实现，后面微软的加入也更能证明这个项目的实力。</p><p>随着K8s催生的云原生的发展，OpenTracing和OpenCensus合并到了<a href="https://opentelemetry.io/">OpenTelemetry</a>，并且将Traces, Metrics, Logs进行了统一。目前OpenTelemetry是云原生基金会的孵化项目，是K8s生态分布式观测系统的未来。</p><p><img src="http://img.hufeifei.cn/picgoimage-20211118104143121.png" alt="image-20211118104143121"></p><h2>分布式观测系统的架构</h2><p>Logging、Metrics、Tracing三者架构上基本是一致统一的，但是<a href="https://openapm.io/landscape">这里面可选的组件</a>可谓是百花齐放。</p><p>比如FileBeat和MetricBeat可以负责Logging和Metrics的日志采集，由Logstash处理后存入ElasticSearch；ElasticAPM Agent可以负责Tracing的数据采集，由APM Server处理后存入ElasticSearch；Kibana中提供了Logging、Metrics、Tracing的可视化；Elastic官方提供了<a href="https://www.elastic.co/cn/what-is/kibana-alerting">kibana-alerting</a>用于告警，开源社区也有一个<a href="https://github.com/Yelp/elastalert">ElastAlert插件</a>可以提供告警功能。</p><p><img src="http://img.hufeifei.cn/picgoimage-20211118102519687.png" alt="EFK"></p><p>1、Library：应用内生成数据。Logging领域的库不胜枚举，Metrics和Tracing领域也有很多。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/1tSJhpzDRzL3Fs0QtzAZaVDTe2Bdx5mrb13picTN0L5qpkDU8HepUZBRYhCwJMUohRv0ZmEVX8iab8YpD6kNt8dg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="Library"></p><p>2、 Collector Agent：负责在服务器节点上采集数据，有一些能做简单的数据处理，如从日志中拆解字段，过滤清洗日志等。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/1tSJhpzDRzL3Fs0QtzAZaVDTe2Bdx5mrwa6micsq8ms79OeXhRUeEkPCwauYwqu6t1HuBuhaRLF392mw1zH8ySg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="Agent"></p><p>3、Transport：负责中间转储，防止日志丢失，为日志处理流程提供相对高的可靠性。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/1tSJhpzDRzL3Fs0QtzAZaVDTe2Bdx5mr9L5WE0hiaH4XWSHCK22l0Vh1l3DIMe6XH1vAiaS0MJEJRQeD0qx5eicjA/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="Transport"></p><p>4、Storage：负责数据的存储，可以根据数据的不同schema（非结构化的大文本日志类，半结构化的JSON文档类型，结构化的）选用适合的存储。</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/1tSJhpzDRzL3Fs0QtzAZaVDTe2Bdx5mrFnak49iazzLVUNibgOSXHzFM42Gr7Nacnib5dlo9KqzLusla5MFtYpHGg/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="Storage"></p><p>5、Visualization &amp; Dashboarding：负责将数据可视化展示，生成相应的仪表盘</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/1tSJhpzDRzL3Fs0QtzAZaVDTe2Bdx5mr8tNgGTPNWl2k9IPLOwicia8c52JYBYh3cBpnz4zZbicxavvsQbUIEPoVw/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="Visualization"></p><p>6、Alerting：负责对异常进行告警</p><p><img src="https://mmbiz.qpic.cn/mmbiz_png/1tSJhpzDRzL3Fs0QtzAZaVDTe2Bdx5mrTsyNI3zOJExvuthHKrd1mZmgMz1GTu9x9xBFXAwlbHUuw98uBxvN1g/640?wx_fmt=png&tp=webp&wxfrom=5&wx_lazy=1&wx_co=1" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="Alerting"></p><h2>基于Grafana的一站式分布式观测系统</h2><p>最早<a href="https://en.wikipedia.org/wiki/Grafana">Grafana</a>是为了弥补<a href="https://en.wikipedia.org/wiki/Kibana">Kibana</a>没有Metrics指标统计功能的一个分支，2014年首次发布，目标是为Prometheus、<a href="https://en.wikipedia.org/wiki/InfluxDB">InfluxDB</a>、OpenTSDB等时序数据库提供可视化界面，后面逐渐支持传统关系型数据库。</p><p>Kibana和Grafana走向了两个不同的发展道路。Kibana作为ElasticSearch的可视化工具，最早只支持日志查询，之后围绕着ElasticSearch存储功能的不断升级改进，才有了后面的Metrics和Tracing的功能。Grafana最早没有自己的存储功能，它通过接入各种数据库(也支持ElasticSearch)，来实现Metrics功能。</p><p><img src="https://p.pstatp.com/origin/pgc-image/06223321b0594f05a65b0d62ab8a7ed8" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer"></p><p>在2019年～2021年获得三轮融资后，依次有了Loki、Tempo专门支持Logging、Tracing的开源产品。</p><p><img src="https://p.pstatp.com/origin/pgc-image/ff7bc578c7ab464a9415a3d6e0791ef9" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer"></p><p><img src="http://img.hufeifei.cn/picgoimage-20211118111959974.png" alt="image-20211118111959974"></p><h3>OpenTelemetry</h3><p><a href="https://blog.hufeifei.cn/2021/10/Distribution/OpenTelemetry/">OpenTelemetry</a>是由两个项目合并而成：由开源社区主导的OpenTracing，由谷歌主导微软支持的OpenCensus。OpenTracing只是制定了Tracing相关的标准，OpenCensus提供了Tracing和Metrics采集与收集的相关实现。两者合并后目标是将Logging、Tracing、Metrics三者的采集与收集进行统一，并指定一个数据编码与传输规范——<a href="https://github.com/open-telemetry/opentelemetry-specification/blob/main/specification/protocol/otlp.md">OpenTelemetry Protocol Specification</a>。</p><p>截至当前(2021年11月)，OTLP规范的Tracing和Metrics已经稳定，Logging目前还在Beta版本。</p><p><img src="http://img.hufeifei.cn/picgoimage-20211118112912951.png" alt="image-20211118112912951"></p><p><a href="https://github.com/open-telemetry/opentelemetry-cpp-contrib/blob/main/instrumentation/nginx/README.md">opentelemetry-cpp-contrib</a>还提供了nginx的支持（C/C++语言实现的）。</p><h3>Loki</h3><p>日志数据的写是由Loki中的<a href="https://github.com/grafana/loki/blob/v2.3.0/docs/sources/architecture/distributor.md">Distributor</a>和Ingester两个组件处理，整体的流程如下图红线部分，读取过程由蓝线部分表示。</p><p><img src="https://p.pstatp.com/origin/pgc-image/1a23422dded44264bf646811a350ce10" rel="external noreferrer nofollow noopener" referrerpolicy="no-referrer" alt="Loki Architecture"></p><p>除此之外，Loki还提供了一个独立的应用<a href="https://grafana.com/docs/loki/latest/operations/loki-canary/">loki-canary</a>用于监控日志抓取性能。</p><p><img src="https://grafana.com/docs/loki/latest/operations/loki-canary-block.png" alt="Loki Canary"></p><p>使用grafana即可通过<a href="https://grafana.com/docs/loki/latest/logql/">LogQL</a>查询日志</p><p><img src="http://img.hufeifei.cn/picgoimage-20211118105337310.png" alt="image-20211118105337310"></p><h3>Tempo</h3><p><img src="http://img.hufeifei.cn/picgografana-query.png" alt="Tempo"></p><p>参考链接：</p><p>^ 1. 分布式系统观测性的三大基石：<a href="https://www.oreilly.com/library/view/distributed-systems-observability/9781492033431/ch04.html">https://www.oreilly.com/library/view/distributed-systems-observability/9781492033431/ch04.html</a></p><p>^ 2. 云原生生态远景图：<a href="https://landscape.cncf.io/">https://landscape.cncf.io/</a></p><p>^ 3. 面向列的数据库：<a href="http://www.timestored.com/time-series-data/what-is-a-column-oriented-database">http://www.timestored.com/time-series-data/what-is-a-column-oriented-database</a></p><p>^ 4. OpenMetrics: <a href="https://openmetrics.io/">https://openmetrics.io/</a></p><p>^ 5. OpenTracing: <a href="https://opentracing.io/">https://opentracing.io/</a></p><p>^ 6. OpenCensus: <a href="https://opencensus.io/">https://opencensus.io/</a></p><p>^ 7. OpenTelemetry: <a href="https://opentelemetry.io/">https://opentelemetry.io/</a></p><p>^ 8. OpenAPM: <a href="https://openapm.io/landscape">https://openapm.io/landscape</a></p><p>^ 9. Loki Architecture: <a href="https://grafana.com/docs/loki/latest/architecture/">https://grafana.com/docs/loki/latest/architecture/</a></p>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2&gt;从单体应用到分布式应用的可观测性&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;https://engineering.zenduty.com/assets/images/tracinglogging.png&quot; alt=&quot;分布式系统观测性的三大基石&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="分布式" scheme="https://blog.hufeifei.cn/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
    
    <category term="Distributed" scheme="https://blog.hufeifei.cn/tags/Distributed/"/>
    
  </entry>
  
  <entry>
    <title>SpringCloudConfig配置项刷新存在的问题</title>
    <link href="https://blog.hufeifei.cn/2021/09/Java/spring-cloud-config-refresh/"/>
    <id>https://blog.hufeifei.cn/2021/09/Java/spring-cloud-config-refresh/</id>
    <published>2021-09-17T16:00:00.000Z</published>
    <updated>2024-05-03T05:17:06.699Z</updated>
    
    <content type="html"><![CDATA[<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css"><h2>spring-cloud-bus项目结构</h2><p><img src="/2021/09/Java/spring-cloud-config-refresh/spring-cloud-monitor.svg"></p><p>spring-cloud-bus是用来实现服务间异步通信的服务总线，有基于kafka和rabbitmq的两个实现。</p><p>kafka和rabbitmq的消息处理逻辑本身也被抽象成了spring-cloud-stream，所以就有了上图中的依赖结构</p><p>spring-cloud-config-monitor是一个通过spring-cloud-bus实现配置实时更新的依赖库。</p><h2>spring-cloud-config-monitor架构</h2><p><img src="/2021/09/Java/spring-cloud-config-refresh/config-server-refresh-single.svg"></p><p>monitor一般是作为config-server的一个依赖库放在config-server上，这个库里提供了一个PropertyPathEndpoint的Controller接口。流程大致如下：</p><p>1、使用者在gitlab上修改并提交配置</p><p>2、gitlab在收到新的push后，把调用预先配置的webhook接口。这个webhook接口一般就是monitor提供的http接口。通过这个接口把git的push事件发送给monitor。</p><p>3、monitor收到事件后，解析事件中修改的文件，广播一个RefreshRemoteApplicationEvent事件到eventbus。这个事件有三个字段。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">abstract</span> <span class="keyword">class</span> <span class="title class_">RemoteApplicationEvent</span> <span class="keyword">extends</span> <span class="title class_">ApplicationEvent</span> &#123;</span><br><span class="line"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">final</span> <span class="type">Object</span> <span class="variable">TRANSIENT_SOURCE</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Object</span>();</span><br><span class="line">    <span class="comment">// 事件由哪个服务发送的</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String originService;</span><br><span class="line">    <span class="comment">// 事件发送给哪个服务，支持&quot;**&quot;的通配符，表示所有服务都接受这个事件</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String destinationService;</span><br><span class="line">    <span class="comment">// 事件ID</span></span><br><span class="line"><span class="keyword">private</span> <span class="keyword">final</span> String id;</span><br><span class="line">    ...</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>4、所有依赖了eventbus的服务会收到这个Refresh事件，根据事件中的<code>destinationService</code>字段判断，这个事件是否需要处理，如果匹配成功，会由<code>RefreshListener</code>接受并处理这个事件。</p><p>5、<code>RefreshListener</code>中会调用<code>ContextRefresher</code>，拉取最新的配置，并更新Environment，重建所有加了@RefreshScope注解的Bean。</p><h2>SpringBus的几个配置</h2><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">spring:</span></span><br><span class="line">  <span class="attr">cloud:</span></span><br><span class="line">    <span class="attr">bus:</span></span><br><span class="line">      <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">refresh:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">env:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">ack:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">true</span></span><br><span class="line">      <span class="attr">trace:</span></span><br><span class="line">        <span class="attr">enabled:</span> <span class="literal">false</span></span><br></pre></td></tr></table></figure><p>1、<code>refresh</code>代表是否要接受远程EventBus发送过来的<code>RefreshRemoteApplicationEvent</code>事件。事件由<code>RefreshListener</code>处理。处理过程中，会从config-server拉取最新配置，并发送EnvironmentChangeEvent通知ConfigurationPropertiesRebinder刷新配置Bean</p><p>2、<code>env</code>是用来刷新部分配置的，事件里面要提供刷新的<code>name</code>和<code>value</code>值。</p><p>3、<code>ack</code>是收到EventBus远程发来的事件后，是否返回确认事件。</p><p>4、<code>trace</code>是用来记录这些事件的，目前SpringCloud没有实现，只是打了debug日志。但是SpringCloud提供了HttpTraceRepository接口，后期可能会扩展。</p><h2>存在的问题</h2><p><img src="/2021/09/Java/spring-cloud-config-refresh/config-server-refresh-config.svg"></p><p>1、如果<code>config-server</code>存在多个实例，webhook没办法广播到多个<code>config-server</code>实例，<code>config-server</code>本地备份的git仓库如何更新。如果有实例没有更新，就会导致第5步，拉取不到最新的配置。</p><p>2、gitlab中通常只配置一个webhook，测试、预发、生产环境的<code>config-server</code>怎么能都收到这个配置进行仓库的更新。</p><h3>解决方案一</h3><p>1、首先mq必须全局共享，开发、测试、预发、生产都用同一套mq</p><p>2、gitlab中配置的webhook是生产环境的config-server，收到push事件后，根据修改的文件提取出来环境和应用，通知对应环境的<code>config-server</code>更新git仓库</p><p>3、对应环境的<code>config-server</code>更新git仓库完成后，需要返回响应，响应中需要带上该环境下其他的<code>config-server</code>实例的信息(这个信息可以从eureka中获取,eureka是环境隔离的)。</p><p>4、需要等其他的<code>config-server</code>都更新完成后，再推送Refresh事件到其他需要更新配置的服务，这个时候能保证所有的服务拉到的配置都是最新的</p><p><img src="/2021/09/Java/spring-cloud-config-refresh/config-server-refresh-multi-profile.svg"></p><h3>解决方案二</h3><p>1、gitlab中配置多个环境的webhook，这要求各环境的<code>config-server</code>域名区分开</p><p>2、webhook调用接口后，<code>config-server</code>检查更新的文件是否涉及当前环境，如果没有不需要做任何处理，相反如果涉及当前环境执行第3步</p><p>3、发送事件给当前环境的所有<code>config-server</code>实例，更新完成后返回确认</p><p>4、收到所有的确认后再由<code>config-server</code>发送Refresh事件到需要更新配置的服务</p><p><img src="/2021/09/Java/spring-cloud-config-refresh/config-server-refresh-isolation.svg"></p><h3>解决方案三</h3><p>SpringCloudBus的问题：</p><p>1、通过rabbitmq广播到每个环境，最后等所有环境确认，这段延时比较严重</p><p>2、通过rabbitmq推送刷新事件到应用，这段延时也比较严重</p><p>3、SpringCloudContext刷新时会重建Context，不可用的情况不能忍</p><p>抛弃SpringCloudBus，使用与Nacos、Consul一样的长轮询</p><p>1、首先mq必须全局共享，开发、测试、预发、生产都用同一套mq</p><p>2、gitlab中配置的webhook是生产环境的config-server，收到push事件后，根据修改的文件提取出来环境和应用，通知对应环境的<code>config-server</code>更新git仓库</p><p>3、<code>config-server</code>一旦收到更新仓库的通知后，更新完仓库，即刻通知自身hold住的长连接返回结果</p><p><img src="/2021/09/Java/spring-cloud-config-refresh/config-server-refresh-long-polling.svg"></p>]]></content>
    
    
    <summary type="html">&lt;link rel=&quot;stylesheet&quot; type=&quot;text/css&quot; href=&quot;https://cdn.jsdelivr.net/hint.css/2.4.1/hint.min.css&quot;&gt;&lt;h2&gt;spring-cloud-bus项目结构&lt;/h2&gt;&lt;p&gt;&lt;img src=&quot;/2021/09/Java/spring-cloud-config-refresh/spring-cloud-monitor.svg&quot;&gt;&lt;/p&gt;</summary>
    
    
    
    <category term="JAVA" scheme="https://blog.hufeifei.cn/categories/JAVA/"/>
    
    
    <category term="JAVA" scheme="https://blog.hufeifei.cn/tags/JAVA/"/>
    
    <category term="SpringCloud" scheme="https://blog.hufeifei.cn/tags/SpringCloud/"/>
    
    <category term="SpringCloudConfig" scheme="https://blog.hufeifei.cn/tags/SpringCloudConfig/"/>
    
  </entry>
  
</feed>
